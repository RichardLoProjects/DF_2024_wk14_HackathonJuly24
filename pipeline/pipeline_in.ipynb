{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script is good!\n"
     ]
    }
   ],
   "source": [
    "'''Data pipeline to pull data from local csv and prepare a json file for frontEnd display.'''\n",
    "import pandas as pd # type: ignore\n",
    "import json\n",
    "\n",
    "\n",
    "class DataPipeline:\n",
    "    def __init__(self, source:str, target:str, primary_key:str) -> None:\n",
    "        self.df = pd.DataFrame()\n",
    "        self.specialisation = pd.DataFrame()\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.pk = primary_key\n",
    "    def extract(self) -> None:\n",
    "        self.df = pd.read_csv(self.source)\n",
    "    def transform(self) -> None:\n",
    "        model_data:pd.DataFrame = self.df\n",
    "        model_data = model_data[(model_data['type']!='dataset')]\n",
    "        model_data.loc[:,'created_date'] = pd.to_datetime(model_data['created_date'], errors='coerce')\n",
    "        new_columns = model_data['modality'].apply(repackage_modality).apply(pd.Series)\n",
    "        model_data = model_data.assign(input_modality=new_columns[0], output_modality=new_columns[1])\n",
    "        model_data = model_data.drop(columns='modality')\n",
    "        model_data.loc[:,'dependencies'] = model_data[['dependencies']].copy().map(\n",
    "            lambda raw: ', '.join([s.strip(' ').strip('\\'') for s in str(raw)[1:-1].split(',')])\n",
    "        )\n",
    "        model_data = model_data.replace('unknown', None, regex=True)\n",
    "        model_data = model_data.replace('nan', None, regex=True)\n",
    "        for column_name in model_data.copy().columns:\n",
    "            if len(model_data[column_name].unique()) <= 1:\n",
    "                model_data = model_data.drop(columns=column_name)\n",
    "        model_data[self.pk] = range(1, 1+len(model_data))\n",
    "        reordered_columns = [\n",
    "            'name'\n",
    "            , 'url'\n",
    "            , 'organization'\n",
    "            , 'created_date'\n",
    "            , 'size'\n",
    "            , 'intended_uses'\n",
    "            , 'prohibited_uses'\n",
    "            , 'input_modality'\n",
    "            , 'output_modality'\n",
    "            , 'model_card'\n",
    "            , 'adaptation'\n",
    "            , 'output_space'\n",
    "            , 'monthly_active_users'\n",
    "            , 'user_distribution'\n",
    "            , 'terms_of_service'\n",
    "            , 'license'\n",
    "            , 'quality_control'\n",
    "            , 'monitoring'\n",
    "            , 'feedback'\n",
    "            , 'access'\n",
    "            , 'description'\n",
    "            , 'analysis'\n",
    "            , 'type'\n",
    "            , 'dependencies'\n",
    "            , 'training_emissions'\n",
    "            , 'training_time'\n",
    "            , 'training_hardware'\n",
    "        ]\n",
    "        model_data = model_data[reordered_columns]\n",
    "        temp_df_excel = pd.read_excel('../data/LLM Matrix.xlsx')\n",
    "        self.specialisation = temp_df_excel.iloc[2:16,0:3]\n",
    "        self.specialisation.columns = temp_df_excel.iloc[1,0:3].to_list()\n",
    "        self.specialisation.rename(columns={'model':'name'}, inplace=True)\n",
    "        self.specialisation.dropna(subset='specialisation', inplace=True)\n",
    "        self.df = model_data.merge(self.specialisation[['name', 'specialisation']], on='name', how='left')\n",
    "    def load(self) -> None:\n",
    "        self.df.to_json(self.target, orient='records', lines=True)\n",
    "        self.df.to_csv('../data/processed.csv')\n",
    "    def call_sos(self, error_message:str) -> None:\n",
    "        print(error_message)\n",
    "\n",
    "\n",
    "def repackage_modality(raw:str) -> tuple[list[str]]:\n",
    "    raw = str(raw)\n",
    "    semicolon_count = raw.count(';')\n",
    "    assert semicolon_count <= 1, 'LLM modality invalid.'\n",
    "    if semicolon_count == 0:\n",
    "        raw = raw + ';' + raw\n",
    "    modal_input_str, modal_output_str = raw.split(';')\n",
    "    modal_inputs = ', '.join([s.strip() for s in modal_input_str.split(',')])\n",
    "    modal_outputs = ', '.join([s.strip() for s in modal_output_str.split(',')])\n",
    "    return modal_inputs, modal_outputs\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    try:\n",
    "        source_path = '../data/assets.csv'\n",
    "        target_path = '../data/processed.json'\n",
    "        primary_key = 'primary_key'\n",
    "        pipeline = DataPipeline(\n",
    "            source_path\n",
    "            , target_path\n",
    "            , primary_key\n",
    "        )\n",
    "        pipeline.extract()\n",
    "        pipeline.transform()\n",
    "        pipeline.load()\n",
    "        print('Script is good!')\n",
    "    except Exception as e:\n",
    "        pipeline.call_sos(e)\n",
    "    finally:\n",
    "        '''Close connections.'''\n",
    "        pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
