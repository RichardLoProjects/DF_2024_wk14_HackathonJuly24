{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data from a CSV file found [here](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table). Let's try to understand it. The motivating goal of the Data Engineer is to clean and structure the data so that it is accessible to our Data Analyst and Software Engineer teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the tool to look at tabular data and extracting it from the csv source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strip away columns with no information, and limit data to LLM models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['type']=='model')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.copy().columns:\n",
    "    if len(df[c].unique()) <= 1:\n",
    "        df.drop(columns=c, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the size of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 359 rows and 20 columns.\n"
     ]
    }
   ],
   "source": [
    "row_count, column_count = df.shape\n",
    "print(f'The data has {row_count} rows and {column_count} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is quite a lot of columns. Let's list them, along with the number of non-null values and their data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "webpage_columns = [\n",
    "    'type'\n",
    "    , 'name'\n",
    "    , 'organization'\n",
    "    , 'created_date'\n",
    "    , 'size'\n",
    "    , 'modality'\n",
    "    , 'access'\n",
    "    , 'license'\n",
    "    , 'dependencies'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 359 entries, 3 to 564\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   name                359 non-null    object\n",
      " 1   organization        359 non-null    object\n",
      " 2   description         299 non-null    object\n",
      " 3   created_date        357 non-null    object\n",
      " 4   url                 357 non-null    object\n",
      " 5   modality            357 non-null    object\n",
      " 6   size                355 non-null    object\n",
      " 7   analysis            234 non-null    object\n",
      " 8   dependencies        359 non-null    object\n",
      " 9   quality_control     85 non-null     object\n",
      " 10  access              359 non-null    object\n",
      " 11  license             343 non-null    object\n",
      " 12  intended_uses       129 non-null    object\n",
      " 13  prohibited_uses     86 non-null     object\n",
      " 14  monitoring          118 non-null    object\n",
      " 15  feedback            161 non-null    object\n",
      " 16  model_card          170 non-null    object\n",
      " 17  training_emissions  244 non-null    object\n",
      " 18  training_time       250 non-null    object\n",
      " 19  training_hardware   262 non-null    object\n",
      "dtypes: object(20)\n",
      "memory usage: 58.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `created_date` should be a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['created_date'] = pd.to_datetime(df['created_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtype cleaning to do:\n",
    "\n",
    "```\n",
    "- date date\n",
    "- modal list -> str\n",
    "- size int (number of param in type model, not type dataset)\n",
    "- monthly_active_users str -> int\n",
    "- sample list of websites -> ??\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
