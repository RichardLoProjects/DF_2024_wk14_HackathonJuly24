,name,organization,description,created_date,url,size,analysis,dependencies,quality_control,access,license,intended_uses,prohibited_uses,monitoring,feedback,model_card,training_emissions,training_time,training_hardware,model_id,input_modality,output_modality,table_pk
1,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,2,text,text,2
2,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,2,text,video,3
3,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,2,video,text,4
4,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,2,video,video,5
151,Chronos,Amazon,"Chronos is a family of pretrained time series forecasting models based on language model architectures. A time series is transformed into a sequence of tokens via scaling and quantization, and a language model is trained on these tokens using the cross-entropy loss. Once trained, probabilistic forecasts are obtained by sampling multiple future trajectories given the historical context.",2024-03-13,https://github.com/amazon-science/chronos-forecasting,710M parameters (dense),Chronos has been evaluated comprehensively on 42 datasets both in the in-domain (15 datasets) and zero-shot settings (27 datasets). Chronos outperforms task specific baselines in the in-domain setting and is competitive or better than trained models in the zero-shot setting.,T5,"Chronos was evaluated rigorously on 42 datasets, including 27 in the zero-shot setting against a variety of statistical and deep learning baselines.",open,Apache 2.0,"Chronos can be used for zero-shot time series forecasting on univariate time series from arbitrary domains and with arbitrary horizons. Chronos models can also be fine-tuned for improved performance of specific datasets. Embeddings from Chronos encoder may also be useful for other time series analysis tasks such as classification, clustering, and anomaly detection.",,,https://github.com/amazon-science/chronos-forecasting/discussions,https://huggingface.co/amazon/chronos-t5-large,,63 hours on p4d.24xlarge EC2 instance,8 NVIDIA A100 40G GPUs,78,time-series,time-series,152
231,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",RefinedWeb,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,97,text,text,232
232,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",The Pile,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,97,text,text,233
233,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",RedPajama-Data,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,97,text,text,234
234,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",Dolma,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,97,text,text,235
235,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",CoreNet library,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,97,text,text,236
366,Gemini,Google,"As of release, Gemini is Google's most capable and flexible AI model, proficient in multimodal domains.",2023-12-06,https://deepmind.google/technologies/gemini/#introduction,unknown,"Evaluated on standard general, reasoning, math, coding, and multimodal benchmarks with results that surpass GPT-4 on almost all.",,,closed,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,,,unknown,unknown,unknown,144,text,image,367
367,Gemini,Google,"As of release, Gemini is Google's most capable and flexible AI model, proficient in multimodal domains.",2023-12-06,https://deepmind.google/technologies/gemini/#introduction,unknown,"Evaluated on standard general, reasoning, math, coding, and multimodal benchmarks with results that surpass GPT-4 on almost all.",,,closed,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,,,unknown,unknown,unknown,144,text,text,368
368,Gemini,Google,"As of release, Gemini is Google's most capable and flexible AI model, proficient in multimodal domains.",2023-12-06,https://deepmind.google/technologies/gemini/#introduction,unknown,"Evaluated on standard general, reasoning, math, coding, and multimodal benchmarks with results that surpass GPT-4 on almost all.",,,closed,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,,,unknown,unknown,unknown,144,text,video,369
405,GPT-4 Turbo,OpenAI,GPT-4 Turbo is a more capable version of GPT-4 and has knowledge of world events up to April 2023. It has a 128k context window so it can fit the equivalent of more than 300 pages of text in a single prompt.,2023-11-06,https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo,unknown,,,,limited,custom,,,unknown,,,unknown,unknown,unknown,167,text,text,406
672,Llama 3,Meta,Llama 3 is the third generation of Meta AI's open-source large language model. It comes with pretrained and instruction-fine-tuned language models with 8B and 70B parameters that can support a broad range of use cases.,2024-04-18,https://llama.meta.com/llama3/,70B parameters,"The models were evaluated based on their performance on standard benchmarks and real-world scenarios. These evaluations were performed using a high-quality human evaluation set containing 1,800 prompts covering multiple use cases. The models also went through red-teaming for safety, where human experts and automated methods were used to generate adversarial prompts to test for problematic responses.",,"Extensive internal and external testing for safety, and design of new trust and safety tools.",open,Llama 3,"Llama 3 is intended for a broad range of use cases, including AI assistance, content creation, learning, and analysis.",unknown,Extensive internal and external performance evaluation and red-teaming approach for safety testing.,"Feedback is encouraged from users to improve the model, but the feedback mechanism is not explicitly described.",https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md,unknown,unknown,2 custom-built Meta 24K GPU clusters,254,text,text,673
787,WizardLM,Microsoft,"Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM.",2023-04-24,https://arxiv.org/pdf/2304.12244v1.pdf,7B parameters (dense),Reports results on standard LLM benchmarks in comparison to other LLMs and test sets.,LLaMA,,open,Apache 2.0,"Creating large amounts of instruction data, particularly with high complexity",,,https://huggingface.co/datasets/WizardLM/evol_instruct_70k/discussions,https://huggingface.co/WizardLM/WizardLM-13B-1.0,,70 hours on 3 epochs,8 V100 GPUs,302,text,text,788
788,WizardLM,Microsoft,"Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM.",2023-04-24,https://arxiv.org/pdf/2304.12244v1.pdf,7B parameters (dense),Reports results on standard LLM benchmarks in comparison to other LLMs and test sets.,Evol-Instruct,,open,Apache 2.0,"Creating large amounts of instruction data, particularly with high complexity",,,https://huggingface.co/datasets/WizardLM/evol_instruct_70k/discussions,https://huggingface.co/WizardLM/WizardLM-13B-1.0,,70 hours on 3 epochs,8 V100 GPUs,302,text,text,789
789,WizardLM,Microsoft,"Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM.",2023-04-24,https://arxiv.org/pdf/2304.12244v1.pdf,7B parameters (dense),Reports results on standard LLM benchmarks in comparison to other LLMs and test sets.,Alpaca dataset,,open,Apache 2.0,"Creating large amounts of instruction data, particularly with high complexity",,,https://huggingface.co/datasets/WizardLM/evol_instruct_70k/discussions,https://huggingface.co/WizardLM/WizardLM-13B-1.0,,70 hours on 3 epochs,8 V100 GPUs,302,text,text,790
818,CORGI,Stanford,Model trained to generate language corrections for physical control tasks.,2023-06-12,https://arxiv.org/pdf/2306.07012.pdf,124M parameters (dense),"Evaluated on three physical control tasks, drawing, steering, and human body movement on various dynamics",GPT-2,,open,MIT,,,,,,,unknown,one NVIDIA A40 GPU,323,human trajectories,text,819
819,CORGI,Stanford,Model trained to generate language corrections for physical control tasks.,2023-06-12,https://arxiv.org/pdf/2306.07012.pdf,124M parameters (dense),"Evaluated on three physical control tasks, drawing, steering, and human body movement on various dynamics",BABEL,,open,MIT,,,,,,,unknown,one NVIDIA A40 GPU,323,human trajectories,text,820
820,CORGI,Stanford,Model trained to generate language corrections for physical control tasks.,2023-06-12,https://arxiv.org/pdf/2306.07012.pdf,124M parameters (dense),"Evaluated on three physical control tasks, drawing, steering, and human body movement on various dynamics",text-davinci-003,,open,MIT,,,,,,,unknown,one NVIDIA A40 GPU,323,human trajectories,text,821
