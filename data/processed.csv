,type,name,organization,description,created_date,url,size,analysis,dependencies,quality_control,access,license,intended_uses,prohibited_uses,monitoring,feedback,model_card,training_emissions,training_time,training_hardware,adaptation,output_space,terms_of_service,monthly_active_users,user_distribution,failures,model_id,input_modality,output_modality,table_pk
3,model,Lag-LLaMA,"Morgan Stanley, ServiceNow Research, University of Montreal, Mila-Quebec AI Institute",Lag-LLaMA is a general-purpose foundation model for univariate probabilistic time series forecasting based on a decoder-only transformer architecture that uses lags as covariates.,2024-02-08,https://time-series-foundation-models.github.io/lag-llama.pdf,unknown,Evaluated on previously unseen time series datasets.,,,open,Apache 2.0,,,unknown,https://huggingface.co/time-series-foundation-models/Lag-Llama/discussions,https://huggingface.co/time-series-foundation-models/Lag-Llama,unknown,unknown,A single NVIDIA Tesla-P100 GPU,,,,,,,1,text,text,1
4,model,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,,,,,,,2,text,text,2
4,model,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,,,,,,,2,text,video,3
4,model,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,,,,,,,2,video,text,4
4,model,Prithvi,IBM,"Prithvi is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.",2023-08-03,https://github.com/NASA-IMPACT/hls-foundation-os,100M parameters (dense),,NASA HLS data,,open,Apache 2.0,,,,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions,https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M,,,,,,,,,,2,video,video,5
5,application,Watsonx.ai,IBM,"Watsonx.ai is part of the IBM watsonx platform that brings together new generative AI capabilities, powered by foundation models and traditional machine learning into a powerful studio spanning the AI lifecycle.",2023-09-07,https://www.ibm.com/products/watsonx-ai,,,Granite,,limited,custom,,,,,,,,,,deployed AI models,https://www.ibm.com/docs/en/watsonx-as-a-service?topic=models-terms-use,,,,3,nan,nan,6
6,model,Granite,IBM,Granite is a set of multi-size foundation models that apply generative AI to both language and code.,2023-09-28,https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models/,13B parameters (dense),unknown,,"Training data passed through IBM HAP detector, language model designed to remove harmful content. Data also deduplicated and filtered for document quality.",limited,,,,,,,unknown,unknown,unknown,,,,,,,4,text,code,7
6,model,Granite,IBM,Granite is a set of multi-size foundation models that apply generative AI to both language and code.,2023-09-28,https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models/,13B parameters (dense),unknown,,"Training data passed through IBM HAP detector, language model designed to remove harmful content. Data also deduplicated and filtered for document quality.",limited,,,,,,,unknown,unknown,unknown,,,,,,,4,text,text,8
7,model,Animagine XL 3.1,Cagliostro Research Lab,"An open-source, anime-themed text-to-image model enhanced to generate higher quality anime-style images with a broader range of characters from well-known anime series, an optimized dataset, and new aesthetic tags for better image creation.",2024-03-18,https://cagliostrolab.net/posts/animagine-xl-v31-release,unknown,unknown,Animagine XL 3.0,"The model undergoes pretraining, first stage finetuning, and second stage finetuning for refining and improving aspects such as hand and anatomy rendering.",open,Fair AI Public License 1.0-SD,"Generating high-quality anime images from textual prompts. Useful for anime fans, artists, and content creators.",Not suitable for creating realistic photos or for users who expect high-quality results from short or simple prompts.,unknown,https://huggingface.co/cagliostrolab/animagine-xl-3.1/discussions,https://huggingface.co/cagliostrolab/animagine-xl-3.1,unknown,"Approximately 15 days, totaling over 350 GPU hours.",2x A100 80GB GPUs,,,,,,,5,text,image,9
8,application,Portkey,Portkey,Portkey is a hosted middleware that allows users to create generative AI applications,2023-05-06,https://portkey.ai/,,,,,open,,,,,,,,,,,generative AI apps,https://portkey.ai/terms,,,,6,nan,nan,10
9,application,Viable,Viable,"Viable analyzes qualitative consumer feedback and provides summary feedback to companies.
",,https://www.askviable.com/,,,OpenAI API,unknown,limited,unknown,"Intended to be used by companies to digest qualitative consumer feedback.
","Prohibited uses are listed in the Terms of Service [[Terms of Service]](https://www.askviable.com/terms-of-service). The terms don't include statements specific to the use of the content generated by the system or GPT-3.
",unknown,unknown,,,,,unknown,"Question and answer, summarization, sentiment analysis, topic identification",https://www.askviable.com/terms-of-service,unknown,unknown,unknown,7,nan,nan,11
10,application,Auto-GPT,Auto-GPT,Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model.,2023-04-16,https://news.agpt.co/,,,GPT-4 API,,open,MIT,,,,,,,,,"GPT-4 adapted to run autonomously by chaining together LLM ""thoughts""",text,,,,,8,nan,nan,12
11,model,Bark,Suno,Bark is a text-to-audio model that can generate multilingual speech as well as other noises.,2023-04-20,https://github.com/suno-ai/bark,,,AudioLM,,open,MIT,,,,https://huggingface.co/spaces/suno/bark/discussions,https://github.com/suno-ai/bark/blob/main/model-card.md,unknown,unknown,,,,,,,,9,text,audio,13
12,application,ChatGPT powered by OBO,HubSpot,"Give your sales, marketing, and customer service teams one of the most powerful AI tools available - ChatGPT priority access, no timeout limits, company wide access managed through a single account, incorporate into your existing processes without leaving HubSpot",2023-01-31,https://ecosystem.hubspot.com/marketplace/apps/sales/sales-enablement/the-obo-group-chatgpt-1398072,,,ChatGPT API,,limited,unknown,,,,,,,,,,,,,,,10,nan,nan,14
13,model,GPT-JT,Together,,2022-11-29,https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai,6B parameters (dense),,GPT-J,,open,Apache 2.0,,,,,,,,,,,,,,,11,text,text,15
13,model,GPT-JT,Together,,2022-11-29,https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai,6B parameters (dense),,P3,,open,Apache 2.0,,,,,,,,,,,,,,,11,text,text,16
13,model,GPT-JT,Together,,2022-11-29,https://www.together.xyz/blog/releasing-v1-of-gpt-jt-powered-by-open-source-ai,6B parameters (dense),,NaturalInstructions-v2,,open,Apache 2.0,,,,,,,,,,,,,,,11,text,text,17
14,model,GPT-NeoXT-Chat-Base,Together,,2023-03-10,https://www.together.xyz/blog/openchatkit,20B parameters (dense),,GPT-NeoX,,open,Apache 2.0,,,,,,,,,,,,,,,12,text,text,18
14,model,GPT-NeoXT-Chat-Base,Together,,2023-03-10,https://www.together.xyz/blog/openchatkit,20B parameters (dense),,OIG-43M,,open,Apache 2.0,,,,,,,,,,,,,,,12,text,text,19
15,model,OpenChatKit moderation model,Together,,2023-03-10,https://www.together.xyz/blog/openchatkit,6B parameters (dense),,GPT-JT,,open,Apache 2.0,,,,,,,,,,,,,,,13,text,text,20
15,model,OpenChatKit moderation model,Together,,2023-03-10,https://www.together.xyz/blog/openchatkit,6B parameters (dense),,OIG-moderation,,open,Apache 2.0,,,,,,,,,,,,,,,13,text,text,21
19,model,Llama-2-7B-32K-Instruct,Together,"Llama-2-7B-32K-Instruct is an open-source, long-context chat model finetuned from Llama-2-7B-32K, over high-quality instruction and chat data.",2023-08-18,https://together.ai/blog/llama-2-7b-32k-instruct,7B parameters (dense),"Model evaluated over AlpacaEval, Rouge score over BookSum, and accuracy over MQA.",BookSum dataset,,open,LLaMA 2,,,,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct/discussions,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct,,,,,,,,,,14,text,text,22
19,model,Llama-2-7B-32K-Instruct,Together,"Llama-2-7B-32K-Instruct is an open-source, long-context chat model finetuned from Llama-2-7B-32K, over high-quality instruction and chat data.",2023-08-18,https://together.ai/blog/llama-2-7b-32k-instruct,7B parameters (dense),"Model evaluated over AlpacaEval, Rouge score over BookSum, and accuracy over MQA.",MQA dataset,,open,LLaMA 2,,,,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct/discussions,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct,,,,,,,,,,14,text,text,23
19,model,Llama-2-7B-32K-Instruct,Together,"Llama-2-7B-32K-Instruct is an open-source, long-context chat model finetuned from Llama-2-7B-32K, over high-quality instruction and chat data.",2023-08-18,https://together.ai/blog/llama-2-7b-32k-instruct,7B parameters (dense),"Model evaluated over AlpacaEval, Rouge score over BookSum, and accuracy over MQA.",Together API,,open,LLaMA 2,,,,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct/discussions,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct,,,,,,,,,,14,text,text,24
19,model,Llama-2-7B-32K-Instruct,Together,"Llama-2-7B-32K-Instruct is an open-source, long-context chat model finetuned from Llama-2-7B-32K, over high-quality instruction and chat data.",2023-08-18,https://together.ai/blog/llama-2-7b-32k-instruct,7B parameters (dense),"Model evaluated over AlpacaEval, Rouge score over BookSum, and accuracy over MQA.",LLaMA 2,,open,LLaMA 2,,,,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct/discussions,https://huggingface.co/togethercomputer/Llama-2-7B-32K-Instruct,,,,,,,,,,14,text,text,25
21,model,StripedHyena,Together,"StripedHyena is an LLM and the first alternative model competitive with the best open-source Transformers in short and long-context evaluations, according to Together.",2023-12-08,https://www.together.ai/blog/stripedhyena-7b,7B parameters (dense),Model evaluated on a suite of short-context task benchmarks.,Hyena,,open,Apache 2.0,,,,https://huggingface.co/togethercomputer/StripedHyena-Hessian-7B/discussions,https://huggingface.co/togethercomputer/StripedHyena-Hessian-7B,unknown,unknown,unknown,,,,,,,15,text,text,26
21,model,StripedHyena,Together,"StripedHyena is an LLM and the first alternative model competitive with the best open-source Transformers in short and long-context evaluations, according to Together.",2023-12-08,https://www.together.ai/blog/stripedhyena-7b,7B parameters (dense),Model evaluated on a suite of short-context task benchmarks.,RedPajama-Data,,open,Apache 2.0,,,,https://huggingface.co/togethercomputer/StripedHyena-Hessian-7B/discussions,https://huggingface.co/togethercomputer/StripedHyena-Hessian-7B,unknown,unknown,unknown,,,,,,,15,text,text,27
22,model,StripedHyena Nous,Together,"StripedHyena Nous is an LLM and chatbot, along with the first alternative model competitive with the best open-source Transformers in short and long-context evaluations, according to Together.",2023-12-08,https://www.together.ai/blog/stripedhyena-7b,7B parameters (dense),Model evaluated on a suite of short-context task benchmarks.,Hyena,,open,Apache 2.0,,,,https://huggingface.co/togethercomputer/StripedHyena-Nous-7B/discussions,https://huggingface.co/togethercomputer/StripedHyena-Nous-7B,unknown,unknown,unknown,,,,,,,16,text,text,28
22,model,StripedHyena Nous,Together,"StripedHyena Nous is an LLM and chatbot, along with the first alternative model competitive with the best open-source Transformers in short and long-context evaluations, according to Together.",2023-12-08,https://www.together.ai/blog/stripedhyena-7b,7B parameters (dense),Model evaluated on a suite of short-context task benchmarks.,RedPajama-Data,,open,Apache 2.0,,,,https://huggingface.co/togethercomputer/StripedHyena-Nous-7B/discussions,https://huggingface.co/togethercomputer/StripedHyena-Nous-7B,unknown,unknown,unknown,,,,,,,16,text,text,29
23,model,MediTron,"EPFL, Idiap Research Institute, OpenAssistant, Yale",Meditron is a large-scale medical LLM that remains open-source.,2023-11-27,https://arxiv.org/pdf/2311.16079.pdf,70B parameters (dense),Evaluated on TruthfulQA as main evaluation benchmark.,,,open,LLaMA 2,"Medical exam question answering, supporting differential diagnosis, disease information.",,,https://huggingface.co/epfl-llm/meditron-7b/discussions,https://huggingface.co/epfl-llm/meditron-70b,unknown,unknown,unknown,,,,,,,17,text,text,30
24,model,XVERSE,Xverse,XVERSE is a multilingual large language model for over 40 languages.,2023-11-06,https://github.com/xverse-ai/XVERSE-65B,65B parameters (dense),Evaluated across a range of standard datasets regarding multiple model capabilities like language comprehension and logical reasoning.,,,open,custom,,,unknown,https://huggingface.co/xverse/XVERSE-65B/discussions,https://huggingface.co/xverse/XVERSE-65B,unknown,unknown,unknown,,,,,,,18,text,text,31
25,model,Otter,Nanyang Technological University,"Otter is a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind’s Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning.",2023-05-05,https://arxiv.org/pdf/2305.03726v1.pdf,1.3B parameters (dense),Evaluated on researcher experiments to test deeper understanding and advanced commonsense reasoning,MIMIC-IT,,open,MIT,Following and executing new instructions with few in-context learning examples given image and textual input.,,,,https://github.com/Luodian/Otter/blob/main/docs/model_card.md,,,4 RTX-3090 GPUs,,,,,,,19,image,text,32
25,model,Otter,Nanyang Technological University,"Otter is a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind’s Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning.",2023-05-05,https://arxiv.org/pdf/2305.03726v1.pdf,1.3B parameters (dense),Evaluated on researcher experiments to test deeper understanding and advanced commonsense reasoning,OpenFlamingo,,open,MIT,Following and executing new instructions with few in-context learning examples given image and textual input.,,,,https://github.com/Luodian/Otter/blob/main/docs/model_card.md,,,4 RTX-3090 GPUs,,,,,,,19,image,text,33
25,model,Otter,Nanyang Technological University,"Otter is a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind’s Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning.",2023-05-05,https://arxiv.org/pdf/2305.03726v1.pdf,1.3B parameters (dense),Evaluated on researcher experiments to test deeper understanding and advanced commonsense reasoning,MIMIC-IT,,open,MIT,Following and executing new instructions with few in-context learning examples given image and textual input.,,,,https://github.com/Luodian/Otter/blob/main/docs/model_card.md,,,4 RTX-3090 GPUs,,,,,,,19,text,text,34
25,model,Otter,Nanyang Technological University,"Otter is a multi-modal model based on OpenFlamingo (open-sourced version of DeepMind’s Flamingo), trained on MIMIC-IT and showcasing improved instruction-following ability and in-context learning.",2023-05-05,https://arxiv.org/pdf/2305.03726v1.pdf,1.3B parameters (dense),Evaluated on researcher experiments to test deeper understanding and advanced commonsense reasoning,OpenFlamingo,,open,MIT,Following and executing new instructions with few in-context learning examples given image and textual input.,,,,https://github.com/Luodian/Otter/blob/main/docs/model_card.md,,,4 RTX-3090 GPUs,,,,,,,19,text,text,35
27,model,MiniMA,Beijing Institute of Technology,MiniMA is a smaller finetuned Llama 2 model adapted for Chinese.,2023-11-13,https://github.com/GeneZC/MiniMA,3B parameters (dense),"Evaluated on standard benchmarks including MMLU, CEval, and DROP.",Llama 2,,open,Llama 2,,,unknokwn,https://huggingface.co/GeneZC/MiniMA-3B/discussions,https://huggingface.co/GeneZC/MiniMA-3B,unknown,unknown,8 A100 80G GPUs,,,,,,,20,text,text,36
28,model,ChatGLM,ChatGLM,"ChatGLM is a Chinese-English language model with question and answer and dialogue functions, and is aimed at a Chinese audience.",2023-03-14,https://chatglm.cn/blog,6B parameters (dense),Performance evaluated on English and Chinese language benchmark tests.,,,open,Apache 2.0,,,,,,unknown,unknown,,,,,,,,21,text,text,37
29,model,OpenFold,Columbia,OpenFold is an open source recreation of AlphaFold2.,2022-11-20,https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2,,Evaluated on wide range of tasks using own evaluation benchmarks.,AlphaFold2,,open,CC BY 4.0,,,,,,unknown,"50,000 GPU hours",Single A100 NVIDIA GPU,,,,,,,22,amino acid sequence,protein structure,38
29,model,OpenFold,Columbia,OpenFold is an open source recreation of AlphaFold2.,2022-11-20,https://www.biorxiv.org/content/10.1101/2022.11.20.517210v2,,Evaluated on wide range of tasks using own evaluation benchmarks.,OpenProteinSet,,open,CC BY 4.0,,,,,,unknown,"50,000 GPU hours",Single A100 NVIDIA GPU,,,,,,,22,amino acid sequence,protein structure,39
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,CLIP,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,image,image,40
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,Vicuna,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,image,image,41
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,CLIP,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,image,text,42
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,Vicuna,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,image,text,43
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,CLIP,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,text,image,44
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,Vicuna,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,text,image,45
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,CLIP,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,text,text,46
30,model,Ferret,"Columbia, Apple AI",Ferret is a Multimodal Large Language Model (MLLM) capable of understanding spatial referring of any shape or granularity within an image and accurately grounding open-vocabulary descriptions.,2023-10-11,https://arxiv.org/pdf/2310.07704.pdf,13B parameters,Evaluated on the object hallucination benchmark and compared to GPT-4V.,Vicuna,,open,Apple,,,,,,unknown,2.5 to 5 days,8 A100 GPUs,,,,,,,23,text,text,47
31,model,Guanaco,University of Washington,"Guanaco is a model family trained with QLORA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance.",2023-05-23,https://arxiv.org/pdf/2305.14314v1.pdf,33B parameters (dense),Reports results on the Vicuna benchmark and compares performance level and time expenditure with ChatGPT,QLoRA,,open,MIT,,,,,,,,A single 24 GB GPU,,,,,,,24,text,text,48
31,model,Guanaco,University of Washington,"Guanaco is a model family trained with QLORA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance.",2023-05-23,https://arxiv.org/pdf/2305.14314v1.pdf,33B parameters (dense),Reports results on the Vicuna benchmark and compares performance level and time expenditure with ChatGPT,OASST1,,open,MIT,,,,,,,,A single 24 GB GPU,,,,,,,24,text,text,49
32,model,Llark,"University of Washington, Spotify",Llark is an instruction-tuned multimodal model for music understanding.,2023-10-11,https://arxiv.org/pdf/2310.07160.pdf,12B parameters (dense),Evaluated on benchmark music understanding tasks on SOTA music datasets.,LLaMA 2,,open,Apache 2.0,,,,,,unknown,54 hours,4 80GB NVIDIA A40 GPUs,,,,,,,25,audio,text,50
32,model,Llark,"University of Washington, Spotify",Llark is an instruction-tuned multimodal model for music understanding.,2023-10-11,https://arxiv.org/pdf/2310.07160.pdf,12B parameters (dense),Evaluated on benchmark music understanding tasks on SOTA music datasets.,Jukebox,,open,Apache 2.0,,,,,,unknown,54 hours,4 80GB NVIDIA A40 GPUs,,,,,,,25,audio,text,51
32,model,Llark,"University of Washington, Spotify",Llark is an instruction-tuned multimodal model for music understanding.,2023-10-11,https://arxiv.org/pdf/2310.07160.pdf,12B parameters (dense),Evaluated on benchmark music understanding tasks on SOTA music datasets.,LLaMA 2,,open,Apache 2.0,,,,,,unknown,54 hours,4 80GB NVIDIA A40 GPUs,,,,,,,25,text,text,52
32,model,Llark,"University of Washington, Spotify",Llark is an instruction-tuned multimodal model for music understanding.,2023-10-11,https://arxiv.org/pdf/2310.07160.pdf,12B parameters (dense),Evaluated on benchmark music understanding tasks on SOTA music datasets.,Jukebox,,open,Apache 2.0,,,,,,unknown,54 hours,4 80GB NVIDIA A40 GPUs,,,,,,,25,text,text,53
33,model,InternLM,InternLM,"InternLM is an LLM pre-trained on over 2.3T Tokens containing high-quality English, Chinese, and code data.",2023-09-20,https://github.com/InternLM/InternLM,7B parameters (dense),Evaluated on the dimensions proposed by OpenCompass in comparison to other LLMs.,,,open,Apache 2.0,,,unknown,https://huggingface.co/internlm/internlm-20b/discussions,https://huggingface.co/internlm/internlm-20b,unknown,unknown,unknown,,,,,,,26,text,text,54
34,model,BioMistral,"Avignon University, Nantes University","BioMistral is an open-source Large Language Model tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central.",2024-02-15,https://arxiv.org/pdf/2402.10373.pdf,7B parameters (dense),BioMistral was evaluated on a benchmark comprising 10 established medical question-answering (QA) tasks in English and seven other languages.,Mistral,,open,Apache 2.0,"Research in the biomedical domain, especially for medical question-answering tasks.",Prohibited from deploying in production environments for natural language generation or any professional health and medical purposes.,,https://huggingface.co/BioMistral/BioMistral-7B/discussions,https://huggingface.co/BioMistral/BioMistral-7B,unknown,unknown,32 NVIDIA A100 80GB GPUs,,,,,,,27,text,text,55
34,model,BioMistral,"Avignon University, Nantes University","BioMistral is an open-source Large Language Model tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central.",2024-02-15,https://arxiv.org/pdf/2402.10373.pdf,7B parameters (dense),BioMistral was evaluated on a benchmark comprising 10 established medical question-answering (QA) tasks in English and seven other languages.,PubMed Central,,open,Apache 2.0,"Research in the biomedical domain, especially for medical question-answering tasks.",Prohibited from deploying in production environments for natural language generation or any professional health and medical purposes.,,https://huggingface.co/BioMistral/BioMistral-7B/discussions,https://huggingface.co/BioMistral/BioMistral-7B,unknown,unknown,32 NVIDIA A100 80GB GPUs,,,,,,,27,text,text,56
35,application,Khanmigo,Khan Academy,An AI-powered assistant that functions as both a virtual tutor for students and a classroom assistant for teachers.,2023-03-14,https://www.khanacademy.org/khan-labs#khanmigo,,,GPT-4 API,,limited,unknown,,,,,,,,,,,,,,,28,nan,nan,57
36,model,GAIA-1,Wayve,"GAIA-1 (‘Generative AI for Autonomy’) is a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features.",2023-09-29,https://arxiv.org/pdf/2309.17080.pdf,9B parameters (dense),Compared to self before being scaled on quality of video generation.,,,closed,unknown,"The main use cases are pure representation learning, planning (look-ahead search), or learning a policy in the world model (neural simulator)",,,,,unknown,4 days,32 A100 80GB GPUs,,,,,,,29,text,video,58
36,model,GAIA-1,Wayve,"GAIA-1 (‘Generative AI for Autonomy’) is a generative world model that leverages video, text, and action inputs to generate realistic driving scenarios while offering fine-grained control over ego-vehicle behavior and scene features.",2023-09-29,https://arxiv.org/pdf/2309.17080.pdf,9B parameters (dense),Compared to self before being scaled on quality of video generation.,,,closed,unknown,"The main use cases are pure representation learning, planning (look-ahead search), or learning a policy in the world model (neural simulator)",,,,,unknown,4 days,32 A100 80GB GPUs,,,,,,,29,video,video,59
37,model,GreenBit LLaMA,GreenBit AI,GreenBit LLaMA is a series of fine-tuned LLaMA models.,2023-09-29,https://github.com/GreenBitAI/low_bit_llama,30B parameters (dense),Evaluated on common LLM benchmarks.,LLaMA,,open,Apache 2.0,,,unknown,https://huggingface.co/GreenBitAI/LLaMA-30B-2bit-groupsize8/discussions,https://huggingface.co/GreenBitAI/LLaMA-30B-2bit-groupsize8,unknown,unknown,unknown,,,,,,,30,text,text,60
38,model,Ocean-1,Cresta,Ocean-1 is the culmination of Cresta's experience in deploying generative AI systems for large enterprises and signifies their latest milestone in advancing the cutting edge AI technology for customer facing conversations.,2023-06-20,https://cresta.com/blog/introducing-ocean-1-worlds-first-contact-center-foundation-model/,7B parameters (dense),Outperforms GPT-4 in common sense and reasoning tasks on the basis of both efficiency and accuracy.,GPT-4,,closed,unknown,Acting as a contact center chatbot agent.,,unknown,,,unknown,unknown,unknown,,,,,,,31,text,text,61
38,model,Ocean-1,Cresta,Ocean-1 is the culmination of Cresta's experience in deploying generative AI systems for large enterprises and signifies their latest milestone in advancing the cutting edge AI technology for customer facing conversations.,2023-06-20,https://cresta.com/blog/introducing-ocean-1-worlds-first-contact-center-foundation-model/,7B parameters (dense),Outperforms GPT-4 in common sense and reasoning tasks on the basis of both efficiency and accuracy.,Claude,,closed,unknown,Acting as a contact center chatbot agent.,,unknown,,,unknown,unknown,unknown,,,,,,,31,text,text,62
38,model,Ocean-1,Cresta,Ocean-1 is the culmination of Cresta's experience in deploying generative AI systems for large enterprises and signifies their latest milestone in advancing the cutting edge AI technology for customer facing conversations.,2023-06-20,https://cresta.com/blog/introducing-ocean-1-worlds-first-contact-center-foundation-model/,7B parameters (dense),Outperforms GPT-4 in common sense and reasoning tasks on the basis of both efficiency and accuracy.,Falcon-40B,,closed,unknown,Acting as a contact center chatbot agent.,,unknown,,,unknown,unknown,unknown,,,,,,,31,text,text,63
39,model,Aurora-M,"Tokyo Institute of Technology, MIT-IBM Watson Lab, Sapienza University of Rome","Aurora-M is a 15B parameter multilingual open-source model trained on English, Finnish, Hindi, Japanese, Vietnamese, and code.",2024-04-23,https://arxiv.org/pdf/2404.00399,15B parameters,"Evaluated on all language datasets compared to similarly sized SOTA models, with Aurora-M achieving strong performance in most.",StarCoderPlus,,open,unknown,,,unknown,,,unknown,48 days,"LUMI supercomputer, using 128 AMD MI250X GPUs",,,,,,,32,text,text,64
40,model,CodeParrot,HuggingFace,CodeParrot is an autoregressive language model trained on code,2021-12-06,https://twitter.com/lvwerra/status/1467933794699259908,1B parameters (dense),,,,open,,,,,,,unknown,unknown,16 x A100 (40GB),,,,,,,33,text,code,65
40,model,CodeParrot,HuggingFace,CodeParrot is an autoregressive language model trained on code,2021-12-06,https://twitter.com/lvwerra/status/1467933794699259908,1B parameters (dense),,,,open,,,,,,,unknown,unknown,16 x A100 (40GB),,,,,,,33,text,text,66
41,model,Zephyr,HuggingFace,Zephyr is a series of language models that are trained to act as helpful assistants.,2023-10-11,https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha,7B parameters (dense),"Evaluated on loss, rewards, logps, and logits rejected and chosen.",Mistral,,open,MIT,Educational and research purposes,,,https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha/discussions,https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha,unknown,unknown,unknown,,,,,,,34,text,text,67
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,OBELICS,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,image,text,68
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,Wikipedia,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,image,text,69
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,LAION-5B,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,image,text,70
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,PMD,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,image,text,71
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,OBELICS,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,text,text,72
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,Wikipedia,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,text,text,73
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,LAION-5B,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,text,text,74
42,model,IDEFICS,HuggingFace,"IDEFICS is an open-access visual language model, based on Flamingo.",2023-08-22,https://huggingface.co/blog/idefics,80B parameters (dense),Evaluated in comparison to Flamingo and OpenFlamingo on standard benchmarks.,PMD,,open,custom,Educational and research purposes,,,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct/discussions,https://huggingface.co/HuggingFaceM4/idefics-80b-instruct,unknown,unknown,unknown,,,,,,,35,text,text,75
44,model,FinGPT,"University of Turku, HuggingFace, National Library of Finland",FinGPT is a series of Finnish LLMs trained from scratch.,2023-11-03,https://arxiv.org/pdf/2311.05640.pdf,13B parameters (dense),"Evaluated on in-house benchmark, FIN-bench, adapted from BIG-bench for Finnish.",,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/TurkuNLP/gpt3-finnish-13B/discussions,https://huggingface.co/TurkuNLP/gpt3-finnish-13B,unknown,unknown,"192 nodes, each consisting of 4 AMD Instinct MI250X GPUs, a single 64-core AMD Trento CPU and 512GB of memory.",,,,,,,36,text,text,76
45,model,BLUUMI,"University of Turku, HuggingFace, National Library of Finland",BLUUMI is a multilingual fine-tuned version of BLOOM.,2023-11-03,https://arxiv.org/pdf/2311.05640.pdf,176B parameters (dense),"Evaluated on in-house benchmark, FIN-bench, adapted from BIG-bench for Finnish.",BLOOM,unknown,open,BigScience RAIL v1.0,,,unknown,https://huggingface.co/TurkuNLP/bloom-finnish-176b/discussions,https://huggingface.co/TurkuNLP/bloom-finnish-176b,unknown,unknown,"192 nodes, each consisting of 4 AMD Instinct MI250X GPUs, a single 64-core AMD Trento CPU and 512GB of memory.",,,,,,,37,text,text,77
47,model,Idefics2,Hugging Face,"Idefics2 is a general multimodal model that takes as input arbitrary sequences of text and images, generating text responses. It has the capability to describe visual content, answer questions about images, perform basic arithmetic operations, create stories grounded in multiple images, and extract information from documents.",2024-04-15,https://huggingface.co/blog/idefics2,8B parameters,The performance of Idefics2 has been evaluated on numerous benchmarks. It is top of its class size and competes with much larger models such as LLava-Next-34B and MM1-30B-chat.,The Cauldron,"The quality of the model has been ensured by training it on a mixture of openly available datasets and enhancing its OCR capabilities. Further improvements include manipulating images in their native resolutions and aspect ratios, better pre-trained backbones, and allowing for sub-image splitting.",open,Apache 2.0,"The model can be used for answering questions about images, describing visual content, creating stories grounded in multiple images, extracting information from documents, and performing basic arithmetic operations.",unknown,unknown,https://huggingface.co/HuggingFaceM4/idefics2-8b/discussions,https://huggingface.co/HuggingFaceM4/idefics2-8b,unknown,unknown,unknown,,,,,,,38,image,text,78
47,model,Idefics2,Hugging Face,"Idefics2 is a general multimodal model that takes as input arbitrary sequences of text and images, generating text responses. It has the capability to describe visual content, answer questions about images, perform basic arithmetic operations, create stories grounded in multiple images, and extract information from documents.",2024-04-15,https://huggingface.co/blog/idefics2,8B parameters,The performance of Idefics2 has been evaluated on numerous benchmarks. It is top of its class size and competes with much larger models such as LLava-Next-34B and MM1-30B-chat.,The Cauldron,"The quality of the model has been ensured by training it on a mixture of openly available datasets and enhancing its OCR capabilities. Further improvements include manipulating images in their native resolutions and aspect ratios, better pre-trained backbones, and allowing for sub-image splitting.",open,Apache 2.0,"The model can be used for answering questions about images, describing visual content, creating stories grounded in multiple images, extracting information from documents, and performing basic arithmetic operations.",unknown,unknown,https://huggingface.co/HuggingFaceM4/idefics2-8b/discussions,https://huggingface.co/HuggingFaceM4/idefics2-8b,unknown,unknown,unknown,,,,,,,38,text,text,79
49,model,DeepFloyd IF,Stability AI,A text-to-image cascaded pixel diffusion model released in conjunction with AI research lab DeepFloyd.,2023-04-28,https://stability.ai/blog/deepfloyd-if-text-to-image-model,4.3B parameters (dense),Evaluated on the COCO dataset.,LAION-5B,,open,custom,,,,https://huggingface.co/DeepFloyd/IF-I-XL-v1.0/discussions,https://huggingface.co/DeepFloyd/IF-I-XL-v1.0,,,,,,,,,,39,text,image,80
50,model,StableLM,Stability AI,Large language models trained on up to 1.5 trillion tokens.,2023-04-20,https://github.com/Stability-AI/StableLM,7B parameters (dense),,StableLM-Alpha dataset,,open,Apache 2.0,,,,,,,,,,,,,,,40,text,text,81
50,model,StableLM,Stability AI,Large language models trained on up to 1.5 trillion tokens.,2023-04-20,https://github.com/Stability-AI/StableLM,7B parameters (dense),,Alpaca dataset,,open,Apache 2.0,,,,,,,,,,,,,,,40,text,text,82
50,model,StableLM,Stability AI,Large language models trained on up to 1.5 trillion tokens.,2023-04-20,https://github.com/Stability-AI/StableLM,7B parameters (dense),,gpt4all dataset,,open,Apache 2.0,,,,,,,,,,,,,,,40,text,text,83
50,model,StableLM,Stability AI,Large language models trained on up to 1.5 trillion tokens.,2023-04-20,https://github.com/Stability-AI/StableLM,7B parameters (dense),,ShareGPT52K dataset,,open,Apache 2.0,,,,,,,,,,,,,,,40,text,text,84
50,model,StableLM,Stability AI,Large language models trained on up to 1.5 trillion tokens.,2023-04-20,https://github.com/Stability-AI/StableLM,7B parameters (dense),,Dolly dataset,,open,Apache 2.0,,,,,,,,,,,,,,,40,text,text,85
50,model,StableLM,Stability AI,Large language models trained on up to 1.5 trillion tokens.,2023-04-20,https://github.com/Stability-AI/StableLM,7B parameters (dense),,HH dataset,,open,Apache 2.0,,,,,,,,,,,,,,,40,text,text,86
51,application,Stable Diffusion,Stability AI,Stable Diffusion is a generative software that creates images from text prompts.,2022-08-22,https://stability.ai/blog/stable-diffusion-public-release,,,,,open,custom,,,,https://huggingface.co/CompVis/stable-diffusion/discussions,,,,,,image,,,,,41,nan,nan,87
52,application,Stable Diffusion XL,Stability AI,"Stable Diffusion XL is an updated version of Stable Diffusion, and creates descriptive images with shorter prompts and generate words within images.",2023-07-26,https://stability.ai/stablediffusion,,,,,open,Open Rail++,,,,,,,,,,image,,,,,42,nan,nan,88
53,model,Stable Video Diffusion,Stability AI,Stable Video Diffusion is a latent diffusion model trained to generate short video clips from an image conditioning.,2023-11-21,https://static1.squarespace.com/static/6213c340453c3f502425776e/t/655ce779b9d47d342a93c890/1700587395994/stable_video_diffusion.pdf,unknown,Evaluated via a user study comparing preferences between Stable Video Diffusion and competing text-to-video models.,Large Video Dataset,,limited,custom,Intended for research purposes only.,Using the model to generate representations of real-world people or events.,,https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt/discussions,https://huggingface.co/stabilityai/stable-video-diffusion-img2vid-xt,unknown,unknown,unknown,,,,,,,43,text,video,89
55,application,Sky Replacer,Stability AI,Sky Replacer is an exciting new tool that allows users to replace the color and aesthetic of the sky in their original photos with a selection of nine alternatives to improve the overall look and feel of the image.,2023-11-01,https://clipdrop.co/real-estate/sky-replacer,,,,,open,unknown,,,,,,,,,,image,https://stability.ai/terms-of-use,,,,44,nan,nan,90
56,model,StableLM 2,Stability AI,"StableLM 2 is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",2024-01-19,https://stability.ai/news/introducing-stable-lm-2,1.6B parameters (dense),Evaluated on standard LLM benchmarks and in multilingual tasks compared to similarly sized open-source models.,RedPajama-Data,,open,custom,The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.,,unknown,https://huggingface.co/stabilityai/stablelm-2-1_6b/discussions,https://huggingface.co/stabilityai/stablelm-2-1_6b,11 tCO2eq,92k GPU hours,512 NVIDIA A100 40GB GPUs,,,,,,,45,text,text,91
56,model,StableLM 2,Stability AI,"StableLM 2 is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",2024-01-19,https://stability.ai/news/introducing-stable-lm-2,1.6B parameters (dense),Evaluated on standard LLM benchmarks and in multilingual tasks compared to similarly sized open-source models.,The Pile,,open,custom,The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.,,unknown,https://huggingface.co/stabilityai/stablelm-2-1_6b/discussions,https://huggingface.co/stabilityai/stablelm-2-1_6b,11 tCO2eq,92k GPU hours,512 NVIDIA A100 40GB GPUs,,,,,,,45,text,text,92
56,model,StableLM 2,Stability AI,"StableLM 2 is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",2024-01-19,https://stability.ai/news/introducing-stable-lm-2,1.6B parameters (dense),Evaluated on standard LLM benchmarks and in multilingual tasks compared to similarly sized open-source models.,RefinedWeb,,open,custom,The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.,,unknown,https://huggingface.co/stabilityai/stablelm-2-1_6b/discussions,https://huggingface.co/stabilityai/stablelm-2-1_6b,11 tCO2eq,92k GPU hours,512 NVIDIA A100 40GB GPUs,,,,,,,45,text,text,93
56,model,StableLM 2,Stability AI,"StableLM 2 is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",2024-01-19,https://stability.ai/news/introducing-stable-lm-2,1.6B parameters (dense),Evaluated on standard LLM benchmarks and in multilingual tasks compared to similarly sized open-source models.,The Stack,,open,custom,The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.,,unknown,https://huggingface.co/stabilityai/stablelm-2-1_6b/discussions,https://huggingface.co/stabilityai/stablelm-2-1_6b,11 tCO2eq,92k GPU hours,512 NVIDIA A100 40GB GPUs,,,,,,,45,text,text,94
56,model,StableLM 2,Stability AI,"StableLM 2 is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",2024-01-19,https://stability.ai/news/introducing-stable-lm-2,1.6B parameters (dense),Evaluated on standard LLM benchmarks and in multilingual tasks compared to similarly sized open-source models.,OpenWebText,,open,custom,The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.,,unknown,https://huggingface.co/stabilityai/stablelm-2-1_6b/discussions,https://huggingface.co/stabilityai/stablelm-2-1_6b,11 tCO2eq,92k GPU hours,512 NVIDIA A100 40GB GPUs,,,,,,,45,text,text,95
56,model,StableLM 2,Stability AI,"StableLM 2 is a state-of-the-art 1.6 billion parameter small language model trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch.",2024-01-19,https://stability.ai/news/introducing-stable-lm-2,1.6B parameters (dense),Evaluated on standard LLM benchmarks and in multilingual tasks compared to similarly sized open-source models.,OpenWebMath,,open,custom,The model is intended to be used as a foundational base model for application-specific fine-tuning. Developers must evaluate and fine-tune the model for safe performance in downstream applications.,,unknown,https://huggingface.co/stabilityai/stablelm-2-1_6b/discussions,https://huggingface.co/stabilityai/stablelm-2-1_6b,11 tCO2eq,92k GPU hours,512 NVIDIA A100 40GB GPUs,,,,,,,45,text,text,96
57,model,Stable Cascade,Stability AI,"Stable Cascade is built upon the Würstchen architecture and its main difference to other models, like Stable Diffusion, is that it is working at a much smaller latent space.",2024-01-16,https://huggingface.co/stabilityai/stable-cascade,unknown,Evaluated on image generation benchmarks in comparison to equal and smaller-sized models.,,,open,custom,The model is intended for research purposes for now.,"The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model. The model should not be used in any way that violates Stability AI's Acceptable Use Policy.",unknown,https://huggingface.co/stabilityai/stable-cascade/discussions,https://huggingface.co/stabilityai/stable-cascade,"2,276 kgCO2eq","24,602 A100 GPU hours",Some number of A100 GPUs,,,,,,,46,text,image,97
58,model,Stable Video 3D,Stability AI,"Stable Video 3D (SV3D) is a generative model based on Stable Video Diffusion that takes in a still image of an object as a conditioning frame, and generates an orbital video of that object.",2024-03-18,https://stability.ai/news/introducing-stable-video-3d,unknown,unknown,Objaverse,unknown,open,StabilityAI Non-Commercial Research Community License,This model is intended to be used for generating orbital videos of objects from still images.,"The model should not be used for generating factual or true representations of people or events, or in any way that violates Stability AIs Acceptable Use Policy.",unknown,https://huggingface.co/stabilityai/sv3d/discussions,https://huggingface.co/stabilityai/sv3d,unknown,unknown,unknown,,,,,,,47,image,video,98
59,model,Stable Audio 2.0,Stability AI,"Stable Audio 2.0 sets a new standard in AI-generated audio, producing high-quality, full tracks with coherent musical structure up to three minutes in length at 44.1kHz stereo.",2024-04-03,https://stability-ai.squarespace.com/news/stable-audio-2-0,unknown,,AudioSparx,"To protect creator copyrights, for audio uploads, Stability AI partners with Audible Magic to use their content recognition (ACR) technology to power real-time content matching and prevent copyright infringement. Opt-out requests were honored during the training phase.",open,unknown,"It can be used to generate melodies, backing tracks, stems, and sound effects.",Uploading copyrighted material for transformation.,Advanced content recognition is used to maintain compliance and prevent copyright infringement.,,,unknown,unknown,unknown,,,,,,,48,audio,audio,99
59,model,Stable Audio 2.0,Stability AI,"Stable Audio 2.0 sets a new standard in AI-generated audio, producing high-quality, full tracks with coherent musical structure up to three minutes in length at 44.1kHz stereo.",2024-04-03,https://stability-ai.squarespace.com/news/stable-audio-2-0,unknown,,AudioSparx,"To protect creator copyrights, for audio uploads, Stability AI partners with Audible Magic to use their content recognition (ACR) technology to power real-time content matching and prevent copyright infringement. Opt-out requests were honored during the training phase.",open,unknown,"It can be used to generate melodies, backing tracks, stems, and sound effects.",Uploading copyrighted material for transformation.,Advanced content recognition is used to maintain compliance and prevent copyright infringement.,,,unknown,unknown,unknown,,,,,,,48,text,audio,100
60,model,Reka Flash,Reka,"Reka Flash is a multimodal, multilingual, state-of-the-art 21B model trained entirely from scratch.",2024-02-12,https://reka.ai/reka-flash-an-efficient-and-capable-multimodal-language-model/,21B parameters (dense),"Evaluated on MMLU, GSM8K, HumanEval, and GPQA benchmarks, among others.",,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,49,image,text,101
60,model,Reka Flash,Reka,"Reka Flash is a multimodal, multilingual, state-of-the-art 21B model trained entirely from scratch.",2024-02-12,https://reka.ai/reka-flash-an-efficient-and-capable-multimodal-language-model/,21B parameters (dense),"Evaluated on MMLU, GSM8K, HumanEval, and GPQA benchmarks, among others.",,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,49,text,text,102
60,model,Reka Flash,Reka,"Reka Flash is a multimodal, multilingual, state-of-the-art 21B model trained entirely from scratch.",2024-02-12,https://reka.ai/reka-flash-an-efficient-and-capable-multimodal-language-model/,21B parameters (dense),"Evaluated on MMLU, GSM8K, HumanEval, and GPQA benchmarks, among others.",,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,49,video,text,103
61,model,Reka Core,Reka,"Reka Core is a frontier-class multimodal language model comparable to industry leaders. It has powerful capabilities including multimodal understanding (including images, videos, and audio), superb reasoning abilities, code generation, and multilinguality with proficiency in 32 languages.",2024-04-15,https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model,unknown,"Reka Core was evaluated against leading models such as OpenAIs GPT-4, Claude-3 Opus, and Gemini Ultra on a variety of tasks and metrics including multimodal and human evaluation conducted by a third party. It was found to be competitive or even surpassing these models.",,,limited,unknown,"Reka Core can be used in e-commerce, social media, digital content and video games, healthcare, robotics, and other industries for tasks that require multimodal understanding, coding, complex reasoning, and more.",unknown,unknown,unknown,,unknown,few months,thousands of GPUs,,,,,,,50,audio,text,104
61,model,Reka Core,Reka,"Reka Core is a frontier-class multimodal language model comparable to industry leaders. It has powerful capabilities including multimodal understanding (including images, videos, and audio), superb reasoning abilities, code generation, and multilinguality with proficiency in 32 languages.",2024-04-15,https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model,unknown,"Reka Core was evaluated against leading models such as OpenAIs GPT-4, Claude-3 Opus, and Gemini Ultra on a variety of tasks and metrics including multimodal and human evaluation conducted by a third party. It was found to be competitive or even surpassing these models.",,,limited,unknown,"Reka Core can be used in e-commerce, social media, digital content and video games, healthcare, robotics, and other industries for tasks that require multimodal understanding, coding, complex reasoning, and more.",unknown,unknown,unknown,,unknown,few months,thousands of GPUs,,,,,,,50,image,text,105
61,model,Reka Core,Reka,"Reka Core is a frontier-class multimodal language model comparable to industry leaders. It has powerful capabilities including multimodal understanding (including images, videos, and audio), superb reasoning abilities, code generation, and multilinguality with proficiency in 32 languages.",2024-04-15,https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model,unknown,"Reka Core was evaluated against leading models such as OpenAIs GPT-4, Claude-3 Opus, and Gemini Ultra on a variety of tasks and metrics including multimodal and human evaluation conducted by a third party. It was found to be competitive or even surpassing these models.",,,limited,unknown,"Reka Core can be used in e-commerce, social media, digital content and video games, healthcare, robotics, and other industries for tasks that require multimodal understanding, coding, complex reasoning, and more.",unknown,unknown,unknown,,unknown,few months,thousands of GPUs,,,,,,,50,text,text,106
61,model,Reka Core,Reka,"Reka Core is a frontier-class multimodal language model comparable to industry leaders. It has powerful capabilities including multimodal understanding (including images, videos, and audio), superb reasoning abilities, code generation, and multilinguality with proficiency in 32 languages.",2024-04-15,https://www.reka.ai/news/reka-core-our-frontier-class-multimodal-language-model,unknown,"Reka Core was evaluated against leading models such as OpenAIs GPT-4, Claude-3 Opus, and Gemini Ultra on a variety of tasks and metrics including multimodal and human evaluation conducted by a third party. It was found to be competitive or even surpassing these models.",,,limited,unknown,"Reka Core can be used in e-commerce, social media, digital content and video games, healthcare, robotics, and other industries for tasks that require multimodal understanding, coding, complex reasoning, and more.",unknown,unknown,unknown,,unknown,few months,thousands of GPUs,,,,,,,50,video,text,107
62,model,FuseChat,FuseAI,FuseChat is a powerful chat Language Learning Model (LLM) that integrates multiple structure and scale-varied chat LLMs using a fuse-then-merge strategy. The fusion is done using two stages,2024-02-26,https://arxiv.org/abs/2402.16107,7B parameters,"The FuseChat model was evaluated on MT-Bench which comprises 80 multi-turn dialogues spanning writing, roleplay, reasoning, math, coding, stem, and humanities domains. It yields an average performance of 66.52 with specific scores for individual domains available in the leaderboard results.",Nous Hermes 2,,open,Apache 2.0,"FuseChat is intended to be used as a powerful chat bot that takes in text inputs and provides text-based responses. It can be utilized in a variety of domains including writing, roleplay, reasoning, math, coding, stem, and humanities.",unknown,unknown,https://huggingface.co/FuseAI/FuseChat-7B-VaRM/discussions,https://huggingface.co/FuseAI/FuseChat-7B-VaRM,unknown,unknown,unknown,,,,,,,51,text,text,108
62,model,FuseChat,FuseAI,FuseChat is a powerful chat Language Learning Model (LLM) that integrates multiple structure and scale-varied chat LLMs using a fuse-then-merge strategy. The fusion is done using two stages,2024-02-26,https://arxiv.org/abs/2402.16107,7B parameters,"The FuseChat model was evaluated on MT-Bench which comprises 80 multi-turn dialogues spanning writing, roleplay, reasoning, math, coding, stem, and humanities domains. It yields an average performance of 66.52 with specific scores for individual domains available in the leaderboard results.",OpenChat 3.5,,open,Apache 2.0,"FuseChat is intended to be used as a powerful chat bot that takes in text inputs and provides text-based responses. It can be utilized in a variety of domains including writing, roleplay, reasoning, math, coding, stem, and humanities.",unknown,unknown,https://huggingface.co/FuseAI/FuseChat-7B-VaRM/discussions,https://huggingface.co/FuseAI/FuseChat-7B-VaRM,unknown,unknown,unknown,,,,,,,51,text,text,109
63,model,MoMo,Moreh,MoMo is a large language model fine-tuned from Qwen.,2024-01-16,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO,72B parameters (dense),unknown,Qwen,unknown,open,MIT,,,unknown,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO/discussions,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO,unknown,unknown,AMD’s MI250 GPU,,,,,,,52,text,text,110
63,model,MoMo,Moreh,MoMo is a large language model fine-tuned from Qwen.,2024-01-16,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO,72B parameters (dense),unknown,OpenOrca,unknown,open,MIT,,,unknown,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO/discussions,https://huggingface.co/moreh/MoMo-72B-lora-1.8.7-DPO,unknown,unknown,AMD’s MI250 GPU,,,,,,,52,text,text,111
64,model,Mistral,Mistral AI,Mistral is a compact language model.,2023-09-27,https://mistral.ai/news/announcing-mistral-7b/,7.3B parameters (dense),Evaluated in comparison to LLaMA series models on standard language benchmarks.,,,open,Apache 2.0,,,,https://huggingface.co/mistralai/Mistral-7B-v0.1/discussions,https://huggingface.co/mistralai/Mistral-7B-v0.1,unknown,unknown,unknown,,,,,,,53,text,text,112
65,model,Mistral Large,Mistral AI,Mistral Large is Mistral AI’s new cutting-edge text generation model.,2024-02-26,https://mistral.ai/news/mistral-large/,unknown,Evaluated on commonly used benchmarks in comparison to the current LLM leaders.,,,limited,unknown,,,,,,unknown,unknown,unknown,,,,,,,54,text,text,113
66,application,Le Chat,Mistral AI,Le Chat is a first demonstration of what can be built with Mistral models and what can deployed in the business environment.,2024-02-26,https://mistral.ai/news/le-chat-mistral/,,,Mistral,,limited,unknown,,,,,,,,,,,https://mistral.ai/terms/#terms-of-use,unknown,unknown,unknown,55,nan,nan,114
66,application,Le Chat,Mistral AI,Le Chat is a first demonstration of what can be built with Mistral models and what can deployed in the business environment.,2024-02-26,https://mistral.ai/news/le-chat-mistral/,,,Mistral Large,,limited,unknown,,,,,,,,,,,https://mistral.ai/terms/#terms-of-use,unknown,unknown,unknown,55,nan,nan,115
67,application,Reexpress One,Reexpress AI,"Reexpress One offers a means of document classification, semantic search, and uncertainty analysis on-device.",2023-03-21,https://re.express/index.html,,,,,limited,unknown,,,unknown,https://github.com/ReexpressAI/support,,,,,,data analyses,hhttps://re.express/tos.html,unknown,unknown,unknown,56,nan,nan,116
68,model,Dolphin 2.2 Yi,Cognitive Computations,Dolphin 2.2 Yi is an LLM based off Yi.,2023-11-14,https://erichartford.com/dolphin,34B parameters (dense),,Dolphin,,open,custom,,,unknown,https://huggingface.co/cognitivecomputations/dolphin-2_2-yi-34b/discussions,https://huggingface.co/cognitivecomputations/dolphin-2_2-yi-34b,unknown,3 days,4 A100 GPUs,,,,,,,57,text,text,117
68,model,Dolphin 2.2 Yi,Cognitive Computations,Dolphin 2.2 Yi is an LLM based off Yi.,2023-11-14,https://erichartford.com/dolphin,34B parameters (dense),,Yi,,open,custom,,,unknown,https://huggingface.co/cognitivecomputations/dolphin-2_2-yi-34b/discussions,https://huggingface.co/cognitivecomputations/dolphin-2_2-yi-34b,unknown,3 days,4 A100 GPUs,,,,,,,57,text,text,118
69,model,WizardLM Uncensored,Cognitive Computations,WizardLM Uncensored is WizardLM trained with a subset of the dataset - responses that contained alignment / moralizing were removed.,2023-06-01,https://huggingface.co/cognitivecomputations/WizardLM-30B-Uncensored,30B parameters (dense),Evaluated on OpenLLM leaderboard.,WizardLM,,open,unknown,,,unknown,https://huggingface.co/cognitivecomputations/WizardLM-30B-Uncensored/discussions,https://huggingface.co/cognitivecomputations/WizardLM-30B-Uncensored,unknown,unknown,unknown,,,,,,,58,text,text,119
70,application,DuckAssist,DuckDuckGo,The first Instant Answer in DuckDuckGo search results to use natural language technology to generate answers to search queries using Wikipedia and other related sources,2023-03-08,https://spreadprivacy.com/duckassist-launch/,,,Anthropic API,,open,unknown,,,,,,,,,,,,,,,59,nan,nan,120
71,application,Perplexity Ask,Perplexity,Perplexity Ask is a new search interface that uses advanced artificial intelligence technologies,2022-12-07,https://www.perplexity.ai/,,,GPT-3.5,,open,,,,,,,,,,,,,,,,60,nan,nan,121
71,application,Perplexity Ask,Perplexity,Perplexity Ask is a new search interface that uses advanced artificial intelligence technologies,2022-12-07,https://www.perplexity.ai/,,,Bing Search,,open,,,,,,,,,,,,,,,,60,nan,nan,122
72,application,Bird SQL,Perplexity,Twitter search interface that is powered by Perplexity's structured search engine.,2022-12-15,https://www.perplexity.ai/sql,,,Perplexity Ask,,closed,,,,,,,,,,,,,,,,61,nan,nan,123
72,application,Bird SQL,Perplexity,Twitter search interface that is powered by Perplexity's structured search engine.,2022-12-15,https://www.perplexity.ai/sql,,,OpenAI API,,closed,,,,,,,,,,,,,,,,61,nan,nan,124
73,application,Perplexity Chat,Perplexity,Perplexity chat is an AI chatbot trained in-house by Perplexity.,2023-10-27,https://labs.perplexity.ai/,,,,,open,,,,,,,,,,,Chatbot output in response to user queries,https://blog.perplexity.ai/legal/terms-of-service,,,,62,nan,nan,125
74,model,Vulture,Virtual Interactive,Vulture is a further fine-tuned causal Decoder-only LLM built by Virtual Interactive (VILM) on top of Falcon.,2023-10-02,https://huggingface.co/vilm/vulture-180b,180B parameters (dense),,Falcon-180B,,open,Apache 2.0,,Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.,unknown,https://huggingface.co/vilm/vulture-180b/discussions,https://huggingface.co/vilm/vulture-180b,unknown,3000 A100 hours,unknown,,,,,,,63,text,text,126
75,model,DeciLM,Deci,DeciLM is a LLM that on release ranks as the fastest and most accurate model of its size.,2023-12-12,https://deci.ai/blog/introducing-decilm-7b-the-fastest-and-most-accurate-7b-large-language-model-to-date,7B parameters (dense),"Evaluated on the OpenLLM benchmarks and, on release, outperforms all other 7B models on the OpenLLM Leaderboard.",,,open,Apache 2.0,This model is intended for commercial and research use in English and can be fine-tuned for use in other languages.,,unknown,,https://deci.ai/model-zoo/decilm-7b/,unknown,unknown,NVIDIA A10 GPUs,,,,,,,64,text,text,127
77,model,GPT-J,EleutherAI,GPT-J is an open-source autoregressive language model.,2021-06-04,https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/,6B parameters (dense),,The Pile,,open,Apache 2.0,,,,,,,,TRC (Unspecified # of TPU v3-8s),,,,,,,65,text,text,128
78,model,GPT-Neo,EleutherAI,,2021-03-21,https://github.com/EleutherAI/gpt-neo,2.7B parameters (dense),,The Pile,,open,MIT,,,,,,,,,,,,,,,66,text,text,129
79,model,GPT-NeoX,EleutherAI,"GPT-NeoX (20B) is an open-sourced autoregressive language model.
",2022-02-02,http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf,20B parameters (dense),"The model was evaluated on standard NLP benchmarks: LAMBADA, ANLI, HellaSwag, MMLU among others [[Section 4]](http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf#section.4).
",The Pile,,open,Apache 2.0,"As stated in the model card: ""GPT-NeoX-20B learns an inner representation of the English language that can be used to extract features useful for downstream tasks. The model is best at what it was pretrained for however, which is generating text from a prompt. Due to the generality of the pretraining set, it has acquired the ability to generate completions across a wide range of tasks - from programming to fiction writing [[Model Card]](https://mystic.the-eye.eu/public/AI/models/GPT-NeoX-20B/20B_model_card.md).""
",,,"Feedback can be provided using the  # 20b channel in EleutherAI Discord group [[EleutherAI Blog Post]](https://blog.eleuther.ai/announcing-20b/). Find the Discord link in the FAQ page [[FAQ]](https://www.eleuther.ai/faq/).
",https://mystic.the-eye.eu/public/AI/models/GPT-NeoX-20B/20B_model_card.md,31.73 tCO2e,47.10 petaflop/s-day,12 x 8 A100 GPUs,,,,,,,67,text,text,130
79,model,GPT-NeoX,EleutherAI,"GPT-NeoX (20B) is an open-sourced autoregressive language model.
",2022-02-02,http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf,20B parameters (dense),"The model was evaluated on standard NLP benchmarks: LAMBADA, ANLI, HellaSwag, MMLU among others [[Section 4]](http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf#section.4).
",The Pile,,open,Apache 2.0,"As stated in the model card: ""GPT-NeoX-20B learns an inner representation of the English language that can be used to extract features useful for downstream tasks. The model is best at what it was pretrained for however, which is generating text from a prompt. Due to the generality of the pretraining set, it has acquired the ability to generate completions across a wide range of tasks - from programming to fiction writing [[Model Card]](https://mystic.the-eye.eu/public/AI/models/GPT-NeoX-20B/20B_model_card.md).""
",,,"Feedback can be provided using the  # 20b channel in EleutherAI Discord group [[EleutherAI Blog Post]](https://blog.eleuther.ai/announcing-20b/). Find the Discord link in the FAQ page [[FAQ]](https://www.eleuther.ai/faq/).
",https://mystic.the-eye.eu/public/AI/models/GPT-NeoX-20B/20B_model_card.md,31.73 tCO2e,47.10 petaflop/s-day,12 x 8 A100 GPUs,,,,,,,67,text,code,131
80,application,GooseAI API,GooseAI,"GooseAI API is an API service providing access to NLP services.
",,goose.ai,,,GPT-NeoX,unknown,limited,custom,"Intended to be used as an NLP infrastructure.
","Illegal or abusive activity, security violations, network abuse
",At will monitoring by the provider,Email support,,,,,unknown,"Text Generation, Text Completion",https://goose.ai/docs/tos,unknown,unknown,unknown,68,nan,nan,132
81,model,VQGAN-CLIP,EleutherAI,VQGAN-CLIP is a model that better generates and edits images using a multimodal encoder to guide image generation.,2022-09-04,https://arxiv.org/pdf/2204.08583.pdf,227M parameters (dense),"Evaluated by human testers rating alignment of text input, image output pairs.",VQGAN,,open,MIT,,,,,,unknown,Less than 1 V100-hour,1 NVIDIA Tesla K80 GPU,,,,,,,69,text,image,133
81,model,VQGAN-CLIP,EleutherAI,VQGAN-CLIP is a model that better generates and edits images using a multimodal encoder to guide image generation.,2022-09-04,https://arxiv.org/pdf/2204.08583.pdf,227M parameters (dense),"Evaluated by human testers rating alignment of text input, image output pairs.",CLIP,,open,MIT,,,,,,unknown,Less than 1 V100-hour,1 NVIDIA Tesla K80 GPU,,,,,,,69,text,image,134
82,model,Pythia,Eleuther AI,A suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters,2023-05-31,https://arxiv.org/pdf/2304.01373.pdf,12B parameters (dense),Evaluated on a variety of NLP benchmarks and found to perform similarly to OPT and BLOOM models.,The Pile,,open,Apache 2.0,,,,https://huggingface.co/EleutherAI/pythia-6.9b/discussions,https://huggingface.co/EleutherAI/pythia-12b,,,64 A100 GPUs,,,,,,,70,text,text,135
83,model,Llemma,"Princeton University, Eleuther AI",Llemma is a large language model for mathematics.,2023-10-16,https://arxiv.org/pdf/2310.10631.pdf,34B parameters (dense),Evaluated on math benchmarks in comparison to general large language models.,Proof Pile 2,,open,LLaMA 2,,,,https://huggingface.co/EleutherAI/llemma_34b/discussions,https://huggingface.co/EleutherAI/llemma_34b,unknown,47k A100 hours,256 A100 40GB GPUs,,,,,,,71,text,text,136
83,model,Llemma,"Princeton University, Eleuther AI",Llemma is a large language model for mathematics.,2023-10-16,https://arxiv.org/pdf/2310.10631.pdf,34B parameters (dense),Evaluated on math benchmarks in comparison to general large language models.,Code LLaMA,,open,LLaMA 2,,,,https://huggingface.co/EleutherAI/llemma_34b/discussions,https://huggingface.co/EleutherAI/llemma_34b,unknown,47k A100 hours,256 A100 40GB GPUs,,,,,,,71,text,text,137
85,model,Pile-T5,EleutherAI,"Pile-T5 is a version of the broadly used T5 model, but improved to eliminate weaknesses such as the omission of crucial code-related tokens. It utilizes LLaMA tokenizer and is trained on the Pile, offering enhancements for finetuning on downstream tasks, particularly those involving code.",2024-04-15,https://blog.eleuther.ai/pile-t5/,unknown,"The models were evaluated on SuperGLUE, CodeXGLUE, as well as MMLU and Bigbench Hard. Comparisons were made with T5v1.1 and found that Pile-T5 models performed better in most conditions.",The Pile,,open,unknown,The model is aimed at downstream tasks that benefit from the encoder-decoder architecture. Particularly useful for tasks involving code.,unknown,unknown,unknown,,unknown,2 million steps,unknown,,,,,,,72,text,text,138
85,model,Pile-T5,EleutherAI,"Pile-T5 is a version of the broadly used T5 model, but improved to eliminate weaknesses such as the omission of crucial code-related tokens. It utilizes LLaMA tokenizer and is trained on the Pile, offering enhancements for finetuning on downstream tasks, particularly those involving code.",2024-04-15,https://blog.eleuther.ai/pile-t5/,unknown,"The models were evaluated on SuperGLUE, CodeXGLUE, as well as MMLU and Bigbench Hard. Comparisons were made with T5v1.1 and found that Pile-T5 models performed better in most conditions.",T5x,,open,unknown,The model is aimed at downstream tasks that benefit from the encoder-decoder architecture. Particularly useful for tasks involving code.,unknown,unknown,unknown,,unknown,2 million steps,unknown,,,,,,,72,text,text,139
85,model,Pile-T5,EleutherAI,"Pile-T5 is a version of the broadly used T5 model, but improved to eliminate weaknesses such as the omission of crucial code-related tokens. It utilizes LLaMA tokenizer and is trained on the Pile, offering enhancements for finetuning on downstream tasks, particularly those involving code.",2024-04-15,https://blog.eleuther.ai/pile-t5/,unknown,"The models were evaluated on SuperGLUE, CodeXGLUE, as well as MMLU and Bigbench Hard. Comparisons were made with T5v1.1 and found that Pile-T5 models performed better in most conditions.",LLaMA,,open,unknown,The model is aimed at downstream tasks that benefit from the encoder-decoder architecture. Particularly useful for tasks involving code.,unknown,unknown,unknown,,unknown,2 million steps,unknown,,,,,,,72,text,text,140
85,model,Pile-T5,EleutherAI,"Pile-T5 is a version of the broadly used T5 model, but improved to eliminate weaknesses such as the omission of crucial code-related tokens. It utilizes LLaMA tokenizer and is trained on the Pile, offering enhancements for finetuning on downstream tasks, particularly those involving code.",2024-04-15,https://blog.eleuther.ai/pile-t5/,unknown,"The models were evaluated on SuperGLUE, CodeXGLUE, as well as MMLU and Bigbench Hard. Comparisons were made with T5v1.1 and found that Pile-T5 models performed better in most conditions.",umT5,,open,unknown,The model is aimed at downstream tasks that benefit from the encoder-decoder architecture. Particularly useful for tasks involving code.,unknown,unknown,unknown,,unknown,2 million steps,unknown,,,,,,,72,text,text,141
86,application,Virtual Volunteer,Be My Eyes,The first-ever digital visual assistant powered by OpenAI’s new GPT-4 language model.,2023-03-14,https://www.bemyeyes.com/blog/introducing-be-my-eyes-virtual-volunteer,,,GPT-4 API,,limited,unknown,,,,,,,,,,,,,,,73,nan,nan,142
87,model,CodeGeeX,Tsinghua University,CodeGeeX is an autoregressive language model trained on code,2022-09-20,https://github.com/THUDM/CodeGeeX,13B parameters (dense),,,,limited,Apache 2.0,,,,,,unknown,unknown,THUDM 1536 Ascend 910 (32GB) Cluster,,,,,,,74,text,code,143
88,model,CogView,Tsinghua University,CogView is a transformer model for text-to-image generation,2021-05-26,https://arxiv.org/abs/2105.13290,4B parameters (dense),,,,open,Apache 2.0,,,,,,,,,,,,,,,75,text,image,144
89,model,CogView 2,Tsinghua University,CogView 2 is a hierarchical transformer for text-to-image generation,2022-04-28,https://arxiv.org/abs/2204.14217,6B parameters (dense),,,,open,Apache 2.0,,,,,,,,,,,,,,,76,text,image,145
90,model,CogVideo,Tsinghua University,CogVideo is a transformer model for text-to-video generation,2022-05-29,https://arxiv.org/abs/2205.15868,unknown,,,,open,Apache 2.0,,,,,,,,,,,,,,,77,text,video,146
91,model,GLM-130B,Tsinghua University,GLM-130B is a bidirectional language model trained on English and Chinese,2022-08-04,https://keg.cs.tsinghua.edu.cn/glm-130b/,130B parameters (dense),,The Pile,,open,GLM-130B License,,,,,,,,THUDM 96 DGX-A100 (40G) cluster,,,,,,,78,text,text,147
91,model,GLM-130B,Tsinghua University,GLM-130B is a bidirectional language model trained on English and Chinese,2022-08-04,https://keg.cs.tsinghua.edu.cn/glm-130b/,130B parameters (dense),,GLM-130B Chinese corpora,,open,GLM-130B License,,,,,,,,THUDM 96 DGX-A100 (40G) cluster,,,,,,,78,text,text,148
91,model,GLM-130B,Tsinghua University,GLM-130B is a bidirectional language model trained on English and Chinese,2022-08-04,https://keg.cs.tsinghua.edu.cn/glm-130b/,130B parameters (dense),,P3,,open,GLM-130B License,,,,,,,,THUDM 96 DGX-A100 (40G) cluster,,,,,,,78,text,text,149
91,model,GLM-130B,Tsinghua University,GLM-130B is a bidirectional language model trained on English and Chinese,2022-08-04,https://keg.cs.tsinghua.edu.cn/glm-130b/,130B parameters (dense),,DeepStruct finetuning dataset,,open,GLM-130B License,,,,,,,,THUDM 96 DGX-A100 (40G) cluster,,,,,,,78,text,text,150
92,model,CogVLM,"Zhipu AI, Tsinghua University",CogVLM is a powerful open-source visual language foundation model,2023-11-06,https://arxiv.org/pdf/2311.03079.pdf,17B parameters (dense),Evaluated on image captioning and visual question answering benchmarks.,Vicuna,,open,custom,Future multimodal research,,,,,unknown,4096 A100 days,unknown,,,,,,,79,image,text,151
92,model,CogVLM,"Zhipu AI, Tsinghua University",CogVLM is a powerful open-source visual language foundation model,2023-11-06,https://arxiv.org/pdf/2311.03079.pdf,17B parameters (dense),Evaluated on image captioning and visual question answering benchmarks.,CLIP,,open,custom,Future multimodal research,,,,,unknown,4096 A100 days,unknown,,,,,,,79,image,text,152
92,model,CogVLM,"Zhipu AI, Tsinghua University",CogVLM is a powerful open-source visual language foundation model,2023-11-06,https://arxiv.org/pdf/2311.03079.pdf,17B parameters (dense),Evaluated on image captioning and visual question answering benchmarks.,Vicuna,,open,custom,Future multimodal research,,,,,unknown,4096 A100 days,unknown,,,,,,,79,text,text,153
92,model,CogVLM,"Zhipu AI, Tsinghua University",CogVLM is a powerful open-source visual language foundation model,2023-11-06,https://arxiv.org/pdf/2311.03079.pdf,17B parameters (dense),Evaluated on image captioning and visual question answering benchmarks.,CLIP,,open,custom,Future multimodal research,,,,,unknown,4096 A100 days,unknown,,,,,,,79,text,text,154
93,model,UltraLM,Tsinghua University,UltraLM is a series of chat language models trained on UltraChat.,2023-06-27,https://github.com/thunlp/UltraChat#UltraLM,13B parameters (dense),Evaluated on AlpacaEval Leaderboard benchmarks.,UltraChat,,open,LLaMA 2,,,unknown,https://huggingface.co/openbmb/UltraLM-13b/discussions,https://huggingface.co/openbmb/UltraLM-13b,unknown,unknown,unknown,,,,,,,80,text,text,155
95,model,PolyCoder,Carnegie Mellon University,"PolyCoder is a code model trained on 2.7B parameters based on the GPT-2 architecture, which was trained on 249GB of code across 12 programming languages on a single machine.",2022-02-26,https://arxiv.org/abs/2202.13169,2.7B parameters (dense),Reports results on standard code benchmarks across a variety of programming languages.,Github,"No specific quality control is mentioned in model training, though details on data processing and how the tokenizer was trained are provided in the paper.",open,MIT,unknown,,,https://huggingface.co/NinedayWang/PolyCoder-2.7B/discussion,https://huggingface.co/NinedayWang/PolyCoder-2.7B,unknown,6 weeks,8 NVIDIA RTX 8000,,,,,,,81,code,code,156
96,model,Moment,"Carnegie Mellon University, University of Pennsylvania",Moment is a family of open-source foundation models for general-purpose time-series analysis.,2024-02-06,https://arxiv.org/pdf/2402.03885.pdf,385M parameters (dense),Evaluated on nascent time-series datasets and benchmarks.,,,open,unknown,,,unknown,,,unknown,unknown,Single A6000 GPU,,,,,,,82,nan,nan,157
97,model,OpenAssistant LLaMA 2,OpenAssistant,OpenAssistant LLaMA 2 is an Open-Assistant fine-tuning of Meta's LLaMA 2.,2023-08-23,https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10,70B parameters (dense),,LLaMA 2,,open,LLaMA 2,,,unknown,https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10/discussions,https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10,unknown,unknown,unknown,,,,,,,83,text,text,158
98,model,Inflection-1,Inflection AI,Inflection AI's first version of its in-house LLM. via Inflection AI's conversational API.,2023-06-22,https://inflection.ai/inflection-1,unknown,"Evaluated on wide range of language benchmarks like MMLU 5-shot, GSM-8K, and HellaSwag 10-shot among others.",,,limited,unknown,,,,,,,,unknown,,,,,,,84,text,text,159
99,application,Pi,Inflection AI,Personal AI chatbot designed to be conversational and specialized in emotional intelligence.,2023-05-02,https://inflection.ai/press,,,Inflection-2.5,,limited,unknown,to be used as a personal assistant chatbot for everyday activities,,,,,,,,,natural language text responses,,,,,85,nan,nan,160
100,model,Inflection-2,Inflection AI,"Inflection-2 is the best model in the world for its compute class and the second most capable LLM in the world, according to benchmark evaluation, as of its release.",2023-11-22,https://inflection.ai/inflection-2,unknown,"Evaluated against state of the art models on benchmarks, and found to be most performant model outside of GPT-4.",,,closed,unknown,,,,,,unknown,unknown,5000 NVIDIA H100 GPUs,,,,,,,86,text,text,161
101,model,Inflection-2.5,Inflection AI,"Inflection-2.5 is an upgraded in-house model that is competitive with all the world's leading LLMs, as of release, like GPT-4 and Gemini.",2024-03-07,https://inflection.ai/inflection-2-5,unknown,"Evaluated on standard LLM and technical benchmarks in comparison to Inflection-1 and GPT-4, along with advanced STEM examinations.",,,limited,unknown,,,,,,unknown,unknown,unknown,,,,,,,87,text,text,162
102,model,RWKV World 4,RWKV,"RWKV World 4 is an RNN with GPT-level LLM performance, which can also be directly trained like a GPT transformer (parallelizable).",2023-05-03,https://huggingface.co/RWKV/rwkv-4-world-7b,7B parameters (dense),,,,open,Apache 2.0,,,unknown,https://huggingface.co/RWKV/rwkv-4-world-7b/discussions,https://huggingface.co/RWKV/rwkv-4-world-7b,unknown,unknown,unknown,,,,,,,88,text,text,163
103,model,RWKV 4 Pile,RWKV,"RWKV 4 Pile is an RNN with GPT-level LLM performance, which can also be directly trained like a GPT transformer (parallelizable).",2023-05-15,https://huggingface.co/RWKV/rwkv-4-14b-pile,14B parameters (dense),,,,open,Apache 2.0,,,unknown,https://huggingface.co/RWKV/rwkv-4-14b-pile/discussions,https://huggingface.co/RWKV/rwkv-4-14b-pile,unknown,unknown,unknown,,,,,,,89,text,text,164
104,model,RWKV World 5,RWKV,"RWKV World 5 is an RNN with GPT-level LLM performance, which can also be directly trained like a GPT transformer (parallelizable).",2023-12-16,https://huggingface.co/RWKV/rwkv-5-world-3b,3B parameters (dense),,,,open,Apache 2.0,,,unknown,https://huggingface.co/RWKV/rwkv-5-world-3b/discussions,https://huggingface.co/RWKV/rwkv-5-world-3b,unknown,unknown,unknown,,,,,,,90,text,text,165
105,model,ERNIE 3.0 Titan,"Baidu, PengCheng Laboratory",ERNIE 3.0 Titan is a language model,2021-12-23,https://arxiv.org/abs/2112.12731,260B parameters (dense),,,,closed,unknown,unknown,unknown,,,,unknown,unknown,"Baidu V100 Cluster, PengCheng Lab Ascend 910 NPU cluster",,,,,,,91,text,text,166
106,model,ERNIE-ViLG,Baidu,ERNIE-ViLG is a model for text-to-image generation,2021-12-31,https://arxiv.org/abs/2112.15283,10B parameters (dense),,,,limited,,unknown,unknown,,,,unknown,unknown,unknown,,,,,,,92,text,image,167
107,model,ERNIE-ViLG 2.0,Baidu,ERNIE-ViLG is a model for text-to-image generation,2022-10-27,https://arxiv.org/abs/2210.15257,10B parameters (dense),,,,closed,unknown,unknown,unknown,,,,unknown,18 days according to [[the paper]](https://arxiv.org/abs/2210.15257),320 A100 GPUs according to [[the paper]](https://arxiv.org/abs/2210.15257),,,,,,,93,text,image,168
108,model,ERNIE 4.0,Baidu,ERNIE-4.0 is a multimodal generalist foundation model.,2023-10-17,https://www.prnewswire.com/news-releases/baidu-launches-ernie-4-0-foundation-model-leading-a-new-wave-of-ai-native-applications-301958681.html,unknown,,,,limited,unknown,unknown,unknown,,,,unknown,unknown,unknown,,,,,,,94,text,image,169
108,model,ERNIE 4.0,Baidu,ERNIE-4.0 is a multimodal generalist foundation model.,2023-10-17,https://www.prnewswire.com/news-releases/baidu-launches-ernie-4-0-foundation-model-leading-a-new-wave-of-ai-native-applications-301958681.html,unknown,,,,limited,unknown,unknown,unknown,,,,unknown,unknown,unknown,,,,,,,94,text,text,170
108,model,ERNIE 4.0,Baidu,ERNIE-4.0 is a multimodal generalist foundation model.,2023-10-17,https://www.prnewswire.com/news-releases/baidu-launches-ernie-4-0-foundation-model-leading-a-new-wave-of-ai-native-applications-301958681.html,unknown,,,,limited,unknown,unknown,unknown,,,,unknown,unknown,unknown,,,,,,,94,text,video,171
109,application,Q-Chat,Quizlet,"Quizlet is introducing Q-Chat, a fully-adaptive AI tutor that engages students with adaptive questions based on relevant study materials delivered through a fun chat experience.",2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,ChatGPT API,,open,,,,,,,,,,,,https://quizlet.com/tos,,,,95,nan,nan,172
110,application,Bedrock,Amazon,"Bedrock is a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is intended for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. using an API.",2023-04-13,https://aws.amazon.com/bedrock/,,,Jurassic-2,,limited,unknown,allowing companies to incorporate generative AI into their business models,,,,,,,,,foundation models made accessible via an API,https://aws.amazon.com/service-terms/,,,,96,nan,nan,173
110,application,Bedrock,Amazon,"Bedrock is a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is intended for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. using an API.",2023-04-13,https://aws.amazon.com/bedrock/,,,Claude,,limited,unknown,allowing companies to incorporate generative AI into their business models,,,,,,,,,foundation models made accessible via an API,https://aws.amazon.com/service-terms/,,,,96,nan,nan,174
110,application,Bedrock,Amazon,"Bedrock is a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is intended for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. using an API.",2023-04-13,https://aws.amazon.com/bedrock/,,,Stable Diffusion,,limited,unknown,allowing companies to incorporate generative AI into their business models,,,,,,,,,foundation models made accessible via an API,https://aws.amazon.com/service-terms/,,,,96,nan,nan,175
110,application,Bedrock,Amazon,"Bedrock is a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is intended for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. using an API.",2023-04-13,https://aws.amazon.com/bedrock/,,,Amazon Titan,,limited,unknown,allowing companies to incorporate generative AI into their business models,,,,,,,,,foundation models made accessible via an API,https://aws.amazon.com/service-terms/,,,,96,nan,nan,176
110,application,Bedrock,Amazon,"Bedrock is a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is intended for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. using an API.",2023-04-13,https://aws.amazon.com/bedrock/,,,Claude 2,,limited,unknown,allowing companies to incorporate generative AI into their business models,,,,,,,,,foundation models made accessible via an API,https://aws.amazon.com/service-terms/,,,,96,nan,nan,177
110,application,Bedrock,Amazon,"Bedrock is a new service that makes FMs from AI21 Labs, Anthropic, Stability AI, and Amazon accessible via an API. Bedrock is intended for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. using an API.",2023-04-13,https://aws.amazon.com/bedrock/,,,Cohere Command,,limited,unknown,allowing companies to incorporate generative AI into their business models,,,,,,,,,foundation models made accessible via an API,https://aws.amazon.com/service-terms/,,,,96,nan,nan,178
111,model,FalconLite2,Amazon,"FalconLite2 is a fine-tuned and quantized Falcon language model, capable of processing long (up to 24K tokens) input sequences.",2023-08-08,https://huggingface.co/amazon/FalconLite2,40B parameters (dense),Evaluated against benchmarks that are specifically designed to assess the capabilities of LLMs in handling longer contexts.,Falcon-40B,,open,Apache 2.0,,,,https://huggingface.co/amazon/FalconLite2/discussions,https://huggingface.co/amazon/FalconLite2,unknown,unknown,unknown,,,,,,,97,text,text,179
112,model,Chronos,Amazon,"Chronos is a family of pretrained time series forecasting models based on language model architectures. A time series is transformed into a sequence of tokens via scaling and quantization, and a language model is trained on these tokens using the cross-entropy loss. Once trained, probabilistic forecasts are obtained by sampling multiple future trajectories given the historical context.",2024-03-13,https://github.com/amazon-science/chronos-forecasting,710M parameters (dense),Chronos has been evaluated comprehensively on 42 datasets both in the in-domain (15 datasets) and zero-shot settings (27 datasets). Chronos outperforms task specific baselines in the in-domain setting and is competitive or better than trained models in the zero-shot setting.,T5,"Chronos was evaluated rigorously on 42 datasets, including 27 in the zero-shot setting against a variety of statistical and deep learning baselines.",open,Apache 2.0,"Chronos can be used for zero-shot time series forecasting on univariate time series from arbitrary domains and with arbitrary horizons. Chronos models can also be fine-tuned for improved performance of specific datasets. Embeddings from Chronos encoder may also be useful for other time series analysis tasks such as classification, clustering, and anomaly detection.",,,https://github.com/amazon-science/chronos-forecasting/discussions,https://huggingface.co/amazon/chronos-t5-large,,63 hours on p4d.24xlarge EC2 instance,8 NVIDIA A100 40G GPUs,,,,,,,98,time-series,time-series,180
113,model,Prism,Toyota Research Institute,Prism is a family of VLMs trained using new analyses about key vision design axes.,2024-02-09,https://arxiv.org/pdf/2402.07865.pdf,7B parameters (dense),Evaluated on standard VLM benchmarks and outperforms SotA open-source VLMs as of release.,,,open,LLaMA 2,,,unknown,,,unknown,less than 9 hours,8 A100 GPUs,,,,,,,99,image,text,181
113,model,Prism,Toyota Research Institute,Prism is a family of VLMs trained using new analyses about key vision design axes.,2024-02-09,https://arxiv.org/pdf/2402.07865.pdf,7B parameters (dense),Evaluated on standard VLM benchmarks and outperforms SotA open-source VLMs as of release.,,,open,LLaMA 2,,,unknown,,,unknown,less than 9 hours,8 A100 GPUs,,,,,,,99,text,text,182
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,Kinetics-400,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,183
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,WebVid-2M,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,184
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,WebVid-10M,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,185
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,HowTo100M,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,186
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,AVA,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,187
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,Something-Something-v2,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,188
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,Kinetics-710,,open,Apache 2.0,,,,,,,,,,,,,,,100,text,video,189
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,Kinetics-400,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,190
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,WebVid-2M,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,191
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,WebVid-10M,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,192
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,HowTo100M,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,193
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,AVA,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,194
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,Something-Something-v2,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,195
114,model,InternVideo,Shanghai AI Laboratory,,2022-12-06,https://arxiv.org/pdf/2212.03191.pdf,1.3B parameters (dense),,Kinetics-710,,open,Apache 2.0,,,,,,,,,,,,,,,100,video,video,196
115,model,Lego-MT,Shanghai AI Laboratory,Lego-MT is a multilingual large language model which uses a more efficient approach of being an effective detachable model.,2023-05-29,https://arxiv.org/pdf/2212.10551.pdf,1.2B parameters (dense),Evaluated based on own constructed dataset covering 433 languages.,OPUS,,open,,,,,,,unknown,15 days,32 A100 GPUs,,,,,,,101,text,text,197
116,model,MathCoder,Shanghai AI Laboratory,MathCoder is a family of models capable of generating code-based solutions for solving challenging math problems.,2023-10-05,https://arxiv.org/pdf/2310.03731.pdf,70B parameters (dense),Evaluated on GSM8K and the competition-level MATH dataset.,GPT-4,,open,unknown,bridging the gap between natural language understanding and computational problem-solving,,,,,unknown,unknown,32 NVIDIA A800 80GB GPUs,,,,,,,102,text,text,198
116,model,MathCoder,Shanghai AI Laboratory,MathCoder is a family of models capable of generating code-based solutions for solving challenging math problems.,2023-10-05,https://arxiv.org/pdf/2310.03731.pdf,70B parameters (dense),Evaluated on GSM8K and the competition-level MATH dataset.,LLaMA 2,,open,unknown,bridging the gap between natural language understanding and computational problem-solving,,,,,unknown,unknown,32 NVIDIA A800 80GB GPUs,,,,,,,102,text,text,199
117,model,InternLM,Shanghai AI Laboratory,"InternLM is a high-quality language model proficient in English, Chinese, and code.",2023-09-20,https://github.com/InternLM/InternLM,20B parameters (dense),Evaluated in comparison to LLaMA series models on standard benchmarks.,,,open,Apache 2.0,,,,https://huggingface.co/internlm/internlm-20b/discussions,https://huggingface.co/internlm/internlm-20b,unknown,unknown,unknown,,,,,,,103,code,code,200
117,model,InternLM,Shanghai AI Laboratory,"InternLM is a high-quality language model proficient in English, Chinese, and code.",2023-09-20,https://github.com/InternLM/InternLM,20B parameters (dense),Evaluated in comparison to LLaMA series models on standard benchmarks.,,,open,Apache 2.0,,,,https://huggingface.co/internlm/internlm-20b/discussions,https://huggingface.co/internlm/internlm-20b,unknown,unknown,unknown,,,,,,,103,code,text,201
117,model,InternLM,Shanghai AI Laboratory,"InternLM is a high-quality language model proficient in English, Chinese, and code.",2023-09-20,https://github.com/InternLM/InternLM,20B parameters (dense),Evaluated in comparison to LLaMA series models on standard benchmarks.,,,open,Apache 2.0,,,,https://huggingface.co/internlm/internlm-20b/discussions,https://huggingface.co/internlm/internlm-20b,unknown,unknown,unknown,,,,,,,103,text,code,202
117,model,InternLM,Shanghai AI Laboratory,"InternLM is a high-quality language model proficient in English, Chinese, and code.",2023-09-20,https://github.com/InternLM/InternLM,20B parameters (dense),Evaluated in comparison to LLaMA series models on standard benchmarks.,,,open,Apache 2.0,,,,https://huggingface.co/internlm/internlm-20b/discussions,https://huggingface.co/internlm/internlm-20b,unknown,unknown,unknown,,,,,,,103,text,text,203
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",InternVL,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,204
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",VideoMAEv2,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,205
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",LAION,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,206
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",WebVid,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,207
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",InternVid,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,208
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",LLaVA,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,209
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",KMash,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,text,text,210
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",InternVL,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,211
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",VideoMAEv2,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,212
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",LAION,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,213
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",WebVid,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,214
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",InternVid,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,215
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",LLaVA,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,216
118,model,InternVideo2,"Shanghai AI Laboratory, Nanjing University, Zhejiang University","InternVideo2 is a new video foundation model (ViFM) that achieves the state-of-the-art performance in action recognition, video-text tasks, and video-centric dialogue.",2024-03-22,https://github.com/OpenGVLab/InternVideo2,6B parameters,"Evaluated across a range of video-related tasks and compared to other multimodal models like CLIP, VideoPrism, and VideoCoCa. InternVideo 2 generally performs among the best of such models on these benchmarks.",KMash,,open,MIT,,,unknown,,,unknown,35 days,"256 NVIDIA A100 GPUs for 32 days, and 64 GPUs for 3 days",,,,,,,104,video,text,217
119,model,CosmicMan,Shanghai AI Laboratory,"CosmicMan is a text-to-image foundation model specialized for generating high-fidelity human images with meticulous appearance, reasonable structure, and precise text-image alignment.",2024-04-01,https://cosmicman-cvpr2024.github.io/,unknown,The model was compared with SOTAs and has shown good performance in generating high-quality human images.,CosmicMan-HQ 1.0,The quality control measures taken include modeling the relationship between dense text descriptions and image pixels in a decomposed manner and enforcing attention refocusing without adding extra modules.,open,unknown,"The model is intended to generate high-quality, photorealistic human images from text descriptions. Applications include avatar generation and potentially virtual reality and video game character creation.",unknown,unknown,unknown,,unknown,1 week,32 80G NVIDIA A100 GPUs,,,,,,,105,text,image,218
121,model,Nucleus,Nucleus.AI,Nucleus is a 22B parameters causal decoder-only model built by Nucleus.AI and trained on 500B tokens of RefinedWeb along with curated corpora.,2023-10-05,https://www.withnucleus.ai/,22B parameters (dense),"Evaluated on the OpenLLM leaderboard, performing on par with similar-sized models.",RefinedWeb,,open,MIT,"Research on large language models; as a foundation for further specialization and finetuning for specific usecases (e.g., summarization, text generation, chatbot, etc.)",Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.,unknown,https://huggingface.co/NucleusAI/nucleus-22B-token-500B/discussions,https://huggingface.co/NucleusAI/nucleus-22B-token-500B,unknown,2 weeks,unknown,,,,,,,106,text,text,219
122,model,Devin,Cognition Labs,Devin is the world’s first fully autonomous AI software engineer.,2024-03-12,https://www.cognition-labs.com/introducing-devin,unknown,"Evaluated on SWE-Bench, a challenging software engineering benchmark, where Devin outperforms major state of the art models unassisted.",,,limited,unknown,,,,,,unknown,unknown,unknown,,,,,,,107,text,code,220
123,model,Konan LLM,Konan,"Konan LLM is a Large Language Model developed in-house by Konan Technology. Optimized for super-large AI training, it leverages high-quality, large-scale data and over 20 years of expertise in natural language processing.",2023-09-17,https://en.konantech.com/en/llm/konanllm,13B parameters,,,,limited,unknown,"Document generation, document review, Q&A, customer response scenarios.",,,,,unknown,unknown,unknown,,,,,,,108,text,text,221
124,application,LinkedIn,LinkedIn,"More than 40 percent of LinkedIn's feed posts include at least one image. We want every member to have equal access to opportunity and are committed to ensuring that we make images accessible to our members who are blind or who have low vision so they can be a part of the online conversation. With Azure Cognitive Service for Vision, we can provide auto-captioning to edit and support alt. text descriptions.",,https://www.linkedin.com/,,,Azure Cognitive Services for Vision,,open,unknown,,,,,,,,,,,,,,,109,nan,nan,222
125,application,Character,Character AI,Character allows users to converse with various chatbot personas.,2022-09-16,https://beta.character.ai/,,,,,limited,unknown,,,,,,,,,,AI-generated chat conversations,https://beta.character.ai/tos,unknown,unknown,unknown,110,nan,nan,223
127,model,RT-1-X,"Open X-Embodiment, Google Deepmind","RT-1-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-1, an efficient Transformer-based architecture designed for robotic control.",2023-10-03,https://robotics-transformer-x.github.io/,35M parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-1 by 50% in emergent skill evaluations.",Open X-Embodiment dataset,unknown,open,Apache 2.0,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,111,images,robot trajectories,224
127,model,RT-1-X,"Open X-Embodiment, Google Deepmind","RT-1-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-1, an efficient Transformer-based architecture designed for robotic control.",2023-10-03,https://robotics-transformer-x.github.io/,35M parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-1 by 50% in emergent skill evaluations.",ImageNet EfficientNet,unknown,open,Apache 2.0,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,111,images,robot trajectories,225
127,model,RT-1-X,"Open X-Embodiment, Google Deepmind","RT-1-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-1, an efficient Transformer-based architecture designed for robotic control.",2023-10-03,https://robotics-transformer-x.github.io/,35M parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-1 by 50% in emergent skill evaluations.",USE,unknown,open,Apache 2.0,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,111,images,robot trajectories,226
127,model,RT-1-X,"Open X-Embodiment, Google Deepmind","RT-1-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-1, an efficient Transformer-based architecture designed for robotic control.",2023-10-03,https://robotics-transformer-x.github.io/,35M parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-1 by 50% in emergent skill evaluations.",Open X-Embodiment dataset,unknown,open,Apache 2.0,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,111,text,robot trajectories,227
127,model,RT-1-X,"Open X-Embodiment, Google Deepmind","RT-1-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-1, an efficient Transformer-based architecture designed for robotic control.",2023-10-03,https://robotics-transformer-x.github.io/,35M parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-1 by 50% in emergent skill evaluations.",ImageNet EfficientNet,unknown,open,Apache 2.0,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,111,text,robot trajectories,228
127,model,RT-1-X,"Open X-Embodiment, Google Deepmind","RT-1-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-1, an efficient Transformer-based architecture designed for robotic control.",2023-10-03,https://robotics-transformer-x.github.io/,35M parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-1 by 50% in emergent skill evaluations.",USE,unknown,open,Apache 2.0,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,111,text,robot trajectories,229
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",Open X-Embodiment dataset,unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,images,robot trajectories,230
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",ViT (unknown size),unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,images,robot trajectories,231
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",UL2,unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,images,robot trajectories,232
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",Open X-Embodiment dataset,unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,text,robot trajectories,233
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",ViT (unknown size),unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,text,robot trajectories,234
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",UL2,unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,text,robot trajectories,235
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",Open X-Embodiment dataset,unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,robot trajectories,robot trajectories,236
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",ViT (unknown size),unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,robot trajectories,robot trajectories,237
128,model,RT-2-X,"Open X-Embodiment, Google Deepmind","RT-2-X is a model trained on the Open X-Embodiment dataset that exhibits better generalization and new capabilities compared to its predecessor RT-2, a large vision-language model co-fine-tuned to output robot actions as natural language tokens.",2023-10-03,https://robotics-transformer-x.github.io/,55B parameters (dense),"Evaluated on in-distribution robotics skills, and outperforms its predecessor RT-2 by 3x in emergent skill evaluations.",UL2,unknown,closed,unknown,Further research on X-embodiment models.,,unknown,,,unknown,unknown,unknown,,,,,,,112,robot trajectories,robot trajectories,238
129,model,Taiyi Diffusion XL,"International Digital Economy Academy, South China University of Technology, University of Science and Technology of China",Taiyi Diffusion XL is a new Chinese and English bilingual text-to-image model which is developed by extending the capabilities of CLIP and Stable-DiffusionXL.,2024-01-26,https://arxiv.org/pdf/2401.14688.pdf,3.5B parameters (dense),Evaluated on human and machine benchmarks in comparison to established image models as a baseline.,CLIP,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B/discussions,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B,unknown,unknown,unknown,,,,,,,113,text,image,239
129,model,Taiyi Diffusion XL,"International Digital Economy Academy, South China University of Technology, University of Science and Technology of China",Taiyi Diffusion XL is a new Chinese and English bilingual text-to-image model which is developed by extending the capabilities of CLIP and Stable-DiffusionXL.,2024-01-26,https://arxiv.org/pdf/2401.14688.pdf,3.5B parameters (dense),Evaluated on human and machine benchmarks in comparison to established image models as a baseline.,LAION-400M,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B/discussions,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B,unknown,unknown,unknown,,,,,,,113,text,image,240
129,model,Taiyi Diffusion XL,"International Digital Economy Academy, South China University of Technology, University of Science and Technology of China",Taiyi Diffusion XL is a new Chinese and English bilingual text-to-image model which is developed by extending the capabilities of CLIP and Stable-DiffusionXL.,2024-01-26,https://arxiv.org/pdf/2401.14688.pdf,3.5B parameters (dense),Evaluated on human and machine benchmarks in comparison to established image models as a baseline.,Wukong,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B/discussions,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B,unknown,unknown,unknown,,,,,,,113,text,image,241
129,model,Taiyi Diffusion XL,"International Digital Economy Academy, South China University of Technology, University of Science and Technology of China",Taiyi Diffusion XL is a new Chinese and English bilingual text-to-image model which is developed by extending the capabilities of CLIP and Stable-DiffusionXL.,2024-01-26,https://arxiv.org/pdf/2401.14688.pdf,3.5B parameters (dense),Evaluated on human and machine benchmarks in comparison to established image models as a baseline.,Stable Diffusion XL,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B/discussions,https://huggingface.co/IDEA-CCNL/Taiyi-Stable-Diffusion-XL-3.5B,unknown,unknown,unknown,,,,,,,113,text,image,242
130,model,Pegasus-1,Twelve Labs,Pegasus-1 is a video-language foundation model.,2023-10-23,https://app.twelvelabs.io/blog/introducing-pegasus-1,80B parameters (dense),Evaluated in comparison to SOTA video-to-language models.,MSR-VTT,Data selected and cleaned to eliminate toxic and biased content.,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,114,video,text,243
130,model,Pegasus-1,Twelve Labs,Pegasus-1 is a video-language foundation model.,2023-10-23,https://app.twelvelabs.io/blog/introducing-pegasus-1,80B parameters (dense),Evaluated in comparison to SOTA video-to-language models.,Video-ChatGPT Video Descriptions Dataset,Data selected and cleaned to eliminate toxic and biased content.,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,114,video,text,244
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,audio,audio,245
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,audio,image,246
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,audio,video,247
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,image,audio,248
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,image,image,249
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,image,video,250
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,text,audio,251
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,text,image,252
131,model,Marengo 2.6,Twelve Labs,"Marengo 2.6 is a new state-of-the-art (SOTA) multimodal foundation model capable of performing any-to-any search tasks, including Text-To-Video, Text-To-Image, Text-To-Audio, Audio-To-Video, Image-To-Video, and more. ",2024-03-01,https://www.twelvelabs.io/blog/introducing-marengo-2-6,unknown,"Marengo-2.6 sets new benchmarks in zero-shot text-to-video, text-to-image, and text-to-audio retrieval tasks with a single embedding model.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,115,text,video,253
132,model,GodziLLa 2,Maya Philippines,"GodziLLa 2 is an experimental combination of various proprietary LoRAs from Maya Philippines and Guanaco LLaMA 2 1K dataset, with LLaMA 2.",2023-08-11,https://huggingface.co/MayaPH/GodziLLa2-70B,70B parameters (dense),"Evaluated on the OpenLLM leaderboard, releasing at rank number 4 on the leaderboard.",LLaMA 2,,open,LLaMA 2,,,unknown,,https://huggingface.co/MayaPH/GodziLLa2-70B,unknown,unknown,unknown,,,,,,,116,text,text,254
132,model,GodziLLa 2,Maya Philippines,"GodziLLa 2 is an experimental combination of various proprietary LoRAs from Maya Philippines and Guanaco LLaMA 2 1K dataset, with LLaMA 2.",2023-08-11,https://huggingface.co/MayaPH/GodziLLa2-70B,70B parameters (dense),"Evaluated on the OpenLLM leaderboard, releasing at rank number 4 on the leaderboard.",Guanaco LLaMA dataset,,open,LLaMA 2,,,unknown,,https://huggingface.co/MayaPH/GodziLLa2-70B,unknown,unknown,unknown,,,,,,,116,text,text,255
133,model,BiomedGPT,Lehigh University,BiomedGPT leverages self-supervision on large and diverse datasets to accept multi-modal inputs and perform a range of downstream tasks.,2023-05-26,https://arxiv.org/pdf/2305.17100.pdf,472M parameters (dense),outperforms majority of preceding state-of-the-art models over 15 unique biomedical modalities.,GPT-style autoregressive decoder,"No specific quality control is mentioned in model training, though details on data processing and how the model was trained are provided in the paper.",open,Apache 2.0,furthering research in developing unified and generalist models for biomedicine.,,,,,unknown,unknown,10 NVIDIA A5000 GPUs,,,,,,,117,image,text,256
133,model,BiomedGPT,Lehigh University,BiomedGPT leverages self-supervision on large and diverse datasets to accept multi-modal inputs and perform a range of downstream tasks.,2023-05-26,https://arxiv.org/pdf/2305.17100.pdf,472M parameters (dense),outperforms majority of preceding state-of-the-art models over 15 unique biomedical modalities.,BiomedGPT biomedical datasets,"No specific quality control is mentioned in model training, though details on data processing and how the model was trained are provided in the paper.",open,Apache 2.0,furthering research in developing unified and generalist models for biomedicine.,,,,,unknown,unknown,10 NVIDIA A5000 GPUs,,,,,,,117,image,text,257
133,model,BiomedGPT,Lehigh University,BiomedGPT leverages self-supervision on large and diverse datasets to accept multi-modal inputs and perform a range of downstream tasks.,2023-05-26,https://arxiv.org/pdf/2305.17100.pdf,472M parameters (dense),outperforms majority of preceding state-of-the-art models over 15 unique biomedical modalities.,GPT-style autoregressive decoder,"No specific quality control is mentioned in model training, though details on data processing and how the model was trained are provided in the paper.",open,Apache 2.0,furthering research in developing unified and generalist models for biomedicine.,,,,,unknown,unknown,10 NVIDIA A5000 GPUs,,,,,,,117,text,text,258
133,model,BiomedGPT,Lehigh University,BiomedGPT leverages self-supervision on large and diverse datasets to accept multi-modal inputs and perform a range of downstream tasks.,2023-05-26,https://arxiv.org/pdf/2305.17100.pdf,472M parameters (dense),outperforms majority of preceding state-of-the-art models over 15 unique biomedical modalities.,BiomedGPT biomedical datasets,"No specific quality control is mentioned in model training, though details on data processing and how the model was trained are provided in the paper.",open,Apache 2.0,furthering research in developing unified and generalist models for biomedicine.,,,,,unknown,unknown,10 NVIDIA A5000 GPUs,,,,,,,117,text,text,259
134,model,MM1,Apple,"MM1 is a family of multimodal models, including both dense variants up to 30B and mixture-of-experts (MoE) variants up to 64B.",2024-03-16,https://arxiv.org/pdf/2403.09611.pdf,30B parameters (dense),Evaluated on image captioning and visual question answering across many benchmarks.,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,118,image,text,260
134,model,MM1,Apple,"MM1 is a family of multimodal models, including both dense variants up to 30B and mixture-of-experts (MoE) variants up to 64B.",2024-03-16,https://arxiv.org/pdf/2403.09611.pdf,30B parameters (dense),Evaluated on image captioning and visual question answering across many benchmarks.,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,118,text,text,261
135,model,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",RefinedWeb,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,,,,,,,119,text,text,262
135,model,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",The Pile,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,,,,,,,119,text,text,263
135,model,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",RedPajama-Data,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,,,,,,,119,text,text,264
135,model,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",Dolma,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,,,,,,,119,text,text,265
135,model,OpenELM,Apple,"OpenELM is a family of Open-source Efficient Language Models. It uses a layer-wise scaling strategy to efficiently allocate parameters within each layer of the transformer model, leading to enhanced accuracy.",2024-04-24,https://machinelearning.apple.com/research/openelm,3B parameters,"The models were evaluated in terms of zero-shot, LLM360, and OpenLLM leaderboard results.",CoreNet library,unknown,open,Apple,To empower and enrich the open research community by providing access to state-of-the-art language models.,"No explicit prohibited uses stated, though it is noted that users should undertake thorough safety testing.",,https://huggingface.co/apple/OpenELM-3B-Instruct/discussions,https://huggingface.co/apple/OpenELM-3B-Instruct,unknown,unknown,unknown,,,,,,,119,text,text,266
136,model,StarCoder,BigCode,"StarCoder is a Large Language Model for Code (Code LLM) trained on permissively licensed data from GitHub, including from 80+ programming languages, Git commits, GitHub issues, and Jupyter notebooks.",2023-05-09,https://arxiv.org/pdf/2305.06161.pdf,15.5B parameters (dense),"Tested on several benchmarks, most notably Python benchmark HumanEval.",The Stack,"No specific quality control is mentioned in model training, though details on data processing and how the tokenizer was trained are provided in the paper.",open,BigCode Open RAIL-M v1.0,"As a foundation model to fine-tune and create more specialized models that support use cases such as code completion, fill-in-the-middle, and text summarization. Can also be used as a Tech Assistant prompt and not as an instruction model given training limitations.",See BigCode Open RAIL-M license and FAQ,,https://huggingface.co/bigcode/starcoder/discussions,https://huggingface.co/bigcode/starcoder,16.68 tons of CO2eq,"320,256 GPU hours",512 A100 80GB GPUs distributed across 64 nodes,,,,,,,120,code,code,267
137,model,SantaCoder,BigCode,Multilingual code model derived from the findings of BigCode Project analysis on Github stars' association to data quality.,2023-02-24,https://arxiv.org/pdf/2301.03988.pdf,1.1B parameters (dense),Evaluated on MultiPL-E system benchmarks.,The Stack,,open,BigCode Open RAIL-M v1,The model was trained on GitHub code. As such it is not an instruction model and commands do not work well. You should phrase commands like they occur in source code such as comments or write a function signature and docstring and let the model complete the function body.,See BigCode Open RAIL-M license and FAQ,,https://huggingface.co/bigcode/santacoder/discussions,https://huggingface.co/bigcode/santacoder,124 kg of CO2eq,"14,284 GPU hours",96 NVIDIA Tesla V100 GPUs,,,,,,,121,code,code,268
137,model,SantaCoder,BigCode,Multilingual code model derived from the findings of BigCode Project analysis on Github stars' association to data quality.,2023-02-24,https://arxiv.org/pdf/2301.03988.pdf,1.1B parameters (dense),Evaluated on MultiPL-E system benchmarks.,BigCode Dataset,,open,BigCode Open RAIL-M v1,The model was trained on GitHub code. As such it is not an instruction model and commands do not work well. You should phrase commands like they occur in source code such as comments or write a function signature and docstring and let the model complete the function body.,See BigCode Open RAIL-M license and FAQ,,https://huggingface.co/bigcode/santacoder/discussions,https://huggingface.co/bigcode/santacoder,124 kg of CO2eq,"14,284 GPU hours",96 NVIDIA Tesla V100 GPUs,,,,,,,121,code,code,269
139,model,StarCoder2-15B,BigCode,"StarCoder2-15B model is a 15B parameter model trained on 600+ programming languages from The Stack v2, with opt-out requests excluded. The training was carried out using the Fill-in-the-Middle objective on 4+ trillion tokens.",2024-02-28,https://www.servicenow.com/company/media/press-room/huggingface-nvidia-launch-starcoder2.html,15B parameters (dense),See https://arxiv.org/pdf/2402.19173.pdf,The Stack v2,The model was filtered for permissive licenses and code with no license only. A search index is provided to identify where generated code came from to apply the proper attribution.,open,BigCode OpenRail-M,"The model was trained on GitHub code as well as additional selected data sources such as Arxiv and Wikipedia. As such it is not an instruction model and commands like ""Write a function that computes the square root."" do not work well. Intended to generate code snippets from given context, but not for writing actual functional code directly.",See BigCode Open RAIL-M license and FAQ,unknown,https://huggingface.co/bigcode/starcoder2-15b/discussions,https://huggingface.co/bigcode/starcoder2-15b,unknown,unknown,1024 x H100 GPUs,,,,,,,122,code,text,270
140,model,StarCoder2-7B,BigCode,"StarCoder2-7B model is a 7B parameter model trained on 17 programming languages from The Stack v2, with opt-out requests excluded. The model uses Grouped Query Attention, a context window of 16,384 tokens with a sliding window attention of 4,096 tokens, and was trained using the Fill-in-the-Middle objective on 3.5+ trillion tokens.",2024-02-28,https://www.servicenow.com/company/media/press-room/huggingface-nvidia-launch-starcoder2.html,7B parameters (dense),See https://arxiv.org/pdf/2402.19173.pdf,The Stack v2,The model was filtered for permissive licenses and code with no license only. A search index is provided to identify where generated code came from to apply the proper attribution.,open,BigCode OpenRail-M,"Intended to generate code snippets from given context, but not for writing actual functional code directly. The model has been trained on source code from 17 programming languages. The predominant language in source is English although other languages are also present. As such the model is capable of generating code snippets provided some context but the generated code is not guaranteed to work as intended. It can be inefficient and contain bugs or exploits. See the paper for an in-depth discussion of the model limitations.",See BigCode Open RAIL-M license and FAQ,unknown,https://huggingface.co/bigcode/starcoder2-7b/discussions,https://huggingface.co/bigcode/starcoder2-7b,"29,622.83 kgCO2eq","145,152 hours (cumulative)",432 H100 GPUs,,,,,,,123,code,text,271
141,model,StarCoder2-3B,BigCode,"StarCoder2-3B model is a 3B parameter model trained on 17 programming languages from The Stack v2, with opt-out requests excluded. The model uses Grouped Query Attention, a context window of 16,384 tokens with a sliding window attention of 4,096 tokens, and was trained using the Fill-in-the-Middle objective on 3+ trillion tokens.",2024-02-28,https://www.servicenow.com/company/media/press-room/huggingface-nvidia-launch-starcoder2.html,3B parameters (dense),See https://arxiv.org/pdf/2402.19173.pdf,The Stack v2,The model was filtered for permissive licenses and code with no license only. A search index is provided to identify where generated code came from to apply the proper attribution.,open,BigCode OpenRail-M,"Intended to generate code snippets from given context, but not for writing actual functional code directly. The model has been trained on source code from 17 programming languages. The predominant language in source is English although other languages are also present. As such the model is capable of generating code snippets provided some context but the generated code is not guaranteed to work as intended. It can be inefficient and contain bugs or exploits. See the paper for an in-depth discussion of the model limitations.",See BigCode Open RAIL-M license and FAQ,unknown,https://huggingface.co/bigcode/starcoder2-3b/discussions,https://huggingface.co/bigcode/starcoder2-3b,"16,107.01 kgCO2eq","97,120 hours (cumulative)",160 A100 GPUs,,,,,,,124,code,text,272
142,model,h2oGPT,H2O AI,Series of models fine-tuned on well-known LLMs using the h2oGPT repositories.,2023-06-16,https://arxiv.org/pdf/2306.08161.pdf,20B parameters (dense),Evaluated on EleutherAI evaluation harness.,GPT-NeoX,,open,Apache 2.0,,,,https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b/discussions,https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b,unknown,unknown,unspecified number of 48GB A100 NVIDIA GPUs,,,,,,,125,text,text,273
142,model,h2oGPT,H2O AI,Series of models fine-tuned on well-known LLMs using the h2oGPT repositories.,2023-06-16,https://arxiv.org/pdf/2306.08161.pdf,20B parameters (dense),Evaluated on EleutherAI evaluation harness.,H2O AI OpenAssistant,,open,Apache 2.0,,,,https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b/discussions,https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b,unknown,unknown,unspecified number of 48GB A100 NVIDIA GPUs,,,,,,,125,text,text,274
142,model,h2oGPT,H2O AI,Series of models fine-tuned on well-known LLMs using the h2oGPT repositories.,2023-06-16,https://arxiv.org/pdf/2306.08161.pdf,20B parameters (dense),Evaluated on EleutherAI evaluation harness.,h2oGPT Repositories,,open,Apache 2.0,,,,https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b/discussions,https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b,unknown,unknown,unspecified number of 48GB A100 NVIDIA GPUs,,,,,,,125,text,text,275
143,model,H2O Danube,H2O AI,H2O Danube is a language model trained on 1T tokens following the core principles of LLaMA 2 and Mistral.,2024-01-30,https://arxiv.org/pdf/2401.16818.pdf,1.8B parameters (dense),Evaluated on common sense and world knowledge benchmarks.,,unknown,open,Apache 2.0,,"Users are encouraged to use the large language model responsibly and ethically. By using this model, you agree not to use it for purposes that promote hate speech, discrimination, harassment, or any form of illegal or harmful activities.",unknown,https://huggingface.co/h2oai/h2o-danube-1.8b-base/discussions,https://huggingface.co/h2oai/h2o-danube-1.8b-base,unknown,unknown,8x H100 GPUs on a single node,,,,,,,126,text,text,276
144,application,ARES,Faraday Lab,ARES is a text-to-image generator based on Stable Diffusion. The goal is to provide a simple tool with a user interface allowing mainstream AI access for artists and creators.,2023-04-26,https://faradaylab.fr/,,,Stable Diffusion,,open,unknown,,,,,,,,,,generated images,,,,,127,nan,nan,277
149,model,T5,Google,Text-To-Text Transfer Transformer (T5) is a model that unifies all NLP tasks under the text-to-text format.,2019-10-23,https://arxiv.org/abs/1910.10683,11B parameters (dense),https://huggingface.co/t5-base#evaluation,C4,The T5 paper documents many analyses/ablations that were considered before arriving at the final architecture/training procedure.,open,Apache 2.0,NLP tasks,unknown,,https://huggingface.co/t5-large/discussions,https://huggingface.co/t5-base,unknown,unknown,"1,024 TPU v3 chips (Cloud TPU Pods)",,,,,,,128,text,text,278
150,model,Internal Google BERT,Google,"Internal Google BERT model used to power Google Search products.
",2019-11-25,https://blog.google/products/search/search-language-understanding-bert/,unknown,unknown,Internal Google BERT dataset,unknown,closed,unknown,unknown,unknown,unknown,unknown,unknown,unknown,unknown,unknown,,,,,,,129,text,text,279
151,application,Google Search,Google,"Google Search is Google's search engine.
",2019-11-25,https://blog.google/products/search/search-language-understanding-bert/,,,Internal Google BERT,unknown,open,,"Searching the web using text, voice or image","Prohibited use cases aren't specifically spelled out for Google search, but several illegal and discouraged use cases are shared in the Respect Others section of the [[Term of Service]](https://policies.google.com/terms).
","It is implied that Google scan uses of its products for spam, malware and illegal content in the [[Term of Service]](https://policies.google.com/terms).
","Feedback can be sent to Google Feedback using the product interface [[Google Feedback]](https://www.google.com/tools/feedback).
",,,,,unknown,web page ranking,https://policies.google.com/terms,unknown,unknown,unknown,130,nan,nan,280
151,application,Google Search,Google,"Google Search is Google's search engine.
",2019-11-25,https://blog.google/products/search/search-language-understanding-bert/,,,MUM,unknown,open,,"Searching the web using text, voice or image","Prohibited use cases aren't specifically spelled out for Google search, but several illegal and discouraged use cases are shared in the Respect Others section of the [[Term of Service]](https://policies.google.com/terms).
","It is implied that Google scan uses of its products for spam, malware and illegal content in the [[Term of Service]](https://policies.google.com/terms).
","Feedback can be sent to Google Feedback using the product interface [[Google Feedback]](https://www.google.com/tools/feedback).
",,,,,unknown,web page ranking,https://policies.google.com/terms,unknown,unknown,unknown,130,nan,nan,281
153,model,LaMDA,Google,"LaMDA stands for Language Models for Dialog Application. It is a transformer based language model trained on dialogue data.
",2021-06-18,https://arxiv.org/pdf/2201.08239.pdf,137B parameters (dense),"The model performance was analyzed on sensibleness, specificity and interestingness. The model was also analyzed on safety, following metrics derived from Google AI Principles [[Appendix A.1]](https://arxiv.org/pdf/2201.08239.pdf#subsection.A.1). Finally, the model was analyzed on groundedness, testing its ability to produce responses that can be associated with ""known sources whenever possible [[Section 4.1]](https://arxiv.org/pdf/2201.08239.pdf#subsection.4.1).""
",Infiniset,"LaMDA was fine-tuned to predict sensibleness, specificity and interestingness as well as safety. Then, the candidates were filtered out if the model safety predictions were below a certain threshold. The next candidates in the conversation were selected as a combination of these predictions. The model was also fine-tuned for groundedness. The results are shown in [[Figure 5]](https://arxiv.org/pdf/2201.08239.pdf#figure.caption.23).
",closed,unknown,"LaMDA is a language model, so it can be used for regular langauge modelling tasks without fine-tuning, but its fine-tuned for dialogue tasks.
","The prohibited uses of LaMDA weren't specifically listed, but the Google AI principles inspired safety objectives in [[Appendix A.1]](https://arxiv.org/pdf/2201.08239.pdf#subsection.A.1) advises avoiding harm, unjust impact and misinformation, among others.
",unknown,,,26 tCO2e,4108.80 petaflop/s-day,1024 TPU-V3 chips,,,,,,,131,text,text,282
155,model,Flan-T5,Google,Flan-T5 is a version of the T5 language model fine-tuned on instruction data,2022-10-20,https://arxiv.org/abs/2210.11416,11B parameters (dense),Evaluated on a variety of standard language datasets.,T5,"Across different multitask datasets, templates and formatting were maintained. For the chain-of-thoughts (CoT) data, specific exemplars were used.",open,Apache 2.0,unknown,,,https://huggingface.co/google/flan-t5-xxl/discussions,https://arxiv.org/pdf/2210.11416.pdf,Unknown,Unknown,512 v4 TPU Chips,,,,,,,132,text,text,283
155,model,Flan-T5,Google,Flan-T5 is a version of the T5 language model fine-tuned on instruction data,2022-10-20,https://arxiv.org/abs/2210.11416,11B parameters (dense),Evaluated on a variety of standard language datasets.,Muffin,"Across different multitask datasets, templates and formatting were maintained. For the chain-of-thoughts (CoT) data, specific exemplars were used.",open,Apache 2.0,unknown,,,https://huggingface.co/google/flan-t5-xxl/discussions,https://arxiv.org/pdf/2210.11416.pdf,Unknown,Unknown,512 v4 TPU Chips,,,,,,,132,text,text,284
155,model,Flan-T5,Google,Flan-T5 is a version of the T5 language model fine-tuned on instruction data,2022-10-20,https://arxiv.org/abs/2210.11416,11B parameters (dense),Evaluated on a variety of standard language datasets.,P3,"Across different multitask datasets, templates and formatting were maintained. For the chain-of-thoughts (CoT) data, specific exemplars were used.",open,Apache 2.0,unknown,,,https://huggingface.co/google/flan-t5-xxl/discussions,https://arxiv.org/pdf/2210.11416.pdf,Unknown,Unknown,512 v4 TPU Chips,,,,,,,132,text,text,285
155,model,Flan-T5,Google,Flan-T5 is a version of the T5 language model fine-tuned on instruction data,2022-10-20,https://arxiv.org/abs/2210.11416,11B parameters (dense),Evaluated on a variety of standard language datasets.,NaturalInstructions-v2,"Across different multitask datasets, templates and formatting were maintained. For the chain-of-thoughts (CoT) data, specific exemplars were used.",open,Apache 2.0,unknown,,,https://huggingface.co/google/flan-t5-xxl/discussions,https://arxiv.org/pdf/2210.11416.pdf,Unknown,Unknown,512 v4 TPU Chips,,,,,,,132,text,text,286
155,model,Flan-T5,Google,Flan-T5 is a version of the T5 language model fine-tuned on instruction data,2022-10-20,https://arxiv.org/abs/2210.11416,11B parameters (dense),Evaluated on a variety of standard language datasets.,Flan CoT,"Across different multitask datasets, templates and formatting were maintained. For the chain-of-thoughts (CoT) data, specific exemplars were used.",open,Apache 2.0,unknown,,,https://huggingface.co/google/flan-t5-xxl/discussions,https://arxiv.org/pdf/2210.11416.pdf,Unknown,Unknown,512 v4 TPU Chips,,,,,,,132,text,text,287
156,model,UL2,Google,UL2 is a language model trained with a new pretraining objective,2022-05-10,https://arxiv.org/abs/2205.05131,20B parameters (dense),,C4,,open,Apache 2.0,,,,,,,,128 TPUv4,,,,,,,133,text,text,288
157,model,Parti,Google,Parti is a text-to-image diffusion model,2022-06-22,https://parti.research.google/,20B parameters (dense),,C4,,closed,unknown,,,,,,,unknown,unknown,,,,,,,134,text,image,289
157,model,Parti,Google,Parti is a text-to-image diffusion model,2022-06-22,https://parti.research.google/,20B parameters (dense),,LAION-400M,,closed,unknown,,,,,,,unknown,unknown,,,,,,,134,text,image,290
157,model,Parti,Google,Parti is a text-to-image diffusion model,2022-06-22,https://parti.research.google/,20B parameters (dense),,FIT400M,,closed,unknown,,,,,,,unknown,unknown,,,,,,,134,text,image,291
157,model,Parti,Google,Parti is a text-to-image diffusion model,2022-06-22,https://parti.research.google/,20B parameters (dense),,JFT-4B,,closed,unknown,,,,,,,unknown,unknown,,,,,,,134,text,image,292
158,model,Imagen,Google,Imagen is a text-to-image diffusion model,2022-05-23,https://imagen.research.google/,14B parameters (dense),,LAION-400M,,open,unknown,,,,,,unknown,unknown,128 TPU-v4,,,,,,,135,text,image,293
158,model,Imagen,Google,Imagen is a text-to-image diffusion model,2022-05-23,https://imagen.research.google/,14B parameters (dense),,Google internal image-text dataset,,open,unknown,,,,,,unknown,unknown,128 TPU-v4,,,,,,,135,text,image,294
159,model,VATT,Google,VATT is a family of models trained on multimodal data,2022-04-22,https://arxiv.org/abs/2104.11178,155M parameters (dense),,AudioSet,,open,Apache 2.0,,,,,,unknown,3 days,256 TPU-v3,,,,,,,136,text,audio,295
159,model,VATT,Google,VATT is a family of models trained on multimodal data,2022-04-22,https://arxiv.org/abs/2104.11178,155M parameters (dense),,HowTo100M,,open,Apache 2.0,,,,,,unknown,3 days,256 TPU-v3,,,,,,,136,text,audio,296
159,model,VATT,Google,VATT is a family of models trained on multimodal data,2022-04-22,https://arxiv.org/abs/2104.11178,155M parameters (dense),,AudioSet,,open,Apache 2.0,,,,,,unknown,3 days,256 TPU-v3,,,,,,,136,text,video,297
159,model,VATT,Google,VATT is a family of models trained on multimodal data,2022-04-22,https://arxiv.org/abs/2104.11178,155M parameters (dense),,HowTo100M,,open,Apache 2.0,,,,,,unknown,3 days,256 TPU-v3,,,,,,,136,text,video,298
160,model,PaLM,Google,"PaLM stands Pathways Language Model, ""dense decoder-only Transformer model trained with the Pathways system"" [[Google ai Blog]](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html).
",2022-04-04,https://arxiv.org/pdf/2204.02311.pdf,540B parameters (dense),"""PaLM is evaluated on English Natural Language Processing (NLP) tasks, tasks from BIG-bench, reasoning tasks, code completion tasks, multilingual generation and question answering tasks, translation tasks, and bias and toxicity benchmarks"" [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E).
",PaLM dataset,Unknown,limited,unknown,"""The primary use is research on language models, including: research on NLP applications like machine translation and question answering, advancing fairness and safety research, and understanding limitations of current LLMs. Within Google, PaLM is being used for research on a variety of open- ended text and code generation tasks, including reasoning [[Section 6.3]](https://arxiv.org/pdf/2204.02311.pdf#subsection.6.3) and code synthesis and understanding [[Section 6.4]](https://arxiv.org/pdf/2204.02311.pdf#subsection.6.4)"" [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E).
","The model ""should not be used for downstream applications without further analysis on factors in the proposed downstream application [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E)""
",unknown,Contact the authors.,https://arxiv.org/pdf/2204.02311.pdf#appendix.E,271.43 tCO2,29600 petaflop/s-days,6144 TPU v4 chips,,,,,,,137,text,text,299
160,model,PaLM,Google,"PaLM stands Pathways Language Model, ""dense decoder-only Transformer model trained with the Pathways system"" [[Google ai Blog]](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html).
",2022-04-04,https://arxiv.org/pdf/2204.02311.pdf,540B parameters (dense),"""PaLM is evaluated on English Natural Language Processing (NLP) tasks, tasks from BIG-bench, reasoning tasks, code completion tasks, multilingual generation and question answering tasks, translation tasks, and bias and toxicity benchmarks"" [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E).
",PaLM dataset,Unknown,limited,unknown,"""The primary use is research on language models, including: research on NLP applications like machine translation and question answering, advancing fairness and safety research, and understanding limitations of current LLMs. Within Google, PaLM is being used for research on a variety of open- ended text and code generation tasks, including reasoning [[Section 6.3]](https://arxiv.org/pdf/2204.02311.pdf#subsection.6.3) and code synthesis and understanding [[Section 6.4]](https://arxiv.org/pdf/2204.02311.pdf#subsection.6.4)"" [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E).
","The model ""should not be used for downstream applications without further analysis on factors in the proposed downstream application [[Model Card]](https://arxiv.org/pdf/2204.02311.pdf#appendix.E)""
",unknown,Contact the authors.,https://arxiv.org/pdf/2204.02311.pdf#appendix.E,271.43 tCO2,29600 petaflop/s-days,6144 TPU v4 chips,,,,,,,137,text,code,300
161,application,PaLM API,Google,a new developer offering that makes it easy and safe to experiment with Google’s language models.,2023-03-14,https://developers.googleblog.com/2023/03/announcing-palm-api-and-makersuite.html,,,PaLM,,limited,unknown,,,,,,,,,,,,,,,138,nan,nan,301
162,model,Med-PaLM,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,540B parameters (dense),,Flan-PaLM,,closed,unknown,,,,,,,,,,,,,,,139,text,text,302
162,model,Med-PaLM,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,540B parameters (dense),,MultiMedQA,,closed,unknown,,,,,,,,,,,,,,,139,text,text,303
163,model,Med-PaLM Multimodal,Google,,2023-07-26,https://arxiv.org/pdf/2307.14334.pdf,562B parameters (dense),Evaluated on MultiMedBench tasks and radiologist evaluations of model-generated chest X-ray reports,PaLM-E,,closed,unknown,,,,,,,,,,,,,,,140,image,text,304
163,model,Med-PaLM Multimodal,Google,,2023-07-26,https://arxiv.org/pdf/2307.14334.pdf,562B parameters (dense),Evaluated on MultiMedBench tasks and radiologist evaluations of model-generated chest X-ray reports,MultiMedBench,,closed,unknown,,,,,,,,,,,,,,,140,image,text,305
163,model,Med-PaLM Multimodal,Google,,2023-07-26,https://arxiv.org/pdf/2307.14334.pdf,562B parameters (dense),Evaluated on MultiMedBench tasks and radiologist evaluations of model-generated chest X-ray reports,PaLM-E,,closed,unknown,,,,,,,,,,,,,,,140,text,text,306
163,model,Med-PaLM Multimodal,Google,,2023-07-26,https://arxiv.org/pdf/2307.14334.pdf,562B parameters (dense),Evaluated on MultiMedBench tasks and radiologist evaluations of model-generated chest X-ray reports,MultiMedBench,,closed,unknown,,,,,,,,,,,,,,,140,text,text,307
163,model,Med-PaLM Multimodal,Google,,2023-07-26,https://arxiv.org/pdf/2307.14334.pdf,562B parameters (dense),Evaluated on MultiMedBench tasks and radiologist evaluations of model-generated chest X-ray reports,PaLM-E,,closed,unknown,,,,,,,,,,,,,,,140,genome sequence,text,308
163,model,Med-PaLM Multimodal,Google,,2023-07-26,https://arxiv.org/pdf/2307.14334.pdf,562B parameters (dense),Evaluated on MultiMedBench tasks and radiologist evaluations of model-generated chest X-ray reports,MultiMedBench,,closed,unknown,,,,,,,,,,,,,,,140,genome sequence,text,309
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,MedQA,,closed,unknown,,,,,,,,,,,,,,,141,text,text,310
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,MedMCQA,,closed,unknown,,,,,,,,,,,,,,,141,text,text,311
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,PubMedQA,,closed,unknown,,,,,,,,,,,,,,,141,text,text,312
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,MMLU,,closed,unknown,,,,,,,,,,,,,,,141,text,text,313
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,LiveQA,,closed,unknown,,,,,,,,,,,,,,,141,text,text,314
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,Medication QA,,closed,unknown,,,,,,,,,,,,,,,141,text,text,315
164,model,MultiMedQA,Google,,2022-12-26,https://arxiv.org/abs/2212.13138,unknown,,HealthSearchQA,,closed,unknown,,,,,,,,,,,,,,,141,text,text,316
165,model,Flan-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,PaLM,,closed,unknown,,,,,,,,,,,,,,,142,text,text,317
165,model,Flan-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,Muffin,,closed,unknown,,,,,,,,,,,,,,,142,text,text,318
165,model,Flan-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,P3,,closed,unknown,,,,,,,,,,,,,,,142,text,text,319
165,model,Flan-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,NaturalInstructions-v2,,closed,unknown,,,,,,,,,,,,,,,142,text,text,320
166,model,Flan-U-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,U-PaLM,,closed,unknown,,,,,,,,,,,,,,,143,text,text,321
166,model,Flan-U-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,Muffin,,closed,unknown,,,,,,,,,,,,,,,143,text,text,322
166,model,Flan-U-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,P3,,closed,unknown,,,,,,,,,,,,,,,143,text,text,323
166,model,Flan-U-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11416,540B parameters (dense),,NaturalInstructions-v2,,closed,unknown,,,,,,,,,,,,,,,143,text,text,324
168,model,U-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11399,540B parameters (dense),,PaLM,,closed,unknown,,,,,,,,,,,,,,,144,text,text,325
168,model,U-PaLM,Google,,2022-10-20,https://arxiv.org/abs/2210.11399,540B parameters (dense),,PaLM dataset,,closed,unknown,,,,,,,,,,,,,,,144,text,text,326
169,model,PaLM-SayCan,Google,,2022-08-16,https://arxiv.org/abs/2204.01691,540B parameters (dense),,PaLM,,closed,"unknown (model weights), Apache 2.0 (SayCan code)",,,,,,,,,,,,,,,145,text,robotics trajectories,327
170,model,GLaM,Google,,2021-12-13,https://arxiv.org/abs/2112.06905,1.2T parameters (sparse),,GLaM Web dataset,,closed,unknown,,,,,,,,,,,,,,,146,text,text,328
170,model,GLaM,Google,,2021-12-13,https://arxiv.org/abs/2112.06905,1.2T parameters (sparse),,Wikipedia,,closed,unknown,,,,,,,,,,,,,,,146,text,text,329
170,model,GLaM,Google,,2021-12-13,https://arxiv.org/abs/2112.06905,1.2T parameters (sparse),,GLaM Conversations dataset,,closed,unknown,,,,,,,,,,,,,,,146,text,text,330
170,model,GLaM,Google,,2021-12-13,https://arxiv.org/abs/2112.06905,1.2T parameters (sparse),,GLaM Forums dataset,,closed,unknown,,,,,,,,,,,,,,,146,text,text,331
170,model,GLaM,Google,,2021-12-13,https://arxiv.org/abs/2112.06905,1.2T parameters (sparse),,BooksCorpus,,closed,unknown,,,,,,,,,,,,,,,146,text,text,332
170,model,GLaM,Google,,2021-12-13,https://arxiv.org/abs/2112.06905,1.2T parameters (sparse),,GLaM News dataset,,closed,unknown,,,,,,,,,,,,,,,146,text,text,333
175,model,MUM,Google,MUM (Multitask Unified Model) is a multimodal model that is specialized for more complex queries.,2021-05-18,https://blog.google/products/search/introducing-mum/,unknown,,MUM dataset,,closed,unknown,,,,,,,,,,,,,,,147,image,text,334
175,model,MUM,Google,MUM (Multitask Unified Model) is a multimodal model that is specialized for more complex queries.,2021-05-18,https://blog.google/products/search/introducing-mum/,unknown,,MUM dataset,,closed,unknown,,,,,,,,,,,,,,,147,text,text,335
177,model,Phenaki,Google,,2023-02-01,https://openreview.net/pdf?id=vOEXS39nOF,1.8B parameters (dense),,LAION-400M,,closed,unknown,,,,,,,,,,,,,,,148,text,video,336
177,model,Phenaki,Google,,2023-02-01,https://openreview.net/pdf?id=vOEXS39nOF,1.8B parameters (dense),,Phenaki Video-Text Corpus,,closed,unknown,,,,,,,,,,,,,,,148,text,video,337
179,model,Flan-UL2,Google,,2023-03-02,https://arxiv.org/abs/2205.05131,20B parameters (dense),,UL2,,open,Apache 2.0,,,,,,,,,,,,,,,149,text,text,338
179,model,Flan-UL2,Google,,2023-03-02,https://arxiv.org/abs/2205.05131,20B parameters (dense),,Flan Collection,,open,Apache 2.0,,,,,,,,,,,,,,,149,text,text,339
181,model,MusicLM,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,1.4B parameters (dense),,SoundStream,,closed,unknown,,,,,,,,,,,,,,,150,text,audio,340
181,model,MusicLM,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,1.4B parameters (dense),,w2v-BERT,,closed,unknown,,,,,,,,,,,,,,,150,text,audio,341
181,model,MusicLM,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,1.4B parameters (dense),,MuLan,,closed,unknown,,,,,,,,,,,,,,,150,text,audio,342
181,model,MusicLM,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,1.4B parameters (dense),,MusicLM semantic model,,closed,unknown,,,,,,,,,,,,,,,150,text,audio,343
181,model,MusicLM,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,1.4B parameters (dense),,MusicLM acoustic model,,closed,unknown,,,,,,,,,,,,,,,150,text,audio,344
182,model,SoundStream,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,unknown,,Free Music Archive,,closed,unknown,,,,,,,,,,,,,,,151,audio,audio,345
183,model,w2v-BERT,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,600M parameters (dense),,Free Music Archive,,closed,unknown,,,,,,,,,,,,,,,152,audio,audio,346
184,model,MuLan,Google,,2022-08-26,https://arxiv.org/abs/2208.12415,unknown,,AST,,closed,unknown,,,,,,,,,,,,,,,153,text,audio,347
184,model,MuLan,Google,,2022-08-26,https://arxiv.org/abs/2208.12415,unknown,,BERT,,closed,unknown,,,,,,,,,,,,,,,153,text,audio,348
184,model,MuLan,Google,,2022-08-26,https://arxiv.org/abs/2208.12415,unknown,,MuLan dataset,,closed,unknown,,,,,,,,,,,,,,,153,text,audio,349
187,model,MusicLM semantic model,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,430M parameters (dense),,MusicLM dataset,,closed,unknown,,,,,,,,,,,,,,,154,audio,audio,350
188,model,MusicLM acoustic model,Google,,2023-01-26,https://arxiv.org/pdf/2301.11325.pdf,430M parameters (dense),,MusicLM dataset,,closed,unknown,,,,,,,,,,,,,,,155,audio,audio,351
189,model,Noise2Music,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,Noise2Music pseudolabel dataset,,closed,unknkown,,,,,,,,,,,,,,,156,audio,audio,352
189,model,Noise2Music,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,Noise2Music pseudolabel dataset,,closed,unknkown,,,,,,,,,,,,,,,156,text,audio,353
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,MuLan,,closed,unknown,,,,,,,,,,,,,,,157,audio,audio,354
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,MuLaMCap,,closed,unknown,,,,,,,,,,,,,,,157,audio,audio,355
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,LaMDA-LF,,closed,unknown,,,,,,,,,,,,,,,157,audio,audio,356
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,Rater-LF,,closed,unknown,,,,,,,,,,,,,,,157,audio,audio,357
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,Rater-SF,,closed,unknown,,,,,,,,,,,,,,,157,audio,audio,358
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,MuLan,,closed,unknown,,,,,,,,,,,,,,,157,text,audio,359
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,MuLaMCap,,closed,unknown,,,,,,,,,,,,,,,157,text,audio,360
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,LaMDA-LF,,closed,unknown,,,,,,,,,,,,,,,157,text,audio,361
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,Rater-LF,,closed,unknown,,,,,,,,,,,,,,,157,text,audio,362
193,model,Noise2Music pseudolabeler,Google,,2023-02-08,https://google-research.github.io/noise2music/noise2music.pdf,unknown,,Rater-SF,,closed,unknown,,,,,,,,,,,,,,,157,text,audio,363
196,application,AI Test Kitchen,Google,"AI Test Kitchen provides a new way for people to learn about, experience, and give feedback on emerging AI technology, like LaMDA.",2022-08-25,https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/,,,LaMDA,,limited,unknown,,,,,,,,,,,,,,,158,nan,nan,364
197,application,Bard,Google,"Conversational AI service, powered by LaMDA",2023-02-06,https://blog.google/technology/ai/bard-google-ai-search-updates/,,,LaMDA,,closed,unknown,,,,,,,,,,,,,,,159,nan,nan,365
198,model,Minerva,Google,,2022-06-29,https://arxiv.org/abs/2206.14858,540B parameters (dense),,PaLM,,closed,unknown,,,,,,,,,,,,,,,160,text,text,366
198,model,Minerva,Google,,2022-06-29,https://arxiv.org/abs/2206.14858,540B parameters (dense),,arXiv,,closed,unknown,,,,,,,,,,,,,,,160,text,text,367
198,model,Minerva,Google,,2022-06-29,https://arxiv.org/abs/2206.14858,540B parameters (dense),,PaLM dataset,,closed,unknown,,,,,,,,,,,,,,,160,text,text,368
198,model,Minerva,Google,,2022-06-29,https://arxiv.org/abs/2206.14858,540B parameters (dense),,Minerva Math Web Pages dataset,,closed,unknown,,,,,,,,,,,,,,,160,text,text,369
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,YT-NLU-U,,limited,unknown,,,,,,,,,,,,,,,161,audio,text,370
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,Pub-U,,limited,unknown,,,,,,,,,,,,,,,161,audio,text,371
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,Web-NTL,,limited,unknown,,,,,,,,,,,,,,,161,audio,text,372
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,YT-SUP+,,limited,unknown,,,,,,,,,,,,,,,161,audio,text,373
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,Pub-S,,limited,unknown,,,,,,,,,,,,,,,161,audio,text,374
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,YT-NLU-U,,limited,unknown,,,,,,,,,,,,,,,161,text,text,375
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,Pub-U,,limited,unknown,,,,,,,,,,,,,,,161,text,text,376
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,Web-NTL,,limited,unknown,,,,,,,,,,,,,,,161,text,text,377
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,YT-SUP+,,limited,unknown,,,,,,,,,,,,,,,161,text,text,378
200,model,USM,Google,"Universal Speech Model (USM) is a family of state-of-the-art speech models with 2B parameters trained on 12 million hours of speech and 28 billion sentences of text, spanning 300+ languages. USM, which is for use in YouTube (e.g., for closed captions), can perform automatic speech recognition (ASR) on widely-spoken languages like English and Mandarin, but also languages like Punjabi, Assamese, Santhali, Balinese, Shona, Malagasy, Luganda, Luo, Bambara, Soga, Maninka, Xhosa, Akan, Lingala, Chichewa, Nkore, Nzema to name a few. Some of these languages are spoken by fewer than twenty million people, making it very hard to find the necessary training data.",2023-03-06,https://arxiv.org/abs/2303.01037,2B parameters (dense),,Pub-S,,limited,unknown,,,,,,,,,,,,,,,161,text,text,379
201,application,YouTube,Google,YouTube is a global online video sharing and social media platform,2005-02-14,https://www.youtube.com/,,,USM,,open,,,,,,,,,,,,,,,,162,nan,nan,380
202,model,PaLM-E,Google,,2023-03-06,https://arxiv.org/abs/2303.03378,562B parameters (dense),,PaLM,,closed,unknown,,,,,,,,,,,,,,,163,image,text,381
202,model,PaLM-E,Google,,2023-03-06,https://arxiv.org/abs/2303.03378,562B parameters (dense),,ViT-22B,,closed,unknown,,,,,,,,,,,,,,,163,image,text,382
202,model,PaLM-E,Google,,2023-03-06,https://arxiv.org/abs/2303.03378,562B parameters (dense),,PaLM,,closed,unknown,,,,,,,,,,,,,,,163,text,text,383
202,model,PaLM-E,Google,,2023-03-06,https://arxiv.org/abs/2303.03378,562B parameters (dense),,ViT-22B,,closed,unknown,,,,,,,,,,,,,,,163,text,text,384
203,model,ViT-22B,Google,,2023-02-10,https://arxiv.org/abs/2302.05442,22B parameters (dense),,JFT,,closed,unknown,,,,,,,,,,,,,,,164,image,image,385
203,model,ViT-22B,Google,,2023-02-10,https://arxiv.org/abs/2302.05442,22B parameters (dense),,JFT,,closed,unknown,,,,,,,,,,,,,,,164,image,image,386
203,model,ViT-22B,Google,,2023-02-10,https://arxiv.org/abs/2302.05442,22B parameters (dense),,JFT,,closed,unknown,,,,,,,,,,,,,,,164,image,image,387
203,model,ViT-22B,Google,,2023-02-10,https://arxiv.org/abs/2302.05442,22B parameters (dense),,JFT,,closed,unknown,,,,,,,,,,,,,,,164,image,image,388
204,model,AudioLM,Google,,2022-09-07,https://arxiv.org/abs/2209.03143,1B parameters (dense),,w2v-BERT,,closed,unknown,,,,,,,,,,,,,,,165,audio,audio,389
204,model,AudioLM,Google,,2022-09-07,https://arxiv.org/abs/2209.03143,1B parameters (dense),,SoundStream,,closed,unknown,,,,,,,,,,,,,,,165,audio,audio,390
204,model,AudioLM,Google,,2022-09-07,https://arxiv.org/abs/2209.03143,1B parameters (dense),,w2v-BERT,,closed,unknown,,,,,,,,,,,,,,,165,text,audio,391
204,model,AudioLM,Google,,2022-09-07,https://arxiv.org/abs/2209.03143,1B parameters (dense),,SoundStream,,closed,unknown,,,,,,,,,,,,,,,165,text,audio,392
205,model,PaLI,Google,,2022-09-14,https://arxiv.org/abs/2209.06794,17B parameters (dense),,mT5,,closed,unknown,,,,,,,,,,,,,,,166,text,image,393
205,model,PaLI,Google,,2022-09-14,https://arxiv.org/abs/2209.06794,17B parameters (dense),,ViT-e,,closed,unknown,,,,,,,,,,,,,,,166,text,image,394
205,model,PaLI,Google,,2022-09-14,https://arxiv.org/abs/2209.06794,17B parameters (dense),,WebLI,,closed,unknown,,,,,,,,,,,,,,,166,text,image,395
206,model,ViT-e,Google,,2022-09-14,https://arxiv.org/abs/2209.06794,3.9B parameters (dense),,JFT,,closed,unknown,,,,,,,,,,,,,,,167,image,image,396
208,model,Vid2Seq,Google,,2023-02-27,https://arxiv.org/abs/2302.14115,500M parameters (dense),,T5,,open,Apache 2.0,,,,,,,,,,,,,,,168,video,text,397
208,model,Vid2Seq,Google,,2023-02-27,https://arxiv.org/abs/2302.14115,500M parameters (dense),,CLIP,,open,Apache 2.0,,,,,,,,,,,,,,,168,video,text,398
208,model,Vid2Seq,Google,,2023-02-27,https://arxiv.org/abs/2302.14115,500M parameters (dense),,YT-Temporal-1B,,open,Apache 2.0,,,,,,,,,,,,,,,168,video,text,399
209,model,Google Joint SLM,Google,Joint speech and language model using a Speech2Text adapter and using a CTC-based blank-filtering.,2023-06-08,https://arxiv.org/pdf/2306.07944.pdf,unknown,"evaluated on DSTC11 Challenge Task, based on MultiWoz 2.1, with a focus on dialog state tracking.",CTC blank-filtering,,closed,unknown,,,,,,,,,,,,,,,169,audio,text,400
209,model,Google Joint SLM,Google,Joint speech and language model using a Speech2Text adapter and using a CTC-based blank-filtering.,2023-06-08,https://arxiv.org/pdf/2306.07944.pdf,unknown,"evaluated on DSTC11 Challenge Task, based on MultiWoz 2.1, with a focus on dialog state tracking.",Speech2Text adapter,,closed,unknown,,,,,,,,,,,,,,,169,audio,text,401
210,model,PaLM 2,Google,PaLM 2 is a new state-of-the-art language model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture of objectives similar to UL2.,2023-05-10,https://blog.google/technology/ai/google-palm-2-ai-large-language-model/,unknown,Reports results on standard code benchmarks across a variety of programming languages.,PaLM 2 dataset,"Employed de-duplication, removal of sensitive-PII and filtering. Added control tokens marking toxicity of text.",open,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,Specific queries provided by annotators,https://ai.google/static/documents/palm2techreport.pdf,,,TPU v4 (number unspecified),,,,,,,170,text,text,402
211,model,MedLM,Google,"MedLM is a collection of foundation models tuned to follow natural language instructions for tasks in medicine, such as question answering and creating draft summaries.",2023-12-13,https://cloud.google.com/vertex-ai/docs/generative-ai/medlm/overview,unknown,"Assessed on medical benchmarks of professional medical exams, medical research, and consumer queries.",,,limited,unknown,"to be used for question answering and creating draft summaries from existing documentation, to be reviewed, edited, and approved by the user before use.",,Google internal monitoring,,https://cloud.google.com/static/vertex-ai/docs/generative-ai/medlm/MedLM-model-card.pdf,unknown,unknown,unknown,,,,,,,171,text,text,403
212,model,Gemini,Google,"As of release, Gemini is Google's most capable and flexible AI model, proficient in multimodal domains.",2023-12-06,https://deepmind.google/technologies/gemini/#introduction,unknown,"Evaluated on standard general, reasoning, math, coding, and multimodal benchmarks with results that surpass GPT-4 on almost all.",,,closed,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,,,unknown,unknown,unknown,,,,,,,172,text,image,404
212,model,Gemini,Google,"As of release, Gemini is Google's most capable and flexible AI model, proficient in multimodal domains.",2023-12-06,https://deepmind.google/technologies/gemini/#introduction,unknown,"Evaluated on standard general, reasoning, math, coding, and multimodal benchmarks with results that surpass GPT-4 on almost all.",,,closed,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,,,unknown,unknown,unknown,,,,,,,172,text,text,405
212,model,Gemini,Google,"As of release, Gemini is Google's most capable and flexible AI model, proficient in multimodal domains.",2023-12-06,https://deepmind.google/technologies/gemini/#introduction,unknown,"Evaluated on standard general, reasoning, math, coding, and multimodal benchmarks with results that surpass GPT-4 on almost all.",,,closed,unknown,"general use large language model that can be used for language, reasoning, and code tasks.",becoming part of a general-purpose service or product or use within specific downstream applications without prior assessment,Google internal monitoring,,,unknown,unknown,unknown,,,,,,,172,text,video,406
213,model,TimesFM,Google,TimesFM is a single forecasting model pre-trained on a large time-series corpus of 100 billion real world time-points.,2024-02-02,https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html,200M parameters (dense),Evaluated on popular time-series benchmarks.,,,closed,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,173,nan,nan,407
214,model,Gemma,Google,"Gemma is a family of lightweight, state-of-the-art open models from Google, based on the Gemini models. They are text-to-text, decoder-only large language models, available in English.",2024-02-21,https://blog.google/technology/developers/gemma-open-models/,7B parameters (dense),Evaluation was conducted on standard LLM benchmarks and includes internal red-teaming testing of relevant content policies.,,"Multiple evaluations and red-teaming conducted, with particular focus on ethics, bias, fair use cases, and safety.",open,custom,"Text generation tasks including question answering, summarization, and reasoning; content creation, communication, research, and education.",Prohibited uses are specified in the Gemma Prohibited Use Policy here https://ai.google.dev/gemma/prohibited_use_policy,,https://huggingface.co/google/gemma-7b/discussions,https://huggingface.co/google/gemma-7b,unknown,unknown,TPUv5e,,,,,,,174,text,text,408
215,model,Med-Gemini,Google,"Med-Gemini is a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly integrate the use of web search, and that can be efficiently tailored to novel modalities using custom encoders.",2024-04-29,https://arxiv.org/pdf/2404.18416,unknown,"Evaluated Med-Gemini on 14 medical benchmarks spanning text, multimodal and long-context applications, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpassing the GPT-4 model family on every benchmark where a direct comparison is viable.",Gemini,,closed,unknown,"To be used in areas of medical research including medical summarization, referral letter generation, and medical simplification tasks.",Unfit for real-world deployment in the safety-critical medical domain.,,,,unknown,unknown,unknown,,,,,,,175,image,text,409
215,model,Med-Gemini,Google,"Med-Gemini is a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly integrate the use of web search, and that can be efficiently tailored to novel modalities using custom encoders.",2024-04-29,https://arxiv.org/pdf/2404.18416,unknown,"Evaluated Med-Gemini on 14 medical benchmarks spanning text, multimodal and long-context applications, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpassing the GPT-4 model family on every benchmark where a direct comparison is viable.",MultiMedBench,,closed,unknown,"To be used in areas of medical research including medical summarization, referral letter generation, and medical simplification tasks.",Unfit for real-world deployment in the safety-critical medical domain.,,,,unknown,unknown,unknown,,,,,,,175,image,text,410
215,model,Med-Gemini,Google,"Med-Gemini is a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly integrate the use of web search, and that can be efficiently tailored to novel modalities using custom encoders.",2024-04-29,https://arxiv.org/pdf/2404.18416,unknown,"Evaluated Med-Gemini on 14 medical benchmarks spanning text, multimodal and long-context applications, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpassing the GPT-4 model family on every benchmark where a direct comparison is viable.",Gemini,,closed,unknown,"To be used in areas of medical research including medical summarization, referral letter generation, and medical simplification tasks.",Unfit for real-world deployment in the safety-critical medical domain.,,,,unknown,unknown,unknown,,,,,,,175,text,text,411
215,model,Med-Gemini,Google,"Med-Gemini is a family of highly capable multimodal models that are specialized in medicine with the ability to seamlessly integrate the use of web search, and that can be efficiently tailored to novel modalities using custom encoders.",2024-04-29,https://arxiv.org/pdf/2404.18416,unknown,"Evaluated Med-Gemini on 14 medical benchmarks spanning text, multimodal and long-context applications, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpassing the GPT-4 model family on every benchmark where a direct comparison is viable.",MultiMedBench,,closed,unknown,"To be used in areas of medical research including medical summarization, referral letter generation, and medical simplification tasks.",Unfit for real-world deployment in the safety-critical medical domain.,,,,unknown,unknown,unknown,,,,,,,175,text,text,412
216,model,HyperCLOVA,NAVER,HyperClova is an autoregressive language model,2021-05-21,https://arxiv.org/abs/2109.04650,82B parameters,,,,closed,unknown,,,,,,,130.4 days,1024 A100 GPUs,,,,,,,176,text,text,413
217,model,HyperCLOVA X,NAVER,"HyperCLOVA X is a family of large language models (LLMs) tailored to the Korean language and culture, along with competitive capabilities in English, math, and coding.",2024-04-13,https://arxiv.org/pdf/2404.01954,unknown,"Evaluated on English and Korean benchmarks in comparison to open source English and multilingual LLMs, with HyperCLOVA X (closed) surpassing the models compared.",,,limited,unknown,,,,,,unknown,unknown,unknown,,,,,,,177,text,text,414
218,application,Crisis Contact Simulator,The Trevor Project,"Crisis Contact Simulator, developed as part of a collaboration with Google.org, helps train The Trevor Project counselors by mimicking to be a teen in crisis. Crisis Contact Simulator is used as part of the training programs for the Trevor Project's 24/7 digital crisis services that supports LGBTQ youth [[Trevor Project Blog]](https://www.thetrevorproject.org/blog/the-trevor-project-launches-new-ai-tool-to-support-crisis-counselor-training/).
",2021-03-24,https://www.thetrevorproject.org/,,,OpenAI API,Limited release,closed,unknown,"Training counselors
",unknown,unknown,unknown,,,,,Fine-tuning,Dialogue,unknown,unknown,unknown,unknown,178,nan,nan,415
219,application,Ask Instacart,Instacart,"Instacart is augmenting the Instacart app to enable customers to ask about food and get inspirational, shoppable answers. This uses ChatGPT alongside Instacart’s own AI and product data from their 75,000+ retail partner store locations to help customers discover ideas for open-ended shopping goals, such as “How do I make great fish tacos?” or “What’s a healthy lunch for my kids?” Instacart plans to launch “Ask Instacart” later this year.",2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,ChatGPT API,,limited,,,,,,,,,,,,,,,,179,nan,nan,416
220,model,Firefly Image 2,Adobe,"Firefly Image 2 is the next generation of generative AI for imaging, bringing significant advancements to creative control and quality, including new Text to Image capabilities now available in the popular Firefly web app where 90% of users are new to Adobe products.",2023-10-10,https://firefly.adobe.com/,unknown,,,,closed,unknown,creative generation of digital art and images,"AI/ML training, attempting to create abusive, illegal, or confidential content.",,,,unknown,unknown,unknown,,,,,,,180,text,image,417
221,model,Firefly Vector,Adobe,"Firefly Vector is the world’s first generative AI focused on producing vector graphics, bringing Adobe's vector graphic and generative AI expertise directly into Adobe Illustrator workflows with Text to Vector Graphic.",2023-10-10,https://firefly.adobe.com/,unknown,,,,closed,unknown,creative generation of digital art and images,"AI/ML training, attempting to create abusive, illegal, or confidential content.",,,,unknown,unknown,unknown,,,,,,,181,text,vector graphic,418
222,model,Firefly Design,Adobe,Firefly Design powers instant generation of amazing quality template designs in Adobe Express with the new Text to Template capability.,2023-10-10,https://firefly.adobe.com/,unknown,,,,closed,unknown,creative generation of digital art and images,"AI/ML training, attempting to create abusive, illegal, or confidential content.",,,,unknown,unknown,unknown,,,,,,,182,text,template design,419
223,application,Firefly,Adobe,"Adobe Firefly is a standalone web application. It offers new ways to ideate, create, and communicate while significantly improving creative workflows using generative AI.",2023-03-21,https://firefly.adobe.com/,,,Firefly Image 2,,limited,unknown,creative generation of digital art and images,"AI/ML training, attempting to create abusive, illegal, or confidential content.",,,,,,,,AI-generated creations,https://www.adobe.com/legal/licenses-terms/adobe-gen-ai-user-guidelines.html,unknown,unknown,unknown,183,nan,nan,420
223,application,Firefly,Adobe,"Adobe Firefly is a standalone web application. It offers new ways to ideate, create, and communicate while significantly improving creative workflows using generative AI.",2023-03-21,https://firefly.adobe.com/,,,Firefly Vector,,limited,unknown,creative generation of digital art and images,"AI/ML training, attempting to create abusive, illegal, or confidential content.",,,,,,,,AI-generated creations,https://www.adobe.com/legal/licenses-terms/adobe-gen-ai-user-guidelines.html,unknown,unknown,unknown,183,nan,nan,421
223,application,Firefly,Adobe,"Adobe Firefly is a standalone web application. It offers new ways to ideate, create, and communicate while significantly improving creative workflows using generative AI.",2023-03-21,https://firefly.adobe.com/,,,Firefly Design,,limited,unknown,creative generation of digital art and images,"AI/ML training, attempting to create abusive, illegal, or confidential content.",,,,,,,,AI-generated creations,https://www.adobe.com/legal/licenses-terms/adobe-gen-ai-user-guidelines.html,unknown,unknown,unknown,183,nan,nan,422
225,model,GenSLM,Argonne National Laboratory,,2022-10-11,https://www.biorxiv.org/content/10.1101/2022.10.10.511571v1,25B parameters (dense),,SARS-CoV-2 genome dataset,,open,MIT,,,,,,,,,,,,,,,184,text,genome sequence,423
225,model,GenSLM,Argonne National Laboratory,,2022-10-11,https://www.biorxiv.org/content/10.1101/2022.10.10.511571v1,25B parameters (dense),,BV-BRC dataset,,open,MIT,,,,,,,,,,,,,,,184,text,genome sequence,424
226,application,Moonhub Recruiter,Moonhub,Moonhub Recruiter is the world's first AI-powered recruiter providing sourcing and recruiting services for startups and growing businesses.,2023-10-11,https://www.moonhub.ai/,,,Cohere Base,,limited,custom,recruiting candidates for business needs,,,,,,,,,job candidate matches,https://www.moonhub.ai/terms,unknown,unknown,,185,nan,nan,425
227,model,Skywork,Kunlun Inc.,The Skywork series is a family of large language models (LLMs) trained on a corpus of over 3.2 trillion tokens drawn from both English and Chinese texts.,2023-10-30,https://arxiv.org/pdf/2310.19341.pdf,13B parameters (dense),Evaluated on several popular benchmarks and performance in different fields.,SkyPile,,open,custom,,,,https://huggingface.co/Skywork/Skywork-13B-base/discussions,https://huggingface.co/Skywork/Skywork-13B-base,unknown,39 days,512 A800-80GB GPUs,,,,,,,186,text,text,426
229,model,Kotoba Speech,Kotoba Tech,Kotoba-Speech is a Transformer-based speech generative model that supports fluent text-to-speech generation in Japanese and one-shot voice cloning through speech prompt.,2024-03-13,https://huggingface.co/kotoba-tech/kotoba-speech-v0.1,1.2B parameters (dense),unknown,,,open,Apache 2.0,,,unknown,https://huggingface.co/kotoba-tech/kotoba-speech-v0.1/discussions,https://huggingface.co/kotoba-tech/kotoba-speech-v0.1,unknown,unknown,unknown,,,,,,,187,text,audio,427
230,application,Shop Assistant,Shop,"When shoppers search for products, the shopping assistant makes personalized recommendations based on their requests. Shop’s new AI-powered shopping assistant will streamline in-app shopping by scanning millions of products to quickly find what buyers are looking for—or help them discover something new.",2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,ChatGPT API,,open,,,,,,,,,,,,,,,,188,nan,nan,428
238,model,GPT-2,OpenAI,,2019-11-01,https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf,1.5B parameters (dense),,WebText,,open,Modified MIT License,,,,,https://github.com/openai/gpt-2/blob/master/model_card.md,,,,,,,,,,189,text,text,429
239,model,GPT-3,OpenAI,"GPT-3 is an autoregressive language model.
",2020-06-11,https://arxiv.org/pdf/2005.14165.pdf,175B parameters (dense),"The GPT-3 model was evaluated on language modeling, closed-book question answering, translation, Winograd-style tasks, commonsense reasoning, reading comprehension, SuperGLUE, NLI, synthetic tasks, and generation [[Section 4]](https://arxiv.org/pdf/2005.14165.pdf#section.4); as well as on fairness and biases [[Section 6]](https://arxiv.org/pdf/2005.14165.pdf#section.6).
",GPT-3 dataset,"One quality control method OpenAI employed was releasing GPT-3 only through the OpenAI API. OpenAI states that it is easier to respond to misuse when the access to the model is gated through the API. It also hints that it plans to broaden the API access over time based on the amount of misuse [[OpenAI API Blog Post]](https://openai.com/blog/openai-api/). The authors identify potential misuses of GPT-3 in the paper and analyze it for fairness, bias and representation issues, but do not identify mitigation strategies [[Section 6]](https://arxiv.org/pdf/2005.14165.pdf#section.6).
",limited,unknown,"GPT-3 was intended to be use through the OpenAI API by developers for language applications. Other intended use of GPT-3 include researchers accessing the model through the API to study its paradigms [[Model Card]](https://github.com/openai/gpt-3/blob/master/model-card.md).
","Access to GPT-3 is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
","OpenAI reviews all use cases of the model [[Model Card]](https://github.com/openai/gpt-3/blob/master/model-card.md).
","Feedback for GPT-3 can be provided on the feedback form linked in the model card [[Model Card]](https://github.com/openai/gpt-3/blob/master/model-card.md). The form is especially meant to collect feedback on concerns about misuse, synthetic text detection, bias, and risk of generative language models.
",https://github.com/openai/gpt-3/blob/master/model-card.md,552.1 tCO2e,3640 petaflop/s-days,Azure,,,,,,,190,text,text,430
240,model,Codex,OpenAI,"Codex is a GPT language model fine-tuned on publicly available code from GitHub.
",2021-08-10,https://arxiv.org/pdf/2107.03374.pdf,12B parameters (dense),"The model was evaluated using the HumanEval dataset with pass@k metric and BLEU scores [[Section 2]](https://arxiv.org/pdf/2107.03374.pdf#section.2).
",GPT-3,"The model wasn't fully released to the public as a quality control measure. The authors identify potential risks of Codex in their paper due to the following: over-reliance, misalignment, bias and representation, economic and labor market impacts, security implications, environmental impact and legal implications. They also make suggestions for some of these, but do not implement them in Codex [[Section 7]](https://arxiv.org/pdf/2107.03374.pdf#section.7).
",limited,unknown,"Codex is intended to be used for coding related language modelling tasks.
",unknown,unknown,"Email the authors [[Codex Paper]](https://arxiv.org/pdf/2107.03374.pdf).
",,unknown,100-1000 petaflop/s-days,Azure,,,,,,,191,text,code,431
240,model,Codex,OpenAI,"Codex is a GPT language model fine-tuned on publicly available code from GitHub.
",2021-08-10,https://arxiv.org/pdf/2107.03374.pdf,12B parameters (dense),"The model was evaluated using the HumanEval dataset with pass@k metric and BLEU scores [[Section 2]](https://arxiv.org/pdf/2107.03374.pdf#section.2).
",Codex dataset,"The model wasn't fully released to the public as a quality control measure. The authors identify potential risks of Codex in their paper due to the following: over-reliance, misalignment, bias and representation, economic and labor market impacts, security implications, environmental impact and legal implications. They also make suggestions for some of these, but do not implement them in Codex [[Section 7]](https://arxiv.org/pdf/2107.03374.pdf#section.7).
",limited,unknown,"Codex is intended to be used for coding related language modelling tasks.
",unknown,unknown,"Email the authors [[Codex Paper]](https://arxiv.org/pdf/2107.03374.pdf).
",,unknown,100-1000 petaflop/s-days,Azure,,,,,,,191,text,code,432
240,model,Codex,OpenAI,"Codex is a GPT language model fine-tuned on publicly available code from GitHub.
",2021-08-10,https://arxiv.org/pdf/2107.03374.pdf,12B parameters (dense),"The model was evaluated using the HumanEval dataset with pass@k metric and BLEU scores [[Section 2]](https://arxiv.org/pdf/2107.03374.pdf#section.2).
",HumanEval,"The model wasn't fully released to the public as a quality control measure. The authors identify potential risks of Codex in their paper due to the following: over-reliance, misalignment, bias and representation, economic and labor market impacts, security implications, environmental impact and legal implications. They also make suggestions for some of these, but do not implement them in Codex [[Section 7]](https://arxiv.org/pdf/2107.03374.pdf#section.7).
",limited,unknown,"Codex is intended to be used for coding related language modelling tasks.
",unknown,unknown,"Email the authors [[Codex Paper]](https://arxiv.org/pdf/2107.03374.pdf).
",,unknown,100-1000 petaflop/s-days,Azure,,,,,,,191,text,code,433
240,model,Codex,OpenAI,"Codex is a GPT language model fine-tuned on publicly available code from GitHub.
",2021-08-10,https://arxiv.org/pdf/2107.03374.pdf,12B parameters (dense),"The model was evaluated using the HumanEval dataset with pass@k metric and BLEU scores [[Section 2]](https://arxiv.org/pdf/2107.03374.pdf#section.2).
",GPT-3,"The model wasn't fully released to the public as a quality control measure. The authors identify potential risks of Codex in their paper due to the following: over-reliance, misalignment, bias and representation, economic and labor market impacts, security implications, environmental impact and legal implications. They also make suggestions for some of these, but do not implement them in Codex [[Section 7]](https://arxiv.org/pdf/2107.03374.pdf#section.7).
",limited,unknown,"Codex is intended to be used for coding related language modelling tasks.
",unknown,unknown,"Email the authors [[Codex Paper]](https://arxiv.org/pdf/2107.03374.pdf).
",,unknown,100-1000 petaflop/s-days,Azure,,,,,,,191,text,text,434
240,model,Codex,OpenAI,"Codex is a GPT language model fine-tuned on publicly available code from GitHub.
",2021-08-10,https://arxiv.org/pdf/2107.03374.pdf,12B parameters (dense),"The model was evaluated using the HumanEval dataset with pass@k metric and BLEU scores [[Section 2]](https://arxiv.org/pdf/2107.03374.pdf#section.2).
",Codex dataset,"The model wasn't fully released to the public as a quality control measure. The authors identify potential risks of Codex in their paper due to the following: over-reliance, misalignment, bias and representation, economic and labor market impacts, security implications, environmental impact and legal implications. They also make suggestions for some of these, but do not implement them in Codex [[Section 7]](https://arxiv.org/pdf/2107.03374.pdf#section.7).
",limited,unknown,"Codex is intended to be used for coding related language modelling tasks.
",unknown,unknown,"Email the authors [[Codex Paper]](https://arxiv.org/pdf/2107.03374.pdf).
",,unknown,100-1000 petaflop/s-days,Azure,,,,,,,191,text,text,435
240,model,Codex,OpenAI,"Codex is a GPT language model fine-tuned on publicly available code from GitHub.
",2021-08-10,https://arxiv.org/pdf/2107.03374.pdf,12B parameters (dense),"The model was evaluated using the HumanEval dataset with pass@k metric and BLEU scores [[Section 2]](https://arxiv.org/pdf/2107.03374.pdf#section.2).
",HumanEval,"The model wasn't fully released to the public as a quality control measure. The authors identify potential risks of Codex in their paper due to the following: over-reliance, misalignment, bias and representation, economic and labor market impacts, security implications, environmental impact and legal implications. They also make suggestions for some of these, but do not implement them in Codex [[Section 7]](https://arxiv.org/pdf/2107.03374.pdf#section.7).
",limited,unknown,"Codex is intended to be used for coding related language modelling tasks.
",unknown,unknown,"Email the authors [[Codex Paper]](https://arxiv.org/pdf/2107.03374.pdf).
",,unknown,100-1000 petaflop/s-days,Azure,,,,,,,191,text,text,436
241,model,InstructGPT,OpenAI,"InstructGPT is a family of GPT-3 based models fine-tuned on human feedback, which allows for better instruction following capabilities than GPT-3.
",2022-01-27,https://arxiv.org/pdf/2203.02155.pdf,175B parameters (dense),"The model was evaluated on human ratings to the InstructGPT answers to the prompts submitted to the OpenAI API as well as on public NLP datasets spanning truthfulness, toxicity, and bias, question answering, reading comprehension, and summarization tasks.",GPT-3,"The model wasn't fully released to the public as a quality control measure.
",closed,unknown,"As stated in the model card: ""The intended direct users of InstructGPT are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience, to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models"" [[Model Card]](https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md).
","Access to InstructGPT is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
",unknown,"Email the authors [[InstructGPT Paper]](https://arxiv.org/pdf/2203.02155.pdf).
",https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md,unknown,60 petaflops/s-days,unknown,,,,,,,192,text,code,437
241,model,InstructGPT,OpenAI,"InstructGPT is a family of GPT-3 based models fine-tuned on human feedback, which allows for better instruction following capabilities than GPT-3.
",2022-01-27,https://arxiv.org/pdf/2203.02155.pdf,175B parameters (dense),"The model was evaluated on human ratings to the InstructGPT answers to the prompts submitted to the OpenAI API as well as on public NLP datasets spanning truthfulness, toxicity, and bias, question answering, reading comprehension, and summarization tasks.",OpenAI API,"The model wasn't fully released to the public as a quality control measure.
",closed,unknown,"As stated in the model card: ""The intended direct users of InstructGPT are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience, to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models"" [[Model Card]](https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md).
","Access to InstructGPT is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
",unknown,"Email the authors [[InstructGPT Paper]](https://arxiv.org/pdf/2203.02155.pdf).
",https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md,unknown,60 petaflops/s-days,unknown,,,,,,,192,text,code,438
241,model,InstructGPT,OpenAI,"InstructGPT is a family of GPT-3 based models fine-tuned on human feedback, which allows for better instruction following capabilities than GPT-3.
",2022-01-27,https://arxiv.org/pdf/2203.02155.pdf,175B parameters (dense),"The model was evaluated on human ratings to the InstructGPT answers to the prompts submitted to the OpenAI API as well as on public NLP datasets spanning truthfulness, toxicity, and bias, question answering, reading comprehension, and summarization tasks.",GPT-3,"The model wasn't fully released to the public as a quality control measure.
",closed,unknown,"As stated in the model card: ""The intended direct users of InstructGPT are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience, to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models"" [[Model Card]](https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md).
","Access to InstructGPT is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
",unknown,"Email the authors [[InstructGPT Paper]](https://arxiv.org/pdf/2203.02155.pdf).
",https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md,unknown,60 petaflops/s-days,unknown,,,,,,,192,text,text,439
241,model,InstructGPT,OpenAI,"InstructGPT is a family of GPT-3 based models fine-tuned on human feedback, which allows for better instruction following capabilities than GPT-3.
",2022-01-27,https://arxiv.org/pdf/2203.02155.pdf,175B parameters (dense),"The model was evaluated on human ratings to the InstructGPT answers to the prompts submitted to the OpenAI API as well as on public NLP datasets spanning truthfulness, toxicity, and bias, question answering, reading comprehension, and summarization tasks.",OpenAI API,"The model wasn't fully released to the public as a quality control measure.
",closed,unknown,"As stated in the model card: ""The intended direct users of InstructGPT are developers who access its capabilities via the OpenAI API. Through the OpenAI API, the model can be used by those who may not have AI development experience, to build and explore language modeling systems across a wide range of functions. We also anticipate that the model will continue to be used by researchers to better understand the behaviors, capabilities, biases, and constraints of large-scale language models"" [[Model Card]](https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md).
","Access to InstructGPT is governed by Open AI API Usage Guidelines and API Terms of Use, prohibiting the use of the API in a way that causes societal harm. [[Usage Guidelines]] (https://beta.openai.com/docs/usage-guidelines/content-policy) [[Terms of Use]](https://openai.com/api/policies/terms/). The list of disallowed applications can be found in the usage guidelines [[Disallowed Applications]] (https://beta.openai.com/docs/usage-guidelines/disallowed-applications).
",unknown,"Email the authors [[InstructGPT Paper]](https://arxiv.org/pdf/2203.02155.pdf).
",https://github.com/openai/following-instructions-human-feedback/blob/main/model-card.md,unknown,60 petaflops/s-days,unknown,,,,,,,192,text,text,440
242,model,Whisper,OpenAI,Whisper is an audio transcription software.,2022-09-21,https://cdn.openai.com/papers/whisper.pdf,1.5B parameters (dense),"The model was evaluated for zero-shot English and multingual speech recognition, translation, language identification and robustness to noise.",Whisper dataset,No specific quality control methods are documented.,open,MIT,"Whisper is a general-purpose speech recognition model; it is a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.
",unknown,,"The discussions page of the codebase is not formally cited as a place for feedback, but is being used in this way [[Discussions page]](https://github.com/openai/whisper/discussions)
",https://github.com/openai/whisper/blob/main/model-card.md,unknown,unknown,Azure,,,,,,,193,audio,text,441
243,model,CLIP,OpenAI,"""CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs. It can be instructed in natural language to predict the most relevant text snippet, given an image, without directly optimizing for the task, similarly to the zero-shot capabilities of GPT-2 and 3. We found CLIP matches the performance of the original ResNet50 on ImageNet “zero-shot” without using any of the original 1.28M labeled examples, overcoming several major challenges in computer vision"" [[CLIP Repository]](https://github.com/openai/CLIP).
",2021-01-05,https://arxiv.org/pdf/2103.00020.pdf,unknown,"The model was evaluated on standard vision datasets (e.g. CIFAR10, ImageNet) and showed robust state of the art results.",CLIP dataset,"The authors found that the performance of the model depended heavily on which classes are included (and excluded) for a given task. They reported significant race and gender based disparities on the Fairface dataset, depending on how the classes were constructed. The authors also demonstrated that the model was capable of racial profiling with high accuracy [[Section 7]](https://arxiv.org/pdf/2103.00020.pdf#section.7).
",open,MIT,"The model is intended to be used by AI researchers to better understand ""robustness, generalization, and other capabilities, biases, and constraints of computer vision models"" [[CLIP Model Card]](https://github.com/openai/CLIP/blob/main/model-card.md).
","""Any deployed use case of the model - whether commercial or not - is currently out of scope. Non-deployed use cases such as image search in a constrained environment, are also not recommended unless there is thorough in-domain testing of the model with a specific, fixed class taxonomy. This is because our safety assessment demonstrated a high need for task specific testing especially given the variability of CLIP’s performance with different class taxonomies. This makes untested and unconstrained deployment of the model in any use case currently potentially harmful.
Certain use cases which would fall under the domain of surveillance and facial recognition are always out-of-scope regardless of performance of the model. This is because the use of artificial intelligence for tasks such as these can be premature currently given the lack of testing norms and checks to ensure its fair use.
Since the model has not been purposefully trained in or evaluated on any languages other than English, its use should be limited to English language use cases"" [[Model Card]](https://github.com/openai/CLIP/blob/main/model-card.mdlicen).
",,Questions can be shared at the feedback form linked in the CLIP model card [[Model Card]](https://github.com/openai/CLIP/blob/main/model-card.mdlicen).,https://github.com/openai/CLIP/blob/main/model-card.md,unknown,71.12 petaflop/s-day,NVIDIA V100 GPUs,,,,,,,194,image,text,442
243,model,CLIP,OpenAI,"""CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs. It can be instructed in natural language to predict the most relevant text snippet, given an image, without directly optimizing for the task, similarly to the zero-shot capabilities of GPT-2 and 3. We found CLIP matches the performance of the original ResNet50 on ImageNet “zero-shot” without using any of the original 1.28M labeled examples, overcoming several major challenges in computer vision"" [[CLIP Repository]](https://github.com/openai/CLIP).
",2021-01-05,https://arxiv.org/pdf/2103.00020.pdf,unknown,"The model was evaluated on standard vision datasets (e.g. CIFAR10, ImageNet) and showed robust state of the art results.",CLIP dataset,"The authors found that the performance of the model depended heavily on which classes are included (and excluded) for a given task. They reported significant race and gender based disparities on the Fairface dataset, depending on how the classes were constructed. The authors also demonstrated that the model was capable of racial profiling with high accuracy [[Section 7]](https://arxiv.org/pdf/2103.00020.pdf#section.7).
",open,MIT,"The model is intended to be used by AI researchers to better understand ""robustness, generalization, and other capabilities, biases, and constraints of computer vision models"" [[CLIP Model Card]](https://github.com/openai/CLIP/blob/main/model-card.md).
","""Any deployed use case of the model - whether commercial or not - is currently out of scope. Non-deployed use cases such as image search in a constrained environment, are also not recommended unless there is thorough in-domain testing of the model with a specific, fixed class taxonomy. This is because our safety assessment demonstrated a high need for task specific testing especially given the variability of CLIP’s performance with different class taxonomies. This makes untested and unconstrained deployment of the model in any use case currently potentially harmful.
Certain use cases which would fall under the domain of surveillance and facial recognition are always out-of-scope regardless of performance of the model. This is because the use of artificial intelligence for tasks such as these can be premature currently given the lack of testing norms and checks to ensure its fair use.
Since the model has not been purposefully trained in or evaluated on any languages other than English, its use should be limited to English language use cases"" [[Model Card]](https://github.com/openai/CLIP/blob/main/model-card.mdlicen).
",,Questions can be shared at the feedback form linked in the CLIP model card [[Model Card]](https://github.com/openai/CLIP/blob/main/model-card.mdlicen).,https://github.com/openai/CLIP/blob/main/model-card.md,unknown,71.12 petaflop/s-day,NVIDIA V100 GPUs,,,,,,,194,text,text,443
244,model,DALL·E,OpenAI,"DALL·E is a GPT-3 based model trained to generate images from text descriptions. The authors found that it had ""a diverse set of capabilities, including creating anthropomorphized versions of animals and objects, combining unrelated concepts in plausible ways, rendering text, and applying transformations to existing images"" [[OpenAI Blog Post]](https://openai.com/blog/dall-e/).
",2021-01-05,https://arxiv.org/pdf/2102.12092.pdf,12B parameters (dense),"The model was evaluated against three prior approaches, AttnGAN, DM-GAN, and DF-GAN using Inception Score and Fréchet Inception Distance on MS-COCO as metrics. The model was also evaluated by humans and received the majority of the votes in generating images that look realistic and better match the caption when compared to the images generated by DF-GAN [[Section]](https://arxiv.org/pdf/2102.12092.pdf#section.3).
",DALL·E dataset,unknown,limited,unknown,"""The model is intended for others to use for training their own generative models"" [[Model Card]](https://github.com/openai/DALL-E/blob/master/model_card.md).
",unknown,,"Contact the paper author(s) specified on the paper [[Paper]](https://arxiv.org/pdf/2102.12092.pdf).
",https://github.com/openai/DALL-E/blob/master/model_card.md,unknown,unknown,NVIDIA V100 GPUs,,,,,,,195,text,image,444
245,model,Jukebox,OpenAI,Jukebox is a generative model that produces music,2020-04-30,https://arxiv.org/abs/2005.00341,5B parameters (dense),Evaluations in paper are primarily considering the fidelity and novelty of samples from Jukebox.,Jukebox Dataset,,open,Noncommercial Use License,,,,,,unknown,4 weeks,510 V100s,,,,,,,196,text,audio,445
246,model,DALL·E 2,OpenAI,"""DALL·E 2 is an artificial intelligence model that takes a text prompt and/or existing image as an input and generates a new image as an output"" [[System Card]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md). The model wasn't fully released, but OpenAI released a version of the model (DALL·E 2 Preview) to a select group of testers.
",2022-04-13,https://arxiv.org/abs/2204.06125,unknown,The model is capable of generating explicit content and the researchers found limited amount of spurious content generated. The researchers also found that visual synonyms can be used to prompt the model to surface unwanted generations [[Probes and Evaluations]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#probes-and-evaluations).,DALL·E dataset,The model is not fully released to the public as part of a quality control measure. The usage of the model by testers is monitored and user provided prompts are filtered [[Input filters]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#input-filters).,limited,unknown,"""The intended use of the DALL·E 2 Preview at this time is for personal, non-commercial exploration and research purposes by people who are interested in understanding the potential uses of these capabilities"" [[Use]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#use).
","Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version [[Content Policy]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#policies-and-enforcement).","Uses of the model are monitored. In the preview version, any user can flag content. The specific policies for monitoring are not disclosed, but possible measures include disabling of accounts violating the content policies [[Monitoring and Reporting]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#monitoring-and-reporting).
'",Feedback can be provided at support at openai.com.,https://github.com/openai/dalle-2-preview/blob/main/system-card.md,unknown,unknown,unknown,,,,,,,197,text,image,446
246,model,DALL·E 2,OpenAI,"""DALL·E 2 is an artificial intelligence model that takes a text prompt and/or existing image as an input and generates a new image as an output"" [[System Card]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md). The model wasn't fully released, but OpenAI released a version of the model (DALL·E 2 Preview) to a select group of testers.
",2022-04-13,https://arxiv.org/abs/2204.06125,unknown,The model is capable of generating explicit content and the researchers found limited amount of spurious content generated. The researchers also found that visual synonyms can be used to prompt the model to surface unwanted generations [[Probes and Evaluations]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#probes-and-evaluations).,CLIP dataset,The model is not fully released to the public as part of a quality control measure. The usage of the model by testers is monitored and user provided prompts are filtered [[Input filters]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#input-filters).,limited,unknown,"""The intended use of the DALL·E 2 Preview at this time is for personal, non-commercial exploration and research purposes by people who are interested in understanding the potential uses of these capabilities"" [[Use]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#use).
","Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version [[Content Policy]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#policies-and-enforcement).","Uses of the model are monitored. In the preview version, any user can flag content. The specific policies for monitoring are not disclosed, but possible measures include disabling of accounts violating the content policies [[Monitoring and Reporting]] (https://github.com/openai/dalle-2-preview/blob/main/system-card.md#monitoring-and-reporting).
'",Feedback can be provided at support at openai.com.,https://github.com/openai/dalle-2-preview/blob/main/system-card.md,unknown,unknown,unknown,,,,,,,197,text,image,447
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,GPT-3,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,448
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,Codex,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,449
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,code-davinci-002,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,450
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,text-davinci-002,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,451
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,text-davinci-003,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,452
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,gpt-3.5-turbo,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,453
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,Whisper,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,454
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,DALL·E,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,455
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,GPT-4,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,456
247,application,OpenAI API,OpenAI,"OpenAI API is a general purpose ""text in, text out"" interface connecting users with a suite of language models. The API was initially released as a gateway to GPT-3, but it now supports access to other, more specialized OpenAI models. [[Open AI Blog Post]](https://openai.com/blog/openai-api/)
",2020-06-11,https://openai.com/api/,,,GPT-4 Turbo,"Given a prompt, OpenAI API checks whether a completion contains unsafe language using its filters and marks the completion accordingly if so. The API also provides developers with special endpoints that scope the API usage. OpenAI also developed user guidelines to help developers understand safety issues [[OpenAI API]](https://openai.com/api/).
",limited,custom,"OpenAI API was designed to be used by developers to empower applications, and researchers to study language models [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI API Terms of Use prohibits the use of the API in a way violating the applicable law, including: (i) ""Illegal activities, such as child pornography, gambling, cybercrime, piracy, violating copyright, trademark or other intellectual property laws""; (ii) ""Accessing or authorizing anyone to access the APIs from an embargoed country, region, or territory as prohibited by the U.S. government""; (iii) ""Threatening, stalking, defaming, defrauding, degrading, victimizing or intimidating anyone for any reason"". The usage requirements are detailed in the Terms of Use [[Section 3]](https://openai.com/api/policies/terms/).
","OpenAI may monitor the API use to ensure ""quality and improve OpenAI systems, products and services; perform research; and ensure compliance"" with the Terms of Service and all applicable laws. Users of the API will give OpenAI reasonable access to their application to monitor compliance with the terms listed in the Terms of Service [[Section 5(b)]](https://openai.com/api/policies/terms/). Apps using the OpenAI API should submit an application once they are deployed to real users. The review form takes 10 minutes to complete and over 97% of the applications are directly accepted or conditionally accepted. The applicants are notified of the decision within 2 business days [[App Review Guidelines]] (https://beta.openai.com/docs/usage-guidelines/app-review).
",unknown,,,,,The API exposes the models fairly direclty with a range of hyperparameters (e.g. temperature scaling).,"Given a prompting text, the OpenAI API provides access to text completions, and log probabilities. The support for text and code embeddings were added on 2022-01-25 [[OpenAI Blog Post]] (https://openai.com/blog/introducing-text-and-code-embeddings/).
",https://openai.com/api/policies/terms/,unknown,unknown,unknown,198,nan,nan,457
248,model,VPT,OpenAI,,2022-06-23,https://arxiv.org/abs/2206.11795,500M parameters (dense),,web_clean,,open,MIT,,,,,,,,,,,,,,,199,video,video,458
250,application,ChatGPT,OpenAI,ChatGPT is an artificial intelligence chatbot developed by OpenAI.,2022-11-30,https://openai.com/blog/chatgpt,,,gpt-3.5-turbo,,limited,custom,,,,,,,,,,,,100M,,,200,nan,nan,459
250,application,ChatGPT,OpenAI,ChatGPT is an artificial intelligence chatbot developed by OpenAI.,2022-11-30,https://openai.com/blog/chatgpt,,,OpenAI toxicity classifier,,limited,custom,,,,,,,,,,,,100M,,,200,nan,nan,460
251,model,gpt-3.5-turbo,OpenAI,,2023-03-01,https://platform.openai.com/docs/models/gpt-3-5,unknown,,gpt-3.5-turbo dataset,,limited,custom,,,,,,,,,,,,,,,201,text,text,461
252,model,GPT-4 Turbo,OpenAI,GPT-4 Turbo is a more capable version of GPT-4 and has knowledge of world events up to April 2023. It has a 128k context window so it can fit the equivalent of more than 300 pages of text in a single prompt.,2023-11-06,https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo,unknown,,,,limited,custom,,,unknown,,,unknown,unknown,unknown,,,,,,,202,text,text,462
255,model,code-davinci-002,OpenAI,,2022-05-01,https://platform.openai.com/docs/model-index-for-researchers,unknown,,code-davinci-002 dataset,,limited,unknown,,,,,,,,,,,,,,,203,text,code,463
255,model,code-davinci-002,OpenAI,,2022-05-01,https://platform.openai.com/docs/model-index-for-researchers,unknown,,code-davinci-002 dataset,,limited,unknown,,,,,,,,,,,,,,,203,text,text,464
256,model,text-davinci-002,OpenAI,,2022-05-01,https://platform.openai.com/docs/model-index-for-researchers,unknown,,code-davinci-002,,limited,unknown,,,,,,,,,,,,,,,204,text,text,465
257,model,text-davinci-003,OpenAI,,2022-11-30,https://platform.openai.com/docs/model-index-for-researchers,unknown,,text-davinci-002,,limited,unknown,,,,,,,,,,,,,,,205,text,text,466
258,application,Whisper API,OpenAI,API to query OpenAI's Whisper model.,2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,Whisper,,open,custom,,,,,,,,,,,,,,,206,nan,nan,467
259,application,ChatGPT API,OpenAI,API to query OpenAI's ChatGPT model.,2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,ChatGPT,,open,custom,,,,,,,,,,,,,,,207,nan,nan,468
260,application,OpenAI Moderation API,OpenAI,This endpoint provides OpenAI API developers with free access to GPT-based classifiers that detect undesired content—an instance of using AI systems to assist with human supervision of these systems.,2022-08-10,https://openai.com/blog/new-and-improved-content-moderation-tooling,,,OpenAI toxicity classifier,,open,custom,,,,,,,,,,,,,,,208,nan,nan,469
261,model,OpenAI toxicity classifier,OpenAI,,2023-01-18,"https://time.com/6247678/openai-chatgpt-kenya-workers/#:~:text=In%20a%20statement%2C%20an%20OpenAI,datasets%20of%20tools%20like%20ChatGPT.",unknown,,OpenAI toxicity dataset,,closed,unknown,,,,,,,,,,,,,,,209,text,text,470
263,application,Sage API,OpenAI,A chatbot language model available via Quora's Poe,2023-02-03,https://quorablog.quora.com/Poe-1,,,Sage,,limited,unknown,,,,,,,,,,,,,,,210,nan,nan,471
264,application,Dragonfly API,OpenAI,A chatbot language model available via Quora's Poe,2023-02-03,https://quorablog.quora.com/Poe-1,,,Dragonfly,,limited,unknown,,,,,,,,,,,,,,,211,nan,nan,472
265,model,Sage,OpenAI,A chatbot language model available via Quora's Poe,2023-02-03,https://quorablog.quora.com/Poe-1,unknown,,,,limited,unknown,,,,,,,,,,,,,,,212,text,text,473
266,model,Dragonfly,OpenAI,A chatbot language model available via Quora's Poe,2023-02-03,https://quorablog.quora.com/Poe-1,unknown,,,,limited,unknown,,,,,,,,,,,,,,,213,text,text,474
267,application,ChatGPT for Slack,"OpenAI, Salesforce","The app integrates ChatGPT’s powerful AI technology to deliver instant conversation summaries, research tools, and writing assistance directly in Slack to help millions of companies work more productively.",2023-03-07,https://www.salesforce.com/news/stories/chatgpt-app-for-slack/,,,ChatGPT API,,limited,unknown,,,,,,,,,,,,,,,214,nan,nan,475
268,model,GPT-4,OpenAI,,2023-03-14,https://arxiv.org/abs/2303.08774,unknown,,,,limited,unknown,,,,,,,,,,,,,,,215,image,image,476
268,model,GPT-4,OpenAI,,2023-03-14,https://arxiv.org/abs/2303.08774,unknown,,,,limited,unknown,,,,,,,,,,,,,,,215,image,text,477
268,model,GPT-4,OpenAI,,2023-03-14,https://arxiv.org/abs/2303.08774,unknown,,,,limited,unknown,,,,,,,,,,,,,,,215,text,image,478
268,model,GPT-4,OpenAI,,2023-03-14,https://arxiv.org/abs/2303.08774,unknown,,,,limited,unknown,,,,,,,,,,,,,,,215,text,text,479
269,application,GPT-4 API,OpenAI,"GPT-4 is OpenAI’s most advanced system, producing safer and more useful responses",2023-03-14,https://openai.com/product/gpt-4,,,GPT-4,,limited,custom,,,,,,,,,,,,,,,216,nan,nan,480
270,application,ChatGPT Enterprise,OpenAI,"ChatGPT Enterprise offers enterprise-grade security and privacy, unlimited higher-speed GPT-4 access, longer context windows for processing longer inputs, advanced data analysis capabilities, and customization options compared to OpenAI's previous offerings.",2023-08-28,https://openai.com/enterprise,,,GPT-4,,limited,custom,,,,,,,,,,,https://openai.com/policies/terms-of-use,,,,217,nan,nan,481
271,model,DALL·E 3,OpenAI,"DALL·E 3 is an artificial intelligence model that takes a text prompt and/or existing image as an input and generates a new image as an output The model is now in research preview, and will be available to ChatGPT Plus and Enterprise customers in October.",2023-09-20,https://openai.com/dall-e-3,unknown,The model is capable of generating explicit content and the researchers found limited amount of spurious content generated.,DALL·E 2 dataset,"DALL·E 3 has mitigations to decline requests that ask for a public figure by name. We improved safety performance in risk areas like generation of public figures and harmful biases related to visual over/under-representation, in partnership with red teamers—domain experts who stress-test the model—to help inform our risk assessment and mitigation efforts in areas like propaganda and misinformation.",limited,custom,"The intended use of the DALL·E 3 Preview at this time is for personal, non-commercial exploration and research purposes by people who are interested in understanding the potential uses of these capabilities","Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version.","Uses of the model are monitored. In the preview version, any user can flag content. The specific policies for monitoring are not disclosed, but possible measures include disabling of accounts violating the content",Feedback can be provided at openai.com,,unknown,unknown,unknown,,,,,,,218,text,image,482
271,model,DALL·E 3,OpenAI,"DALL·E 3 is an artificial intelligence model that takes a text prompt and/or existing image as an input and generates a new image as an output The model is now in research preview, and will be available to ChatGPT Plus and Enterprise customers in October.",2023-09-20,https://openai.com/dall-e-3,unknown,The model is capable of generating explicit content and the researchers found limited amount of spurious content generated.,CLIP dataset,"DALL·E 3 has mitigations to decline requests that ask for a public figure by name. We improved safety performance in risk areas like generation of public figures and harmful biases related to visual over/under-representation, in partnership with red teamers—domain experts who stress-test the model—to help inform our risk assessment and mitigation efforts in areas like propaganda and misinformation.",limited,custom,"The intended use of the DALL·E 3 Preview at this time is for personal, non-commercial exploration and research purposes by people who are interested in understanding the potential uses of these capabilities","Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version.","Uses of the model are monitored. In the preview version, any user can flag content. The specific policies for monitoring are not disclosed, but possible measures include disabling of accounts violating the content",Feedback can be provided at openai.com,,unknown,unknown,unknown,,,,,,,218,text,image,483
271,model,DALL·E 3,OpenAI,"DALL·E 3 is an artificial intelligence model that takes a text prompt and/or existing image as an input and generates a new image as an output The model is now in research preview, and will be available to ChatGPT Plus and Enterprise customers in October.",2023-09-20,https://openai.com/dall-e-3,unknown,The model is capable of generating explicit content and the researchers found limited amount of spurious content generated.,ChatGPT,"DALL·E 3 has mitigations to decline requests that ask for a public figure by name. We improved safety performance in risk areas like generation of public figures and harmful biases related to visual over/under-representation, in partnership with red teamers—domain experts who stress-test the model—to help inform our risk assessment and mitigation efforts in areas like propaganda and misinformation.",limited,custom,"The intended use of the DALL·E 3 Preview at this time is for personal, non-commercial exploration and research purposes by people who are interested in understanding the potential uses of these capabilities","Use of the model is governed by the OpenAI Content Policy, which prohibits posting of G rated content. Users are not allowed to utilize the model in commercial products in the preview version.","Uses of the model are monitored. In the preview version, any user can flag content. The specific policies for monitoring are not disclosed, but possible measures include disabling of accounts violating the content",Feedback can be provided at openai.com,,unknown,unknown,unknown,,,,,,,218,text,image,484
272,model,Sora,OpenAI,Sora is an AI model that can create realistic and imaginative scenes from text instructions.,2024-02-15,https://openai.com/sora,unknown,,,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,219,text,image,485
272,model,Sora,OpenAI,Sora is an AI model that can create realistic and imaginative scenes from text instructions.,2024-02-15,https://openai.com/sora,unknown,,,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,219,text,video,486
273,model,Ideogram 1.0,Ideogram AI,"Ideogram 1.0 is Ideogram’s most advanced text-to-image model, as of release.",2024-02-28,https://about.ideogram.ai/1.0,unknown,Compared to DALL·E 3 based on a qualitative user comparison.,,,limited,unknown,,,,,,unknown,unknown,unknown,,,,,,,220,text,image,487
275,model,BloombergGPT,Bloomberg,BloombergGPT is a 50 billion parameter large language model that is specifically trained on a wide range of financial data to support a diverse set of natural language processing tasks within the financial industry.,2023-03-30,https://arxiv.org/abs/2303.17564,50B parameters (dense),"Authors evaluate the performance of BloombergGPT on two broad categories of tasks, finance-specific and general purpose, on several standard benchmarks. They compare BloombergGPT to the three closest models: GPT-NeoX, OPT-66B and BLOOM-176B. They also report results from the original GPT-3 whenever externally available. They conclude ""We achieve strong results on general LLM benchmarks and outperform comparable models on financial tasks. We attribute this, in decreasing order of impact, to 1. a well-curated internal dataset, 2. our unique choice in tokenizer, and 3. an up-to-date architecture.""
",FinPile,"Authors state the following:
- ""To provide natural language applications to the financial community, we
  have developed a rigorous risk and testing assessment process. This process
  includes careful annotation guidelines Tseng et al. (2020), pre-launch review
  at multiple levels by the central risk and compliance organizations, and
  by the product leaders (e.g., the newsroom) as applicable, and post-launch
  monitoring. Moreover, we conduct our research, development, and deployment
  of NLP and AI systems in accordance with all applicable regulations.""
- ""Similarly, toxicity and bias are areas where, as a company, we take extraordinary
  care with any content we produce, whether from humans or machines. Since
  the measurement of toxicity and bias in our model depends on its application
  areas, quantifying the potential for the generation of harmful language
  remains an open question. We are particularly interested in studying whether
  FinPile, which is cleaner and contains fewer examples of overtly biased
  or toxic language (e.g., Press Releases), reduces the proclivity of the
  model to generate inappropriate content.""
",closed,unknown,"""This model will assist Bloomberg in improving existing financial NLP tasks, such as sentiment analysis, named entity recognition, news classification, and question answering, among others. Furthermore, BloombergGPT will unlock new opportunities for marshalling the vast quantities of data available on the Bloomberg Terminal to better help the firm's customers, while bringing the full potential of AI to the financial domain.""
",,,,,unknown,53 days,64 Amazon EC2 p4d.24xlarge instances each with 8 NVIDIA 40GB A100 GPUs (i.e. total 512 A100 GPUs),,,,,,,221,text,text,488
275,model,BloombergGPT,Bloomberg,BloombergGPT is a 50 billion parameter large language model that is specifically trained on a wide range of financial data to support a diverse set of natural language processing tasks within the financial industry.,2023-03-30,https://arxiv.org/abs/2303.17564,50B parameters (dense),"Authors evaluate the performance of BloombergGPT on two broad categories of tasks, finance-specific and general purpose, on several standard benchmarks. They compare BloombergGPT to the three closest models: GPT-NeoX, OPT-66B and BLOOM-176B. They also report results from the original GPT-3 whenever externally available. They conclude ""We achieve strong results on general LLM benchmarks and outperform comparable models on financial tasks. We attribute this, in decreasing order of impact, to 1. a well-curated internal dataset, 2. our unique choice in tokenizer, and 3. an up-to-date architecture.""
",The Pile,"Authors state the following:
- ""To provide natural language applications to the financial community, we
  have developed a rigorous risk and testing assessment process. This process
  includes careful annotation guidelines Tseng et al. (2020), pre-launch review
  at multiple levels by the central risk and compliance organizations, and
  by the product leaders (e.g., the newsroom) as applicable, and post-launch
  monitoring. Moreover, we conduct our research, development, and deployment
  of NLP and AI systems in accordance with all applicable regulations.""
- ""Similarly, toxicity and bias are areas where, as a company, we take extraordinary
  care with any content we produce, whether from humans or machines. Since
  the measurement of toxicity and bias in our model depends on its application
  areas, quantifying the potential for the generation of harmful language
  remains an open question. We are particularly interested in studying whether
  FinPile, which is cleaner and contains fewer examples of overtly biased
  or toxic language (e.g., Press Releases), reduces the proclivity of the
  model to generate inappropriate content.""
",closed,unknown,"""This model will assist Bloomberg in improving existing financial NLP tasks, such as sentiment analysis, named entity recognition, news classification, and question answering, among others. Furthermore, BloombergGPT will unlock new opportunities for marshalling the vast quantities of data available on the Bloomberg Terminal to better help the firm's customers, while bringing the full potential of AI to the financial domain.""
",,,,,unknown,53 days,64 Amazon EC2 p4d.24xlarge instances each with 8 NVIDIA 40GB A100 GPUs (i.e. total 512 A100 GPUs),,,,,,,221,text,text,489
275,model,BloombergGPT,Bloomberg,BloombergGPT is a 50 billion parameter large language model that is specifically trained on a wide range of financial data to support a diverse set of natural language processing tasks within the financial industry.,2023-03-30,https://arxiv.org/abs/2303.17564,50B parameters (dense),"Authors evaluate the performance of BloombergGPT on two broad categories of tasks, finance-specific and general purpose, on several standard benchmarks. They compare BloombergGPT to the three closest models: GPT-NeoX, OPT-66B and BLOOM-176B. They also report results from the original GPT-3 whenever externally available. They conclude ""We achieve strong results on general LLM benchmarks and outperform comparable models on financial tasks. We attribute this, in decreasing order of impact, to 1. a well-curated internal dataset, 2. our unique choice in tokenizer, and 3. an up-to-date architecture.""
",C4,"Authors state the following:
- ""To provide natural language applications to the financial community, we
  have developed a rigorous risk and testing assessment process. This process
  includes careful annotation guidelines Tseng et al. (2020), pre-launch review
  at multiple levels by the central risk and compliance organizations, and
  by the product leaders (e.g., the newsroom) as applicable, and post-launch
  monitoring. Moreover, we conduct our research, development, and deployment
  of NLP and AI systems in accordance with all applicable regulations.""
- ""Similarly, toxicity and bias are areas where, as a company, we take extraordinary
  care with any content we produce, whether from humans or machines. Since
  the measurement of toxicity and bias in our model depends on its application
  areas, quantifying the potential for the generation of harmful language
  remains an open question. We are particularly interested in studying whether
  FinPile, which is cleaner and contains fewer examples of overtly biased
  or toxic language (e.g., Press Releases), reduces the proclivity of the
  model to generate inappropriate content.""
",closed,unknown,"""This model will assist Bloomberg in improving existing financial NLP tasks, such as sentiment analysis, named entity recognition, news classification, and question answering, among others. Furthermore, BloombergGPT will unlock new opportunities for marshalling the vast quantities of data available on the Bloomberg Terminal to better help the firm's customers, while bringing the full potential of AI to the financial domain.""
",,,,,unknown,53 days,64 Amazon EC2 p4d.24xlarge instances each with 8 NVIDIA 40GB A100 GPUs (i.e. total 512 A100 GPUs),,,,,,,221,text,text,490
275,model,BloombergGPT,Bloomberg,BloombergGPT is a 50 billion parameter large language model that is specifically trained on a wide range of financial data to support a diverse set of natural language processing tasks within the financial industry.,2023-03-30,https://arxiv.org/abs/2303.17564,50B parameters (dense),"Authors evaluate the performance of BloombergGPT on two broad categories of tasks, finance-specific and general purpose, on several standard benchmarks. They compare BloombergGPT to the three closest models: GPT-NeoX, OPT-66B and BLOOM-176B. They also report results from the original GPT-3 whenever externally available. They conclude ""We achieve strong results on general LLM benchmarks and outperform comparable models on financial tasks. We attribute this, in decreasing order of impact, to 1. a well-curated internal dataset, 2. our unique choice in tokenizer, and 3. an up-to-date architecture.""
",Wikipedia,"Authors state the following:
- ""To provide natural language applications to the financial community, we
  have developed a rigorous risk and testing assessment process. This process
  includes careful annotation guidelines Tseng et al. (2020), pre-launch review
  at multiple levels by the central risk and compliance organizations, and
  by the product leaders (e.g., the newsroom) as applicable, and post-launch
  monitoring. Moreover, we conduct our research, development, and deployment
  of NLP and AI systems in accordance with all applicable regulations.""
- ""Similarly, toxicity and bias are areas where, as a company, we take extraordinary
  care with any content we produce, whether from humans or machines. Since
  the measurement of toxicity and bias in our model depends on its application
  areas, quantifying the potential for the generation of harmful language
  remains an open question. We are particularly interested in studying whether
  FinPile, which is cleaner and contains fewer examples of overtly biased
  or toxic language (e.g., Press Releases), reduces the proclivity of the
  model to generate inappropriate content.""
",closed,unknown,"""This model will assist Bloomberg in improving existing financial NLP tasks, such as sentiment analysis, named entity recognition, news classification, and question answering, among others. Furthermore, BloombergGPT will unlock new opportunities for marshalling the vast quantities of data available on the Bloomberg Terminal to better help the firm's customers, while bringing the full potential of AI to the financial domain.""
",,,,,unknown,53 days,64 Amazon EC2 p4d.24xlarge instances each with 8 NVIDIA 40GB A100 GPUs (i.e. total 512 A100 GPUs),,,,,,,221,text,text,491
277,application,Cformers,Nolano,Cformers is a set of transformers that act as an API for AI inference in code.,2023-03-19,https://www.nolano.org/services/Cformers/,,,,,limited,MIT,,,,,,,,,,,,,,,222,nan,nan,492
278,model,Platypus,Boston University,Platypus is a family of fine-tuned and merged Large Language Models (LLMs).,2023-08-14,https://arxiv.org/pdf/2308.07317.pdf,13B parameters (dense),Platypus achieves the strongest performance and currently stands at first place in HuggingFace’s Open LLM Leaderboard as of its release date.,LLaMA 2,,open,CC by-NC-SA 4.0,,,,https://huggingface.co/garage-bAInd/Platypus2-13B/discussions,https://huggingface.co/garage-bAInd/Platypus2-13B,,5 hours,1 A100 GPU,,,,,,,223,text,text,493
278,model,Platypus,Boston University,Platypus is a family of fine-tuned and merged Large Language Models (LLMs).,2023-08-14,https://arxiv.org/pdf/2308.07317.pdf,13B parameters (dense),Platypus achieves the strongest performance and currently stands at first place in HuggingFace’s Open LLM Leaderboard as of its release date.,Platypus curated dataset,,open,CC by-NC-SA 4.0,,,,https://huggingface.co/garage-bAInd/Platypus2-13B/discussions,https://huggingface.co/garage-bAInd/Platypus2-13B,,5 hours,1 A100 GPU,,,,,,,223,text,text,494
279,model,UFOGen,Boston University,"UFOGen is a novel generative model designed for ultra-fast, one-step text-to-image synthesis.",2023-11-14,https://arxiv.org/pdf/2311.09257.pdf,900M parameters (dense),UFOGen is evaluated on standard image benchmarks against other models fine-tuned with Stable Diffusion.,Stable Diffusion,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,224,text,image,495
280,application,Nextdoor Assistant,Nextdoor,AI chatbot on Nextdoor that helps users write more clear and conscientious posts.,2023-05-02,https://help.nextdoor.com/s/article/Introducing-Assistant,,,ChatGPT,,open,unknown,to be used to help make the Nextdoor experience more positive for users,,,,,,,,,natural language text guidance,,,,,225,nan,nan,496
282,model,You model,You,,,https://you.com/,unknkown,,You dataset,,closed,unknown,,,,,,,,,,,,,,,226,text,text,497
283,application,You Search,You,You.com is a search engine built on artificial intelligence that provides users with a customized search experience while keeping their data 100% private.,,https://you.com/,,,You model,,open,unknown,,,,,,,,,,,,,,,227,nan,nan,498
288,model,AlphaFold2,Google Deepmind,AlphaFold2 is a protein language model trained on protein sequences,2021-07-15,https://www.nature.com/articles/s41586-021-03819-2,93M parameters (dense),,Protein Data Bank,,open,Apache 2.0,,,,,,,11 days,128 TPUv3 cores,,,,,,,228,amino acid sequence,protein structure,499
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",M3W,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,image,text,500
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",ALIGN,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,image,text,501
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",LTIP,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,image,text,502
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",VTP,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,image,text,503
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",Chinchilla,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,image,text,504
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",M3W,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,text,text,505
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",ALIGN,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,text,text,506
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",LTIP,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,text,text,507
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",VTP,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,text,text,508
289,model,Flamingo,Google Deepmind,"Flamingo is a Visual Language Model using the Transformer architecture that is intended for few-shot learning.
",2022-04-29,https://arxiv.org/pdf/2204.14198.pdf,80B parameters (dense),"Model performance was evaluated on image and video datasets primarily, including dialogue.
",Chinchilla,,closed,unknown,"The intended uses are stated in the model card: ""The primary use is research on visual language models (VLM), including: research on VLM applications like classification, captioning or visual question answering, understanding how strong VLMs can contribute to AGI, advancing fairness and safety research in the area of multimodal research, and understanding limitations of current large VLMs."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
","The model card lists the following as out of scope uses of the model: ""Uses of the model for visually conditioned language generation in harmful or deceitful settings. Broadly speaking, the model should not be used for downstream applications without further safety and fairness mitigations specific to each application."" [[Model Card]](https://arxiv.org/pdf/2204.14198.pdf#appendix.E).
",unknown,,https://arxiv.org/pdf/2204.14198.pdf#appendix.E,unknown,15 days on 1536 TPUs,TPU,,,,,,,229,text,text,509
290,model,AlphaCode,Google Deepmind,AlphaCode is an autoregressive language model trained on code,2022-02-02,https://arxiv.org/abs/2203.07814,41B parameters (dense),,,,closed,unknown,,,,,,,,,,,,,,,230,text,code,510
291,model,Gopher,Google Deepmind,"Gopher is an autoregressive language model based on the Transformer architecture with two modifications: using RMSNorm instead of LayerNorm and using relative positional encoding scheme instead of absolute positional encodings [[Section 3]](https://arxiv.org/pdf/2112.11446.pdf#subsection.3.1).
",2021-12-08,https://arxiv.org/pdf/2112.11446.pdf,280B parameters (dense),"Model performance was evaluated and analyzed on 152 NLP tasks including: Language Modelling (20), Reading Comprehension (3), Fact Checking (3), Question Answering (3), Common Sense (4), MMLU (57), BIG-bench (62) [[Section 4]](https://arxiv.org/pdf/2112.11446.pdf#section.4); on toxicity and bias datasets [[Section 5]](https://arxiv.org/pdf/2112.11446.pdf#section.5); and on dialogue tasks [[Section 6]](https://arxiv.org/pdf/2112.11446.pdf#section.6).
",MassiveText,,closed,unknown,"The intended uses are stated in the Gopher model card: ""The primary use is research on language models, including: research on NLP applications like machine translation and question answering, understanding how strong language models can contribute to AGI, advancing fairness and safety research, and understanding limitations of current LLMs"" [[Model Card]](https://arxiv.org/pdf/2112.11446.pdf#appendix.B).
","The model card lists the following as out of scope uses of the model: ""for language generation in harmful or deceitful settings. More generally, the model should not be used for downstream applications without further safety and fairness mitigations"" [[Model Card]](https://arxiv.org/pdf/2112.11446.pdf#appendix.B).
",unknown,"The feedback for the model can be provided at the email linked in the model card, geoffreyi at google.com [[Model Card]](https://arxiv.org/pdf/2112.11446.pdf#appendix.B).
",https://arxiv.org/pdf/2112.11446.pdf#appendix.B,380 tCO2e,7303.24 petaflop/s-day,TPUv3 pods,,,,,,,231,text,code,511
292,model,Chinchilla,Google Deepmind,"Chinchilla is an autoregressive language model based on the Transformer architecture with improved scaling laws.
",2022-03-29,https://arxiv.org/pdf/2203.15556.pdf,70B parameters (dense),"Model performance was evaluated and analyzed on many NLP tasks including language modeling, reading comprehension, question answering, commonsense-intensive tasks, and the BIG-Bench and MMLU meta-benchmarks.
",MassiveText,,closed,unknown,"The intended uses are stated in the Chinchilla model card: ""The primary use is research on language models, including: research on the scaling behaviour of language models along with those listed in Gopher paper"" [[Model Card]](https://arxiv.org/pdf/2203.15556.pdf#appendix.I).
","The model card lists the following as out of scope uses of the model: ""for language generation in harmful or deceitful settings. More generally, the model should not be used for downstream applications without further safety and fairness mitigations"" [[Model Card]](https://arxiv.org/pdf/2203.15556.pdf#appendix.I).
",Unknown,"The feedback for the model can be provided at the email linked in the model card, {jordanhoffmann, sborgeaud, amensch,sifre} at deepmind.com [[Model Card]](https://arxiv.org/pdf/2203.15556.pdf#appendix.I).
",https://arxiv.org/pdf/2203.15556.pdf,Unknown,7303.24 petaflop/s-day,TPUv3/TPUv4 pods,,,,,,,232,text,code,512
293,model,Gato,Google Deepmind,"Gato is a generalist agent based on sequence modeling using the Transformer architecture to implement multi-modal, multi-task, multi-embodiment generalist policy.
",2022-05-12,https://www.deepmind.com/blog/a-generalist-agent,1.2B parameters (dense),"Model performance was evaluated on simulated and robotics task primarily, including out-of-distribution and skill generalization.
",Gato dataset,,closed,unknown,"The intended uses are stated in the Gopher model card: ""Learn to accomplish a wide variety of tasks from expert demonstrations, such as playing video games, controlling simulated embodiments, and real world block stacking."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
","The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",unknown,"The feedback for the model can be provided at the email linked in the model card, reedscot at google.com [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",https://openreview.net/pdf?id=1ikK0kHjvj#appendix.B,unknown,4 days on a 16x16 TPU v3 slice,16x16 TPU v3 slice,,,,,,,233,image,image,513
293,model,Gato,Google Deepmind,"Gato is a generalist agent based on sequence modeling using the Transformer architecture to implement multi-modal, multi-task, multi-embodiment generalist policy.
",2022-05-12,https://www.deepmind.com/blog/a-generalist-agent,1.2B parameters (dense),"Model performance was evaluated on simulated and robotics task primarily, including out-of-distribution and skill generalization.
",Gato dataset,,closed,unknown,"The intended uses are stated in the Gopher model card: ""Learn to accomplish a wide variety of tasks from expert demonstrations, such as playing video games, controlling simulated embodiments, and real world block stacking."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
","The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",unknown,"The feedback for the model can be provided at the email linked in the model card, reedscot at google.com [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",https://openreview.net/pdf?id=1ikK0kHjvj#appendix.B,unknown,4 days on a 16x16 TPU v3 slice,16x16 TPU v3 slice,,,,,,,233,image,text,514
293,model,Gato,Google Deepmind,"Gato is a generalist agent based on sequence modeling using the Transformer architecture to implement multi-modal, multi-task, multi-embodiment generalist policy.
",2022-05-12,https://www.deepmind.com/blog/a-generalist-agent,1.2B parameters (dense),"Model performance was evaluated on simulated and robotics task primarily, including out-of-distribution and skill generalization.
",Gato dataset,,closed,unknown,"The intended uses are stated in the Gopher model card: ""Learn to accomplish a wide variety of tasks from expert demonstrations, such as playing video games, controlling simulated embodiments, and real world block stacking."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
","The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",unknown,"The feedback for the model can be provided at the email linked in the model card, reedscot at google.com [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",https://openreview.net/pdf?id=1ikK0kHjvj#appendix.B,unknown,4 days on a 16x16 TPU v3 slice,16x16 TPU v3 slice,,,,,,,233,image,robotics trajectories,515
293,model,Gato,Google Deepmind,"Gato is a generalist agent based on sequence modeling using the Transformer architecture to implement multi-modal, multi-task, multi-embodiment generalist policy.
",2022-05-12,https://www.deepmind.com/blog/a-generalist-agent,1.2B parameters (dense),"Model performance was evaluated on simulated and robotics task primarily, including out-of-distribution and skill generalization.
",Gato dataset,,closed,unknown,"The intended uses are stated in the Gopher model card: ""Learn to accomplish a wide variety of tasks from expert demonstrations, such as playing video games, controlling simulated embodiments, and real world block stacking."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
","The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",unknown,"The feedback for the model can be provided at the email linked in the model card, reedscot at google.com [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",https://openreview.net/pdf?id=1ikK0kHjvj#appendix.B,unknown,4 days on a 16x16 TPU v3 slice,16x16 TPU v3 slice,,,,,,,233,text,image,516
293,model,Gato,Google Deepmind,"Gato is a generalist agent based on sequence modeling using the Transformer architecture to implement multi-modal, multi-task, multi-embodiment generalist policy.
",2022-05-12,https://www.deepmind.com/blog/a-generalist-agent,1.2B parameters (dense),"Model performance was evaluated on simulated and robotics task primarily, including out-of-distribution and skill generalization.
",Gato dataset,,closed,unknown,"The intended uses are stated in the Gopher model card: ""Learn to accomplish a wide variety of tasks from expert demonstrations, such as playing video games, controlling simulated embodiments, and real world block stacking."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
","The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",unknown,"The feedback for the model can be provided at the email linked in the model card, reedscot at google.com [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",https://openreview.net/pdf?id=1ikK0kHjvj#appendix.B,unknown,4 days on a 16x16 TPU v3 slice,16x16 TPU v3 slice,,,,,,,233,text,text,517
293,model,Gato,Google Deepmind,"Gato is a generalist agent based on sequence modeling using the Transformer architecture to implement multi-modal, multi-task, multi-embodiment generalist policy.
",2022-05-12,https://www.deepmind.com/blog/a-generalist-agent,1.2B parameters (dense),"Model performance was evaluated on simulated and robotics task primarily, including out-of-distribution and skill generalization.
",Gato dataset,,closed,unknown,"The intended uses are stated in the Gopher model card: ""Learn to accomplish a wide variety of tasks from expert demonstrations, such as playing video games, controlling simulated embodiments, and real world block stacking."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
","The model card lists the following as out of scope uses of the model: ""Not intended for commercial or production use. Military uses are strictly prohibited."" [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",unknown,"The feedback for the model can be provided at the email linked in the model card, reedscot at google.com [[Model Card]](https://openreview.net/pdf?id=1ikK0kHjvj#appendix.A).
",https://openreview.net/pdf?id=1ikK0kHjvj#appendix.B,unknown,4 days on a 16x16 TPU v3 slice,16x16 TPU v3 slice,,,,,,,233,text,robotics trajectories,518
294,model,Sparrow,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Chinchilla,,closed,unknown,,,,,,,,,,,,,,,234,text,text,519
294,model,Sparrow,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Google Search,,closed,unknown,,,,,,,,,,,,,,,234,text,text,520
294,model,Sparrow,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Sparrow Rule reward model,,closed,unknown,,,,,,,,,,,,,,,234,text,text,521
294,model,Sparrow,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Sparrow Preference reward model,,closed,unknown,,,,,,,,,,,,,,,234,text,text,522
295,model,RETRO,Google Deepmind,,2021-12-08,https://arxiv.org/abs/2112.04426,7.5B parameters (dense),,MassiveText,,closed,unknown,,,,,,,,,,,,,,,235,text,text,523
296,model,Sparrow Rule reward model,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Chinchilla,,closed,unknown,,,,,,,,,,,,,,,236,text,text,524
296,model,Sparrow Rule reward model,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Sparrow adversarial probing dataset,,closed,unknown,,,,,,,,,,,,,,,236,text,text,525
297,model,Sparrow Preference reward model,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Chinchilla,,closed,unknown,,,,,,,,,,,,,,,237,text,text,526
297,model,Sparrow Preference reward model,Google Deepmind,,2022-09-28,https://arxiv.org/abs/2209.14375,70B parameters (dense),,Sparrow response preference dataset,,closed,unknown,,,,,,,,,,,,,,,237,text,text,527
300,model,GopherCite,Google Deepmind,,2022-03-16,https://storage.googleapis.com/deepmind-media/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf,280B parameters (dense),,Gopher,,closed,unknown,,,,,,,,,,,,,,,238,text,text,528
300,model,GopherCite,Google Deepmind,,2022-03-16,https://storage.googleapis.com/deepmind-media/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf,280B parameters (dense),,Google Search,,closed,unknown,,,,,,,,,,,,,,,238,text,text,529
300,model,GopherCite,Google Deepmind,,2022-03-16,https://storage.googleapis.com/deepmind-media/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf,280B parameters (dense),,GopherCite reward model,,closed,unknown,,,,,,,,,,,,,,,238,text,text,530
301,model,GopherCite reward model,Google Deepmind,,2022-03-16,https://storage.googleapis.com/deepmind-media/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf,7B parameters (dense),,Gopher,,closed,unknown,,,,,,,,,,,,,,,239,text,text,531
301,model,GopherCite reward model,Google Deepmind,,2022-03-16,https://storage.googleapis.com/deepmind-media/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes/Teaching%20language%20models%20to%20support%20answers%20with%20verified%20quotes.pdf,7B parameters (dense),,GopherCite Preference dataset,,closed,unknown,,,,,,,,,,,,,,,239,text,text,532
303,model,Dramatron,Google Deepmind,,2022-09-29,https://arxiv.org/abs/2209.14958,70B parameters (dense),,Chinchilla,,closed,unknown,,,,,,,,,,,,,,,240,text,text,533
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLI-X,,open,unknown,,,,,,,,,,,,,,,241,text,text,534
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLM-E,,open,unknown,,,,,,,,,,,,,,,241,text,text,535
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,RT-2 action tokens,,open,unknown,,,,,,,,,,,,,,,241,text,text,536
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLI-X,,open,unknown,,,,,,,,,,,,,,,241,text,robotics trajectories,537
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLM-E,,open,unknown,,,,,,,,,,,,,,,241,text,robotics trajectories,538
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,RT-2 action tokens,,open,unknown,,,,,,,,,,,,,,,241,text,robotics trajectories,539
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLI-X,,open,unknown,,,,,,,,,,,,,,,241,video,text,540
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLM-E,,open,unknown,,,,,,,,,,,,,,,241,video,text,541
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,RT-2 action tokens,,open,unknown,,,,,,,,,,,,,,,241,video,text,542
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLI-X,,open,unknown,,,,,,,,,,,,,,,241,video,robotics trajectories,543
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,PaLM-E,,open,unknown,,,,,,,,,,,,,,,241,video,robotics trajectories,544
304,model,RT-2,Google Deepmind,RT-2 is a vision-language-action model for robotic actions that incorporates chain of thought reasoning.,2023-07-28,https://arxiv.org/pdf/2307.15818.pdf,55B parameters (dense),Evaluated on evaluation trajectories and SoTA baselines using robotic data.,RT-2 action tokens,,open,unknown,,,,,,,,,,,,,,,241,video,robotics trajectories,545
305,model,Lyria,Google Deepmind,Lyria is DeepMind's most advanced AI music generation model to date.,2023-11-16,https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/,unknown,unknown,,worked with artists and music industry to ensure utility,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,242,text,music,546
306,model,Genie,Google DeepMind,"Gene is a foundation world model trained from Internet videos that can generate an endless variety of playable (action-controllable) worlds from synthetic images, photographs, and even sketches.",2024-02-23,https://sites.google.com/view/genie-2024,11B parameters (dense),Evaluated using only out-of-distribution image prompts for qualitative results.,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,243,image,video,547
310,application,Sana,Sana,"""Sana is your all-in-one, AI-assisted, online learning platform (LMS). Author employee training courses and measure team development with Sana's powerful analytics. Sana partners with the world's most important organizations and fastest-growing startups to make personalized, adaptive learning available for everyone, everywhere"" [[Sana GPT-3 Demo]](https://gpt3demo.com/apps/sanalabs).
",,https://www.sanalabs.com/,,,OpenAI API,unknown,limited,custom,"Sana is intended to be used by employers to provide a learning service for their employees.
",,unknown,unknown,,,,,"Customized GPT-3, fine-tuned on private data [[Sana GPT-3 Demo]](https://gpt3demo.com/apps/sanalabs).
","question and answer, summarization, sentiment analysis,topic identification",https://www.sanalabs.com/legal/,unknown,unknown,unknown,244,nan,nan,548
314,model,COSMO,AI2,COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets,2023-05-24,https://arxiv.org/pdf/2212.10465.pdf,11B parameters (dense),Evaluated by human testers on generalization capabilities and responses compared to other chatbots.,SODA,,open,,,,,https://huggingface.co/allenai/cosmo-xl/discussions,https://huggingface.co/allenai/cosmo-xl,unknown,unknown,v3-128 TPU accelerators with batch size 256,,,,,,,245,text,text,549
314,model,COSMO,AI2,COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets,2023-05-24,https://arxiv.org/pdf/2212.10465.pdf,11B parameters (dense),Evaluated by human testers on generalization capabilities and responses compared to other chatbots.,ProsocialDialog,,open,,,,,https://huggingface.co/allenai/cosmo-xl/discussions,https://huggingface.co/allenai/cosmo-xl,unknown,unknown,v3-128 TPU accelerators with batch size 256,,,,,,,245,text,text,550
314,model,COSMO,AI2,COSMO is a conversation agent with greater generalizability on both in- and out-of-domain chitchat datasets,2023-05-24,https://arxiv.org/pdf/2212.10465.pdf,11B parameters (dense),Evaluated by human testers on generalization capabilities and responses compared to other chatbots.,T5,,open,,,,,https://huggingface.co/allenai/cosmo-xl/discussions,https://huggingface.co/allenai/cosmo-xl,unknown,unknown,v3-128 TPU accelerators with batch size 256,,,,,,,245,text,text,551
317,model,Tulu 2,AI2,Tulu 2 is a language model trained on the new Tulu-v2-mix dataset and fine-tuned on more state of the art language models.,2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,70B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,LLaMA 2,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/tulu-2-70b/discussions,https://huggingface.co/allenai/tulu-2-70b,unknown,unknown,unknown,,,,,,,246,text,text,552
317,model,Tulu 2,AI2,Tulu 2 is a language model trained on the new Tulu-v2-mix dataset and fine-tuned on more state of the art language models.,2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,70B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,Tulu-V2-mix,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/tulu-2-70b/discussions,https://huggingface.co/allenai/tulu-2-70b,unknown,unknown,unknown,,,,,,,246,text,text,553
318,model,Tulu 2 DPO,AI2,"Tulu 2 DPO is created in a similar manner to Tulu 2, but with Direct Preference Optimization (DPO).",2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,70B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,LLaMA 2,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/tulu-2-dpo-70b/discussions,https://huggingface.co/allenai/tulu-2-dpo-70b,unknown,unknown,unknown,,,,,,,247,text,text,554
318,model,Tulu 2 DPO,AI2,"Tulu 2 DPO is created in a similar manner to Tulu 2, but with Direct Preference Optimization (DPO).",2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,70B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,Tulu-V2-mix,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/tulu-2-dpo-70b/discussions,https://huggingface.co/allenai/tulu-2-dpo-70b,unknown,unknown,unknown,,,,,,,247,text,text,555
319,model,Code Tulu 2,AI2,"Code Tulu 2 is a fine-tuned version of Code LLaMA that was trained on a mix of publicly available, synthetic and human datasets.",2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,13B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,Code LLaMA,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/codetulu-2-13b/discussions,https://huggingface.co/allenai/codetulu-2-13b,unknown,unknown,unknown,,,,,,,248,text,code,556
319,model,Code Tulu 2,AI2,"Code Tulu 2 is a fine-tuned version of Code LLaMA that was trained on a mix of publicly available, synthetic and human datasets.",2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,13B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,Tulu-V2-mix,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/codetulu-2-13b/discussions,https://huggingface.co/allenai/codetulu-2-13b,unknown,unknown,unknown,,,,,,,248,text,code,557
319,model,Code Tulu 2,AI2,"Code Tulu 2 is a fine-tuned version of Code LLaMA that was trained on a mix of publicly available, synthetic and human datasets.",2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,13B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,Code LLaMA,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/codetulu-2-13b/discussions,https://huggingface.co/allenai/codetulu-2-13b,unknown,unknown,unknown,,,,,,,248,text,text,558
319,model,Code Tulu 2,AI2,"Code Tulu 2 is a fine-tuned version of Code LLaMA that was trained on a mix of publicly available, synthetic and human datasets.",2023-11-20,https://arxiv.org/pdf/2311.10702.pdf,13B parameters (dense),Evaluated on MT-Bench and AlpacaEval. compared to other chatbots.,Tulu-V2-mix,,open,AI2 ImpACT,,,,https://huggingface.co/allenai/codetulu-2-13b/discussions,https://huggingface.co/allenai/codetulu-2-13b,unknown,unknown,unknown,,,,,,,248,text,text,559
320,model,OLMo,AI2,"Open Language Model (OLMo) is designed to provide access to data, training code, models, and evaluation code necessary to advance AI through open research to empower academics and researchers to study the science of language models collectively.",2024-02-01,https://allenai.org/olmo/olmo-paper.pdf,7B parameters (dense),"Evaluated on standard LLM tasks and benchmarks in comparison to LLaMA, Falcon, and MPT, in addition to other same-sized models.",Dolma,training data from Dolma filtered and deduplicated before being trained on.,open,Apache 2.0,,,unknown,https://huggingface.co/allenai/OLMo-7B/discussions,https://huggingface.co/allenai/OLMo-7B,75.05 tCo2eq,unknown,"27 nodes, with each node containing 8x NVIDIA A100-40GB GPUs provided by MosaicML",,,,,,,249,text,text,560
322,model,VARCO-LLM,NCSOFT,VARCO-LLM is NCSOFT’s large language model and is trained on English and Korean.,2023-08-16,https://github.com/ncsoft/ncresearch,13B parameters,"Boasts the highest performance among the Korean LLMs of similar sizes that have been released to date, according to internal evaluations.",,,closed,custom,"Developing various NLP-based AI services such as Q&A, chatbot, summarization, information extraction",,,,,unknown,unknown,unknown,,,,,,,250,text,text,561
323,application,UnderwriteGPT,Paladin Group and Dais Technology,UnderwriteGPT is the world's first generative AI underwriting tool.,2023-02-01,https://dais.com/underwritegpt/,,,,,limited,,,,,,,,,,,,,,,,251,nan,nan,562
324,model,Cerebras-GPT,Cerebras,"A Family of Open, Compute-efficient, Large Language Models. The family includes 111M, 256M, 590M, 1.3B, 2.7B, 6.7B, and 13B models. All models in the Cerebras-GPT family have been trained in accordance with Chinchilla scaling laws (20 tokens per model parameter). [[Cerebras Blog Post]](https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models)
",2023-03-28,https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/,13B parameters (dense),"""We evaluate our models on the PILE validation set comprising 380M tokens. We also evaluate the public checkpoints of Pythia, Eleuther (2022); OPT, Zhang et al. (2022); GPT-NeoX 20B, Black et al. (2022); and GPT-J 6B, Wang & Komatsuzaki (2021). We performed upstream (pre-training) evaluations of text prediction cross-entropy using the Pile validation and test splits. We performed downstream evaluations of text generation accuracy on standardized tasks using the Eleuther lm-evaluation-harness."" [[Evaluations]] (https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/pytorch/gpt3/configs/Cerebras_GPT#evaluations).
",The Pile,"The Pile dataset has been thoroughly analyzed from various ethical standpoints such as toxicity analysis, gender bias, pejorative content, racially sensitive content etc. Only mitigations in standard Pile dataset pre-processing were employed when pre-training Cerebras-GPT. [[Risk, Bias, Ethical Considerations]](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/pytorch/gpt3/configs/Cerebras_GPT#risk-bias-ethical-considerations)
",open,Apache 2.0,"""The primary intended use is to further research into large language models. These models can be used as a foundation model for NLP, applications, ethics, and alignment research. Our primary intended users are researchers who are working to improve LLMs and practitioners seeking reference implementations, training setups, hyperparameters, or pre-trained models. We release these models with a fully permissive Apache license for the community to use freely."" [[Uses and Limitations]](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/pytorch/gpt3/configs/Cerebras_GPT#uses-and-limitations).
","Authors note the following limitations of the model: ""Cerebras-GPT models are trained on the Pile, with English language only, and are not suitable for machine translation tasks. Cerebras-GPT models have not been tuned for human-facing dialog applications like chatbots and will not respond to prompts in a similar way to models that have received instruction tuning or reinforcement learning from human feedback (RLHF) like Flan-T5 or ChatGPT."" [[Uses and Limitations]](https://github.com/Cerebras/modelzoo/tree/main/modelzoo/transformers/pytorch/gpt3/configs/Cerebras_GPT#out-of-scope-use).
",,,https://huggingface.co/cerebras/Cerebras-GPT-13B,,,16x Cerebras CS-2 wafer scale systems,,,,,,,252,text,text,563
325,model,Jais,"Inception Institute of Artificial Intelligence, Cerebras, Mohamed bin Zayed University of Artificial Intelligence",Jais is the world’s most advanced Arabic LLM as of its release.,2023-08-30,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,13B parameters (dense),Evaluated on standard English LLM benchmarks and adapted Arabic LLM benchmarks.,GPT-3,,open,Apache 2.0,Jais is released with the aim to stimulate research and development in the Arabic NLP community.,"Generating or endorsing hate speech, disseminating false information, engaging in illegal activities, managing sensitive data, attempting language generalization beyond Arabic and English, and making critical decisions with high stakes.",unknown,,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,unknown,unknown,Condor Galaxy Supercomputer,,,,,,,253,text,text,564
325,model,Jais,"Inception Institute of Artificial Intelligence, Cerebras, Mohamed bin Zayed University of Artificial Intelligence",Jais is the world’s most advanced Arabic LLM as of its release.,2023-08-30,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,13B parameters (dense),Evaluated on standard English LLM benchmarks and adapted Arabic LLM benchmarks.,The Pile,,open,Apache 2.0,Jais is released with the aim to stimulate research and development in the Arabic NLP community.,"Generating or endorsing hate speech, disseminating false information, engaging in illegal activities, managing sensitive data, attempting language generalization beyond Arabic and English, and making critical decisions with high stakes.",unknown,,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,unknown,unknown,Condor Galaxy Supercomputer,,,,,,,253,text,text,565
326,model,Jais Chat,"Inception Institute of Artificial Intelligence, Cerebras, Mohamed bin Zayed University of Artificial Intelligence","Jais Chat is an instruction-tuned version of Jais, optimized for dialog interaction.",2023-08-30,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,13B parameters (dense),Evaluated on standard English LLM benchmarks and adapted Arabic LLM benchmarks.,GPT-3,,open,Apache 2.0,Jais Chat is released with the aim to stimulate research and development in the Arabic NLP community.,"Generating or endorsing hate speech, disseminating false information, engaging in illegal activities, managing sensitive data, attempting language generalization beyond Arabic and English, and making critical decisions with high stakes.",unknown,,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,unknown,unknown,Condor Galaxy Supercomputer from Cerebras,,,,,,,254,text,text,566
326,model,Jais Chat,"Inception Institute of Artificial Intelligence, Cerebras, Mohamed bin Zayed University of Artificial Intelligence","Jais Chat is an instruction-tuned version of Jais, optimized for dialog interaction.",2023-08-30,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,13B parameters (dense),Evaluated on standard English LLM benchmarks and adapted Arabic LLM benchmarks.,The Pile,,open,Apache 2.0,Jais Chat is released with the aim to stimulate research and development in the Arabic NLP community.,"Generating or endorsing hate speech, disseminating false information, engaging in illegal activities, managing sensitive data, attempting language generalization beyond Arabic and English, and making critical decisions with high stakes.",unknown,,https://inceptioniai.org/jais/docs/Technicalpaper.pdf,unknown,unknown,Condor Galaxy Supercomputer from Cerebras,,,,,,,254,text,text,567
327,model,Bittensor Language Model,Cerebras,Bittensor Language Model is a 3 billion parameter language model with an 8k context length trained on 627B tokens of SlimPajama.,2023-07-24,https://www.cerebras.net/blog/btlm-3b-8k-7b-performance-in-a-3-billion-parameter-model/,3B parameters (dense),Evaluated on standard LLM benchmarks in comparison to similar-sized models.,SlimPajama,,open,Apache 2.0,,,unknown,https://huggingface.co/cerebras/btlm-3b-8k-base/discussions,https://huggingface.co/cerebras/btlm-3b-8k-base,unknown,unknown,unknown,,,,,,,255,text,text,568
329,model,CodeGen,Salesforce,CodeGen is a language model for code,2022-03-25,https://arxiv.org/abs/2203.13474,16B parameters (dense),,,,open,"none (model weights), BSD-3-Clause (code)",,,,,,,,Unspecified Salesforce Compute (TPU-V4s),,,,,,,256,code,code,569
329,model,CodeGen,Salesforce,CodeGen is a language model for code,2022-03-25,https://arxiv.org/abs/2203.13474,16B parameters (dense),,,,open,"none (model weights), BSD-3-Clause (code)",,,,,,,,Unspecified Salesforce Compute (TPU-V4s),,,,,,,256,code,text,570
329,model,CodeGen,Salesforce,CodeGen is a language model for code,2022-03-25,https://arxiv.org/abs/2203.13474,16B parameters (dense),,,,open,"none (model weights), BSD-3-Clause (code)",,,,,,,,Unspecified Salesforce Compute (TPU-V4s),,,,,,,256,text,code,571
329,model,CodeGen,Salesforce,CodeGen is a language model for code,2022-03-25,https://arxiv.org/abs/2203.13474,16B parameters (dense),,,,open,"none (model weights), BSD-3-Clause (code)",,,,,,,,Unspecified Salesforce Compute (TPU-V4s),,,,,,,256,text,text,572
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,ViT-B,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,573
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,BERT,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,574
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,COCO,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,575
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,Visual Genome,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,576
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,Conceptual Captions,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,577
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,Conceptual 12M,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,578
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,SBU Captions,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,579
330,model,BLIP,Salesforce,,2022-01-28,https://arxiv.org/abs/2201.12086,unknown,,LAION-115M,,open,BSD-3-Clause,,,,,,,,,,,,,,,257,text,image,580
332,application,EinsteinGPT,Salesforce,EinsteinGPT is generative AI for customer relationship management (CRFM).,2023-03-07,https://www.salesforce.com/products/einstein/overview/?d=cta-body-promo-8,,,ChatGPT API,,limited,unknown,,,,,,,,,,,,,,,258,nan,nan,581
333,model,BLIP-2,Salesforce,BLIP-2 is a model that employs a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models.,2023-01-30,https://arxiv.org/pdf/2301.12597.pdf,2.7B parameters (dense),"BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods",OPT,,open,MIT,,,,https://huggingface.co/Salesforce/blip2-opt-2.7b/discussions,https://huggingface.co/Salesforce/blip2-opt-2.7b,unknown,less than 9 days,unknown,,,,,,,259,text,image,582
334,model,Moirai,Salesforce,"Moirai is a cutting-edge time series foundation model, offering universal forecasting capabilities. It stands out as a versatile time series forecasting model capable of addressing diverse forecasting tasks across multiple domains, frequencies, and variables in a zero-shot manner.",2024-03-19,https://blog.salesforceairesearch.com/moirai/,311M parameters,Moirai has undergone a comprehensive evaluation in both in-distribution and out-of-distribution settings. It demonstrated its capabilities as a zero-shot forecaster and delivered competitive or superior performance compared to full-shot models.,LOTSA,The performance of Moirai was evaluated through in-distribution and out-of-distribution settings.,open,Apache 2.0,"Moirai can be used for time series forecasting in multiple domains. It offers robust zero-shot forecasting capabilities and eliminates the need for additional data, extensive computational resources, and expert input for achieving accurate forecasts.",unknown,unknown,https://huggingface.co/Salesforce/moirai-1.0-R-large/discussions,https://huggingface.co/Salesforce/moirai-1.0-R-large,unknown,unknown,NVIDIA A100 40G GPUs,,,,,,,260,time-series,time-series,583
337,model,Neeva model,Neeva,,,https://neeva.com/index,unknown,,Neeva dataset,,closed,unknown,,,,,,,,,,,,,,,261,text,text,584
338,application,NeevaAI,Neeva,NeevaAI is an AI-powered search tool that combines the capabilities of LLMs with Neeva's independent in-house search stack to create a unique and transformative search experience.,2023-01-06,https://neeva.com/blog/introducing-neevaai,,,Neeva model,,open,Custom,,,,,,,,,,,https://neeva.com/terms,,,,262,nan,nan,585
341,model,Jurassic-1,AI21 Labs,"Jurassic-1 is a family of autoregressive language models (Large, Grande, Jumbo).",2021-08-11,https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf,178B parameters (dense),"Evaluated on several standard benchmarks (e.g. ARC, BoolQ, HellaSwag, RTE, Winogrande)",Jurassic-1 dataset,,limited,unknown,unknown,"Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",,,,unknown,Several months,Over 800 A100 GPUs,,,,,,,263,text,text,586
342,model,Jurassic-1 Instruct,AI21 Labs,Jurassic-1 Instruct is an instruction-tuned autoregressive language model.,2022-12-01,https://docs.ai21.com/docs/jurassic-1-instruct-beta,17B parameters (dense),,Jurassic-1,unknown,limited,unknown,"Jurassic-1 Instruct was trained specifically to handle instructions-only prompts (""zero-shot"") without examples (""few-shot""). It is the most natural way to interact with language models, and it is the best way to get a sense of the optimal output for your task without any examples.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",,,,unknown,unknown,unknown,,,,,,,264,text,text,587
342,model,Jurassic-1 Instruct,AI21 Labs,Jurassic-1 Instruct is an instruction-tuned autoregressive language model.,2022-12-01,https://docs.ai21.com/docs/jurassic-1-instruct-beta,17B parameters (dense),,Jurassic-1 Instruct dataset,unknown,limited,unknown,"Jurassic-1 Instruct was trained specifically to handle instructions-only prompts (""zero-shot"") without examples (""few-shot""). It is the most natural way to interact with language models, and it is the best way to get a sense of the optimal output for your task without any examples.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",,,,unknown,unknown,unknown,,,,,,,264,text,text,588
343,model,Jurassic-2,AI21 Labs,Jurassic-2 is a family of language models designed to replace Jurassic-1.,2023-03-09,https://docs.ai21.com/docs/jurassic-2-models,unknown,The model was evaluated on the HELM benchmark as discussed in https://www.ai21.com/blog/introducing-j2.,,unknown,limited,unknown,,"Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,,,unknown,unknown,unknown,,,,,,,265,text,text,589
344,application,AI21 Playground,AI21 Labs,The AI21 Labs Playground supports several task-specific APIs in addition to a variety of models.,2021-08-11,https://studio.ai21.com/playground/,,,Jurassic-1,unknown,limited,,"The intended uses are text completion, rewriting, and summarization.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The Playground provides direct access to the language models (Complete API) as well as wrapped for Rewrite and Summarize.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,266,nan,nan,590
344,application,AI21 Playground,AI21 Labs,The AI21 Labs Playground supports several task-specific APIs in addition to a variety of models.,2021-08-11,https://studio.ai21.com/playground/,,,Jurassic-1 Instruct,unknown,limited,,"The intended uses are text completion, rewriting, and summarization.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The Playground provides direct access to the language models (Complete API) as well as wrapped for Rewrite and Summarize.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,266,nan,nan,591
344,application,AI21 Playground,AI21 Labs,The AI21 Labs Playground supports several task-specific APIs in addition to a variety of models.,2021-08-11,https://studio.ai21.com/playground/,,,Jurassic-2,unknown,limited,,"The intended uses are text completion, rewriting, and summarization.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The Playground provides direct access to the language models (Complete API) as well as wrapped for Rewrite and Summarize.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,266,nan,nan,592
344,application,AI21 Playground,AI21 Labs,The AI21 Labs Playground supports several task-specific APIs in addition to a variety of models.,2021-08-11,https://studio.ai21.com/playground/,,,AI21 Summarization API,unknown,limited,,"The intended uses are text completion, rewriting, and summarization.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The Playground provides direct access to the language models (Complete API) as well as wrapped for Rewrite and Summarize.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,266,nan,nan,593
344,application,AI21 Playground,AI21 Labs,The AI21 Labs Playground supports several task-specific APIs in addition to a variety of models.,2021-08-11,https://studio.ai21.com/playground/,,,AI21 Paraphrase API,unknown,limited,,"The intended uses are text completion, rewriting, and summarization.","Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The Playground provides direct access to the language models (Complete API) as well as wrapped for Rewrite and Summarize.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,266,nan,nan,594
345,application,AI21 Paraphrase API,AI21 Labs,AI21 Studio's Paraphrase API offers access to our world-class paraphrasing engine. It has been specifically developed for suggesting alternative ways to convey the same message using different words.,2023-03-09,https://docs.ai21.com/docs/paraphrase-api,,,Jurassic-2,unknown,limited,,The intended uses are text paraphrasing.,"Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The AI21 language models are further specialized to the task of paraphrasing.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,267,nan,nan,595
346,application,AI21 Summarization API,AI21 Labs,AI21 Studio's Summarize API offers access to our world-class summarization engine. It has been specifically developed for reading long texts and providing a faithful summary of the original document.,2023-03-09,https://docs.ai21.com/docs/summarize-api,,,Jurassic-2,unknown,limited,,The intended uses are text paraphrasing.,"Illegal activities, such as hate speech, gambling, child pornography or violating intellectual property rights; Harassment, victimization, intimidation, fraud or spam; Creation or dissemination of misinformation, promotion of self-harm, glorification of violent events or incitement of violence.",unknown,Feedback can be given by emailing at info at ai21.com,,,,,The AI21 language models are further specialized to the task of summarization.,text,https://www.ai21.com/terms-of-use,unknown,unknown,unknown,268,nan,nan,596
347,application,Wordtune,AI21 Labs,"Wordtune, the first AI-based writing companion that understands context and meaning.",2020-10-27,https://www.wordtune.com/,,,AI21 Paraphrase API,unknown,limited,Wordtune License,The Wordtune assistant is a writing assistant,,unknown,,,,,,unknown,text,https://www.wordtune.com/terms-of-use,unknown,unknown,unknown,269,nan,nan,597
348,application,Wordtune Read,AI21 Labs,"Wordtune Read is an AI reader that summarizes long documents so you can understand more, faster.",2021-11-16,https://www.wordtune.com/read,,,AI21 Summarize API,unknown,limited,Wordtune License,,,unknown,,,,,,unknown,text,https://www.wordtune.com/terms-of-use,unknown,unknown,unknown,270,nan,nan,598
349,model,Jamba,AI21 Labs,"Jamba is a state-of-the-art, hybrid SSM-Transformer LLM. Jamba is the world’s first production-grade Mamba based model.",2024-03-28,https://www.ai21.com/blog/announcing-jamba,52B parameters (sparse),Jamba outperforms or matches other state-of-the-art models in its size class on a wide range of benchmarks.,,,open,Apache 2.0,"intended for use as a foundation layer for fine tuning, training",,,https://huggingface.co/ai21labs/Jamba-v0.1/discussions,https://huggingface.co/ai21labs/Jamba-v0.1,unknown,unknown,unknown,,,,,,,271,text,text,599
350,model,MPT,Mosaic,MPT is a series of large language models seeking to address the limitations of other open source models like LLaMA and Pythia.,2023-05-05,https://www.mosaicml.com/blog/mpt-7b,7B parameters (dense),Evaluated on a range of benchmarks and performed on par with LLaMA-7B.,RedPajama-Data,,open,Apache 2.0,,,,,,unknown,9.5 days,440 A100 40GB GPUs,,,,,,,272,text,text,600
350,model,MPT,Mosaic,MPT is a series of large language models seeking to address the limitations of other open source models like LLaMA and Pythia.,2023-05-05,https://www.mosaicml.com/blog/mpt-7b,7B parameters (dense),Evaluated on a range of benchmarks and performed on par with LLaMA-7B.,C4,,open,Apache 2.0,,,,,,unknown,9.5 days,440 A100 40GB GPUs,,,,,,,272,text,text,601
350,model,MPT,Mosaic,MPT is a series of large language models seeking to address the limitations of other open source models like LLaMA and Pythia.,2023-05-05,https://www.mosaicml.com/blog/mpt-7b,7B parameters (dense),Evaluated on a range of benchmarks and performed on par with LLaMA-7B.,The Stack,,open,Apache 2.0,,,,,,unknown,9.5 days,440 A100 40GB GPUs,,,,,,,272,text,text,602
350,model,MPT,Mosaic,MPT is a series of large language models seeking to address the limitations of other open source models like LLaMA and Pythia.,2023-05-05,https://www.mosaicml.com/blog/mpt-7b,7B parameters (dense),Evaluated on a range of benchmarks and performed on par with LLaMA-7B.,Multimodal C4,,open,Apache 2.0,,,,,,unknown,9.5 days,440 A100 40GB GPUs,,,,,,,272,text,text,603
351,model,CommonCanvas,"Cornell University, Mosaic",CommonCanvas is a text-to-image model trained solely on Creative Commons licensed images.,2023-10-25,https://arxiv.org/pdf/2310.16825.pdf,unknown,"Compared to Stable Diffusion 2, a SOTA text-to-image model.",CommonCatalog,,open,Apache 2.0,,,,,,unknown,6.79 days,128 A100 NVIDIA GPUs,,,,,,,273,text,image,604
353,application,AI Dungeon,Latitude,"AI Dungeon is a single-player text adventure game that uses AI to generate content.
",2019-12-17,https://play.aidungeon.io,,,OpenAI API,,limited,custom,,,,,,,,,,,https://play.aidungeon.io/main/termsOfService,,,,274,nan,nan,605
355,model,Conformer-1,AssemblyAI,"Conformer-1 is a state-of-the-art speech recognition model trained on 650K hours of audio data that achieves near human-level performance and robustness across a variety of data, making up to 43% fewer errors on noisy data than other ASR models.",2023-03-15,https://www.assemblyai.com/blog/conformer-1/,300M parameters (dense),"In order to evaluate the accuracy and robustness of Conformer-1, we sourced 60+ hours of human labeled audio data covering popular speech domains such as call centers, podcasts, broadcasts, and webinars. We then calculated the Word Error Rate (WER) of Conformer-1 against these datasets, and compared the results against Whisper and a number of other ASR models. To ground our results against popular open source speech recognition benchmarks, we also performed the same WER analysis against a number of academic datasets.",Conformer-1 dataset,,limited,unknown,,,,,,,,,,,,,,,275,audio,audio,606
355,model,Conformer-1,AssemblyAI,"Conformer-1 is a state-of-the-art speech recognition model trained on 650K hours of audio data that achieves near human-level performance and robustness across a variety of data, making up to 43% fewer errors on noisy data than other ASR models.",2023-03-15,https://www.assemblyai.com/blog/conformer-1/,300M parameters (dense),"In order to evaluate the accuracy and robustness of Conformer-1, we sourced 60+ hours of human labeled audio data covering popular speech domains such as call centers, podcasts, broadcasts, and webinars. We then calculated the Word Error Rate (WER) of Conformer-1 against these datasets, and compared the results against Whisper and a number of other ASR models. To ground our results against popular open source speech recognition benchmarks, we also performed the same WER analysis against a number of academic datasets.",Conformer-1 dataset,,limited,unknown,,,,,,,,,,,,,,,275,audio,text,607
355,model,Conformer-1,AssemblyAI,"Conformer-1 is a state-of-the-art speech recognition model trained on 650K hours of audio data that achieves near human-level performance and robustness across a variety of data, making up to 43% fewer errors on noisy data than other ASR models.",2023-03-15,https://www.assemblyai.com/blog/conformer-1/,300M parameters (dense),"In order to evaluate the accuracy and robustness of Conformer-1, we sourced 60+ hours of human labeled audio data covering popular speech domains such as call centers, podcasts, broadcasts, and webinars. We then calculated the Word Error Rate (WER) of Conformer-1 against these datasets, and compared the results against Whisper and a number of other ASR models. To ground our results against popular open source speech recognition benchmarks, we also performed the same WER analysis against a number of academic datasets.",Conformer-1 dataset,,limited,unknown,,,,,,,,,,,,,,,275,text,audio,608
355,model,Conformer-1,AssemblyAI,"Conformer-1 is a state-of-the-art speech recognition model trained on 650K hours of audio data that achieves near human-level performance and robustness across a variety of data, making up to 43% fewer errors on noisy data than other ASR models.",2023-03-15,https://www.assemblyai.com/blog/conformer-1/,300M parameters (dense),"In order to evaluate the accuracy and robustness of Conformer-1, we sourced 60+ hours of human labeled audio data covering popular speech domains such as call centers, podcasts, broadcasts, and webinars. We then calculated the Word Error Rate (WER) of Conformer-1 against these datasets, and compared the results against Whisper and a number of other ASR models. To ground our results against popular open source speech recognition benchmarks, we also performed the same WER analysis against a number of academic datasets.",Conformer-1 dataset,,limited,unknown,,,,,,,,,,,,,,,275,text,text,609
356,application,AssemblyAI,AssemblyAI,AssemblyAI uses Claude and Anthropic's model to transcribe and understand audio data at scale.,,https://www.assemblyai.com/,,,Anthropic API,,limited,custom,,,,,,,,,,,https://www.assemblyai.com/legal/terms-of-service,,,,276,nan,nan,610
357,application,Conformer-1 API,AssemblyAI,API to access the AssemblyAI's Conformer-1 model.,2023-03-15,https://www.assemblyai.com/blog/conformer-1/,,,Conformer-1,,open,custom,Speech recognition,,,,,,,,,,https://www.assemblyai.com/legal/terms-of-service,,,,277,nan,nan,611
358,model,Xwin-LM,Xwin,"Xwin-LM is a LLM, which on release, ranked top 1 on AlpacaEval, becoming the first to surpass GPT-4 on this benchmark.",2023-09-20,https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1,70B parameters (dense),Evaluated on AlpacaEval benchmark against SOTA LLMs.,,,open,LLaMA2,,,,https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1/discussions,https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1,unknown,unknown,unknown,,,,,,,278,text,text,612
359,model,JARVIS-1,Peking University Institute for Artificial Intelligence,"JARVIS-1 is an open-world agent that can perceive multimodal input (visual observations and human instructions), generate sophisticated plans, and perform embodied control, all within the popular yet challenging open-world Minecraft universe.",2023-11-10,https://arxiv.org/pdf/2311.05997.pdf,unknown,"Compared with other multi-task, instruction-following agents.",,,open,unknown,,,,,,unknown,unknown,unknown,,,,,,,279,text,in-game actions,613
360,model,MAmmoTH,Ohio State University,MAmmoTH is a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.,2023-09-11,https://arxiv.org/pdf/2309.05653.pdf,34B parameters (dense),"Evaluated on MATH, a competition-level dataset, and achieves a 46% accuracy, higher than accuracy produced by GPT-4's chain of thought.",MathInstruct,,open,MIT,,,,,,,,,,,,,,,280,text,text,614
360,model,MAmmoTH,Ohio State University,MAmmoTH is a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.,2023-09-11,https://arxiv.org/pdf/2309.05653.pdf,34B parameters (dense),"Evaluated on MATH, a competition-level dataset, and achieves a 46% accuracy, higher than accuracy produced by GPT-4's chain of thought.",LLaMA,,open,MIT,,,,,,,,,,,,,,,280,text,text,615
360,model,MAmmoTH,Ohio State University,MAmmoTH is a series of open-source large language models (LLMs) specifically tailored for general math problem-solving.,2023-09-11,https://arxiv.org/pdf/2309.05653.pdf,34B parameters (dense),"Evaluated on MATH, a competition-level dataset, and achieves a 46% accuracy, higher than accuracy produced by GPT-4's chain of thought.",Code LLaMA,,open,MIT,,,,,,,,,,,,,,,280,text,text,616
361,model,A.X,SK Telecom,"A.X is SK Telecom's proprietary LLM, which has been trained on the Korean language.",2023-09-26,https://www.sktelecom.com/en/press/press_detail.do?idx=1582,39B parameters,,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,281,text,text,617
362,model,Yi,01 AI,The Yi series models are large language models trained from scratch by developers at 01 AI.,2023-11-02,https://github.com/01-ai/Yi,34B parameters (dense),"Evaluated on standard language benchmarks, common sense reasoning, and reading comprehension in comparison to SoTA LLMs.",,"Model underwent supervised fine-tuning, leading to a greater diversity of responses.",open,custom,,,unknown,https://huggingface.co/01-ai/Yi-34B/discussions,https://huggingface.co/01-ai/Yi-34B,unknown,unknown,unknown,,,,,,,282,text,text,618
363,model,Yi-VL,01 AI,"The Yi Vision Language (Yi-VL) model is the open-source, multimodal version of the Yi Large Language Model (LLM) series, enabling content comprehension, recognition, and multi-round conversations about images.",2024-01-23,https://github.com/01-ai/Yi,34B parameters (dense),"Yi-VL outperforms all existing open-source models in MMMU and CMMMU, two advanced benchmarks that include massive multi-discipline multimodal questions (based on data available up to January 2024).",,unknown,open,custom,,,unknown,https://huggingface.co/01-ai/Yi-VL-34B/discussions,https://huggingface.co/01-ai/Yi-VL-34B,unknown,10 days,128 NVIDIA A800 (80G) GPUs,,,,,,,283,text,text,619
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,LLaMA 2,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,620
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,The Stack,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,621
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RefinedWeb,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,622
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RedPajama,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,623
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Common Crawl,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,624
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Wikipedia,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,625
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,ArXiv,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,code,626
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,LLaMA 2,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,627
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,The Stack,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,628
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RefinedWeb,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,629
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RedPajama,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,630
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Common Crawl,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,631
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Wikipedia,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,632
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,ArXiv,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,code,text,633
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,LLaMA 2,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,634
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,The Stack,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,635
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RefinedWeb,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,636
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RedPajama,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,637
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Common Crawl,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,638
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Wikipedia,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,639
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,ArXiv,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,code,640
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,LLaMA 2,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,641
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,The Stack,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,642
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RefinedWeb,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,643
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,RedPajama,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,644
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Common Crawl,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,645
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Wikipedia,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,646
365,model,Lemur,OpenLemur,Lemur is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,ArXiv,,open,LLaMA2,,,,https://huggingface.co/OpenLemur/lemur-70b-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-v1,unknown,unknown,TPUv4-512 pod,,,,,,,284,text,text,647
366,model,Lemur-Chat,OpenLemur,Lemur-Chat is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Lemur,,open,CC-BY-NC-4.0,,,,https://huggingface.co/OpenLemur/lemur-70b-chat-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-chat-v1,unknown,unknown,unknown,,,,,,,285,text,text,648
366,model,Lemur-Chat,OpenLemur,Lemur-Chat is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,OpenAssistant 1,,open,CC-BY-NC-4.0,,,,https://huggingface.co/OpenLemur/lemur-70b-chat-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-chat-v1,unknown,unknown,unknown,,,,,,,285,text,text,649
366,model,Lemur-Chat,OpenLemur,Lemur-Chat is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,OpenOrca,,open,CC-BY-NC-4.0,,,,https://huggingface.co/OpenLemur/lemur-70b-chat-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-chat-v1,unknown,unknown,unknown,,,,,,,285,text,text,650
366,model,Lemur-Chat,OpenLemur,Lemur-Chat is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,ShareGPT & ChatLogs,,open,CC-BY-NC-4.0,,,,https://huggingface.co/OpenLemur/lemur-70b-chat-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-chat-v1,unknown,unknown,unknown,,,,,,,285,text,text,651
366,model,Lemur-Chat,OpenLemur,Lemur-Chat is an openly accessible language model optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents.,2023-10-10,https://arxiv.org/pdf/2310.06830.pdf,70B parameters (dense),Evaluated on text and code benchmarks in comparison to other models.,Evol-CodeAlpaca data,,open,CC-BY-NC-4.0,,,,https://huggingface.co/OpenLemur/lemur-70b-chat-v1/discussions,https://huggingface.co/OpenLemur/lemur-70b-chat-v1,unknown,unknown,unknown,,,,,,,285,text,text,652
367,model,ACT-1,Adept,ACT-1 (ACtion Transformer) is a large-scale transformer model designed and trained specifically for taking actions on computers (use software tools APIs and websites) in response to the user's natural language commands.,2022-09-14,https://www.adept.ai/blog/act-1,,,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,286,text,text,653
368,model,Persimmon,Adept,"Persimmon is the most capable open-source, fully permissive model with fewer than 10 billion parameters, as of its release date.",2023-09-07,https://www.adept.ai/blog/persimmon-8b,8B parameters (dense),"Evaluated in comparison to LLaMA 2 and MPT Instruct, and outperforms both on standard benchmarks.",,,open,Apache 2.0,,,,,,,,,,,,,,,287,text,text,654
369,model,Fuyu,Adept,Fuyu is a small version of the multimodal model that powers Adept's core product.,2023-10-17,https://www.adept.ai/blog/fuyu-8b,8B parameters (dense),Evaluated on standard image understanding benchmarks.,,,open,CC-BY-NC-4.0,The model is intended for research purposes only.,"The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model.",,https://huggingface.co/adept/fuyu-8b/discussions,https://huggingface.co/adept/fuyu-8b,unknown,unknown,unknown,,,,,,,288,image,text,655
369,model,Fuyu,Adept,Fuyu is a small version of the multimodal model that powers Adept's core product.,2023-10-17,https://www.adept.ai/blog/fuyu-8b,8B parameters (dense),Evaluated on standard image understanding benchmarks.,,,open,CC-BY-NC-4.0,The model is intended for research purposes only.,"The model was not trained to be factual or true representations of people or events, and therefore using the model to generate such content is out-of-scope for the abilities of this model.",,https://huggingface.co/adept/fuyu-8b/discussions,https://huggingface.co/adept/fuyu-8b,unknown,unknown,unknown,,,,,,,288,text,text,656
370,model,Fuyu Heavy,Adept,Fuyu Heavy is a new multimodal model designed specifically for digital agents.,2024-01-24,https://www.adept.ai/blog/adept-fuyu-heavy,unknown,"Evaluated on the MMLU, GSM8K, MATH, and HumanEval benchmarks. According to these benchmarks, Fuyu-Heavy is, as of release, the strongest multimodal model trained outside of Google or OpenAI.",,,closed,unknown,unknown,,,,,unknown,unknown,unknown,,,,,,,289,image,text,657
370,model,Fuyu Heavy,Adept,Fuyu Heavy is a new multimodal model designed specifically for digital agents.,2024-01-24,https://www.adept.ai/blog/adept-fuyu-heavy,unknown,"Evaluated on the MMLU, GSM8K, MATH, and HumanEval benchmarks. According to these benchmarks, Fuyu-Heavy is, as of release, the strongest multimodal model trained outside of Google or OpenAI.",,,closed,unknown,unknown,,,,,unknown,unknown,unknown,,,,,,,289,text,text,658
371,model,CPM Bee,OpenBMB,"CPM-Bee is a fully open-source, commercially-usable Chinese-English bilingual base model with a capacity of ten billion parameters.",2023-05-27,https://github.com/OpenBMB/CPM-Bee,10B parameters (dense),Evaluated on English and Chinese language benchmarks.,,,open,custom,You can use the raw model for many NLP tasks like text generation or fine-tune it to a downstream task.,,unknown,https://huggingface.co/openbmb/cpm-bee-10b/discussions,https://huggingface.co/openbmb/cpm-bee-10b,unknown,unknown,unknown,,,,,,,290,text,text,659
373,model,MiniCPM,OpenBMB,"MiniCPM is an End-Side LLM developed by ModelBest Inc. and TsinghuaNLP, with only 2.4B parameters excluding embeddings (2.7B in total).",2024-02-01,https://github.com/OpenBMB/MiniCPM/,2.4B parameters (dense),Evaluated on open-sourced general benchmarks in comparison to SotA LLMs.,,,open,custom,,,unknown,https://huggingface.co/openbmb/MiniCPM-V/discussions,https://huggingface.co/openbmb/MiniCPM-V,unknown,unknown,unknown,,,,,,,291,text,text,660
374,model,Eurus,OpenBMB,Eurus is a suite of large language models (LLMs) optimized for reasoning.,2024-04-02,https://arxiv.org/abs/2404.02078,70B parameters,The model was comprehensively benchmarked across 12 tests covering five tasks. Eurus achieved the best overall performance among open-source models of similar sizes and even outperformed specialized models in many cases.,Eurus SFT,,open,Apache 2.0,The model can be used for reasoning tasks and is especially tailored for coding and math following specific prompts.,,unknown,https://huggingface.co/openbmb/Eurus-70b-nca/discussions,https://huggingface.co/openbmb/Eurus-70b-nca,unknown,unknown,unknown,,,,,,,292,text,text,661
374,model,Eurus,OpenBMB,Eurus is a suite of large language models (LLMs) optimized for reasoning.,2024-04-02,https://arxiv.org/abs/2404.02078,70B parameters,The model was comprehensively benchmarked across 12 tests covering five tasks. Eurus achieved the best overall performance among open-source models of similar sizes and even outperformed specialized models in many cases.,UltraInteract,,open,Apache 2.0,The model can be used for reasoning tasks and is especially tailored for coding and math following specific prompts.,,unknown,https://huggingface.co/openbmb/Eurus-70b-nca/discussions,https://huggingface.co/openbmb/Eurus-70b-nca,unknown,unknown,unknown,,,,,,,292,text,text,662
374,model,Eurus,OpenBMB,Eurus is a suite of large language models (LLMs) optimized for reasoning.,2024-04-02,https://arxiv.org/abs/2404.02078,70B parameters,The model was comprehensively benchmarked across 12 tests covering five tasks. Eurus achieved the best overall performance among open-source models of similar sizes and even outperformed specialized models in many cases.,UltraFeedback,,open,Apache 2.0,The model can be used for reasoning tasks and is especially tailored for coding and math following specific prompts.,,unknown,https://huggingface.co/openbmb/Eurus-70b-nca/discussions,https://huggingface.co/openbmb/Eurus-70b-nca,unknown,unknown,unknown,,,,,,,292,text,text,663
376,model,ESM-2,Meta,ESM-2 is a series of protein language models trained on protein sequences,2022-10-31,https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2.full.pdf+html,15B parameters (dense),,UniRef50,,open,MIT,,,,,,,,,,,,,,,293,text,protein sequence,664
376,model,ESM-2,Meta,ESM-2 is a series of protein language models trained on protein sequences,2022-10-31,https://www.biorxiv.org/content/10.1101/2022.07.20.500902v2.full.pdf+html,15B parameters (dense),,UniRef90,,open,MIT,,,,,,,,,,,,,,,293,text,protein sequence,665
378,model,FLAVA,Meta,"FLAVA is a multimodal model composed of an image encoder, text encoder, and multimodal encoder.",2021-12-08,https://arxiv.org/abs/2112.04482,306M,"FLAVA is benchmarked on a range of vision-only (e.g. CIFAR-10), language-only (e.g. GLUE), and multimodal (e.g. Hateful Memes) standard evaluations.",PMD,"FLAVA introduces a variety of new modeling techniques, specifically with an interest in improved text-image alignment through contrastive objectives.",open,BSD-3-Clause,"Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""The model is intended to serve as a reproducible research artifact for research communities in the light of models whose exact reproduction details are never released such as CLIP and SimVLM.""
","Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""Any deployed use case of the model - whether commercial or not"" - is currently out of scope.
",,https://huggingface.co/facebook/flava-full/discussions,https://huggingface.co/facebook/flava-full,unknown,unknown,unknown,,,,,,,294,image,image,666
378,model,FLAVA,Meta,"FLAVA is a multimodal model composed of an image encoder, text encoder, and multimodal encoder.",2021-12-08,https://arxiv.org/abs/2112.04482,306M,"FLAVA is benchmarked on a range of vision-only (e.g. CIFAR-10), language-only (e.g. GLUE), and multimodal (e.g. Hateful Memes) standard evaluations.",PMD,"FLAVA introduces a variety of new modeling techniques, specifically with an interest in improved text-image alignment through contrastive objectives.",open,BSD-3-Clause,"Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""The model is intended to serve as a reproducible research artifact for research communities in the light of models whose exact reproduction details are never released such as CLIP and SimVLM.""
","Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""Any deployed use case of the model - whether commercial or not"" - is currently out of scope.
",,https://huggingface.co/facebook/flava-full/discussions,https://huggingface.co/facebook/flava-full,unknown,unknown,unknown,,,,,,,294,image,text,667
378,model,FLAVA,Meta,"FLAVA is a multimodal model composed of an image encoder, text encoder, and multimodal encoder.",2021-12-08,https://arxiv.org/abs/2112.04482,306M,"FLAVA is benchmarked on a range of vision-only (e.g. CIFAR-10), language-only (e.g. GLUE), and multimodal (e.g. Hateful Memes) standard evaluations.",PMD,"FLAVA introduces a variety of new modeling techniques, specifically with an interest in improved text-image alignment through contrastive objectives.",open,BSD-3-Clause,"Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""The model is intended to serve as a reproducible research artifact for research communities in the light of models whose exact reproduction details are never released such as CLIP and SimVLM.""
","Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""Any deployed use case of the model - whether commercial or not"" - is currently out of scope.
",,https://huggingface.co/facebook/flava-full/discussions,https://huggingface.co/facebook/flava-full,unknown,unknown,unknown,,,,,,,294,text,image,668
378,model,FLAVA,Meta,"FLAVA is a multimodal model composed of an image encoder, text encoder, and multimodal encoder.",2021-12-08,https://arxiv.org/abs/2112.04482,306M,"FLAVA is benchmarked on a range of vision-only (e.g. CIFAR-10), language-only (e.g. GLUE), and multimodal (e.g. Hateful Memes) standard evaluations.",PMD,"FLAVA introduces a variety of new modeling techniques, specifically with an interest in improved text-image alignment through contrastive objectives.",open,BSD-3-Clause,"Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""The model is intended to serve as a reproducible research artifact for research communities in the light of models whose exact reproduction details are never released such as CLIP and SimVLM.""
","Per the [[HuggingFace repository]](https://huggingface.co/facebook/flava-full), ""Any deployed use case of the model - whether commercial or not"" - is currently out of scope.
",,https://huggingface.co/facebook/flava-full/discussions,https://huggingface.co/facebook/flava-full,unknown,unknown,unknown,,,,,,,294,text,text,669
380,model,Galactica,Meta,Galactica is a family of autoregressive language models.,2022-11-15,https://galactica.org/static/paper.pdf,120B parameters (dense),,The Galactica Corpus,,open,CC BY-NC 4.0,,,,,https://huggingface.co/facebook/galactica-6.7b,unknown,unknown,Meta AI Cluster. Trained on 1024 80GB A100 GPUs (128 8xA100 80GB nodes),,,,,,,295,code,code,670
380,model,Galactica,Meta,Galactica is a family of autoregressive language models.,2022-11-15,https://galactica.org/static/paper.pdf,120B parameters (dense),,The Galactica Corpus,,open,CC BY-NC 4.0,,,,,https://huggingface.co/facebook/galactica-6.7b,unknown,unknown,Meta AI Cluster. Trained on 1024 80GB A100 GPUs (128 8xA100 80GB nodes),,,,,,,295,code,text,671
380,model,Galactica,Meta,Galactica is a family of autoregressive language models.,2022-11-15,https://galactica.org/static/paper.pdf,120B parameters (dense),,The Galactica Corpus,,open,CC BY-NC 4.0,,,,,https://huggingface.co/facebook/galactica-6.7b,unknown,unknown,Meta AI Cluster. Trained on 1024 80GB A100 GPUs (128 8xA100 80GB nodes),,,,,,,295,text,code,672
380,model,Galactica,Meta,Galactica is a family of autoregressive language models.,2022-11-15,https://galactica.org/static/paper.pdf,120B parameters (dense),,The Galactica Corpus,,open,CC BY-NC 4.0,,,,,https://huggingface.co/facebook/galactica-6.7b,unknown,unknown,Meta AI Cluster. Trained on 1024 80GB A100 GPUs (128 8xA100 80GB nodes),,,,,,,295,text,text,673
381,model,InCoder,"Meta, CMU, TTI-Chicago, UC Berkeley, University of Washington",InCoder is a language model trained on code with a causal masking objective,2022-04-12,https://arxiv.org/abs/2204.05999,6B parameters (dense),,,unknown,open,CC BY-NC 4.0,,,,,,Unknown,"24 days, according to [[the paper]](https://arxiv.org/pdf/2204.05999.pdf)","248 V100 GPUs, according to [[the paper]](https://arxiv.org/pdf/2204.05999.pdf)",,,,,,,296,text,code,674
382,model,OPT,Meta,OPT is a family of autoregressive language models.,2022-05-01,https://arxiv.org/abs/2205.01068,175B parameters (dense),,RoBERTa dataset,,limited,OPT-175B License,,,,,https://arxiv.org/pdf/2205.01068.pdf,75 tCO2e,,Meta AI cluster. Trained on 992 80GB A100 GPUs,,,,,,,297,text,text,675
382,model,OPT,Meta,OPT is a family of autoregressive language models.,2022-05-01,https://arxiv.org/abs/2205.01068,175B parameters (dense),,The Pile,,limited,OPT-175B License,,,,,https://arxiv.org/pdf/2205.01068.pdf,75 tCO2e,,Meta AI cluster. Trained on 992 80GB A100 GPUs,,,,,,,297,text,text,676
382,model,OPT,Meta,OPT is a family of autoregressive language models.,2022-05-01,https://arxiv.org/abs/2205.01068,175B parameters (dense),,PushShift.io Reddit,,limited,OPT-175B License,,,,,https://arxiv.org/pdf/2205.01068.pdf,75 tCO2e,,Meta AI cluster. Trained on 992 80GB A100 GPUs,,,,,,,297,text,text,677
384,model,Make-A-Video,Meta,"Make-A-Video is a model for Text-to-Video Generation without Text-Video Data.
",2022-09-29,https://arxiv.org/pdf/2209.14792.pdf,unknown,"Model performance was evaluated using automated (Frechet Video Distance; Frechet Inception Distance) and human evaluation on two datasets (UCF-101, MSR-VTT) in the zero-shot setting.
",Make-A-Video dataset,,closed,,unknown,unknown,unknown,,,unknown,unknown,unknown,,,,,,,298,text,video,678
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,CommonCrawl,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,679
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,C4,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,680
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,Github,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,681
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,Wikipedia,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,682
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,BooksCorpus,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,683
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,arXiv,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,684
385,model,LLaMA,Meta,"LLaMA is a collection of foundation language models ranging from 7B to 65B parameters trained our on trillions of tokens. The LLaMA models show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets.",2023-02-24,https://arxiv.org/abs/2302.13971,65B parameters (dense),,StackExchange,,open,"LLaMa License (model weights), GPLv3 (code)",,,,,,,,,,,,,,,299,text,text,685
386,model,Llama 2,Meta,Llama 2 is an updated version of LLaMA trained on a new mix of publicly available data.,2023-07-18,https://ai.meta.com/resources/models-and-libraries/llama/,70B parameters (dense),Evaluated on standard academic benchmarks and internal Meta libraries.,,,open,custom,"Llama 2 is intended for commercial and research use in English. Tuned models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks.",Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Llama 2.,,,Can be found at appendix of paper at https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/,539 tCO2eq,,NVIDIA A100-80GB GPUs (TDP of 350-400W),,,,,,,300,text,text,686
387,model,OPT-IML,Meta,,2022-12-22,https://arxiv.org/abs/2212.12017,175B parameters (dense),,OPT,,open,OPT-IML 175B License,,,,,,,,,,,,,,,301,text,text,687
387,model,OPT-IML,Meta,,2022-12-22,https://arxiv.org/abs/2212.12017,175B parameters (dense),,OPT-IML Bench,,open,OPT-IML 175B License,,,,,,,,,,,,,,,301,text,text,688
389,model,SAM,Meta,"SAM (Segment Anything Model) is a foundation model for image segmentation. The model is designed and trained to be promptable, and supports flexible prompts (point, box, mask and free-form text) to compute masks in real-time to allow interactive use.",2023-04-05,https://arxiv.org/pdf/2304.02643.pdf,unknown,"""We extensively evaluate SAM. First, using a diverse new suite of 23 segmentation datasets, we find that SAM produces high-quality masks from a single foreground point, often only slightly below that of the manually annotated ground truth. Second, we find consistently strong quantitative and qualitative results on a variety of downstream tasks under a zero-shot transfer protocol using prompt engineering, including edge detection, object proposal generation, instance segmentation, and a preliminary exploration of text-to-mask prediction.""
",SA-1B,"""We perform a Responsible AI (RAI) analysis of our work by investigating potential fairness concerns and biases when using SA-1B and SAM. We focus on the geographic and income distribution of SA-1B and fairness of SAM across protected attributes of people.""
",open,Apache 2.0,"""SAM is intended to be used for any prompt-based segmentation task. We explored its use in segmenting objects from a point, edge detection, segmenting all objects, and segmenting detected objects. We explored how SAM can integrate with other vision models to segment objects from text.""
","For out-of-scope use cases see terms of use in [[LICENSE]](https://github.com/facebookresearch/segment-anything/blob/main/LICENSE). Authors also discuss the following limitations of the model: ""While SAM performs well in general, it is not perfect. It can miss fine structures, hallucinates small disconnected components at times, and does not produce boundaries as crisply as more computationally intensive methods that “zoom-in”, e.g. [18]. In general, we expect dedicated interactive segmentation methods to outperform SAM when many points are provided, e.g. [67]. Unlike these methods, SAM is designed for generality and breadth of use rather than high IoU interactive segmentation. Moreover, SAM can process prompts in real-time, but nevertheless SAM's overall performance is not real-time when using a heavy image encoder. Our foray into the text-to-mask task is exploratory and not entirely robust, although we believe it can be improved with more effort. While SAM can perform many tasks, it is unclear how to design simple prompts that implement semantic and panoptic segmentation. Finally, there are domain-specific tools, such as [7], that we expect to outperform SAM in their respective domains.""
",,Feedback can be given via the feedback form on their website [segment-anything.com](https://segment-anything.com/) or by emailing at segment-anything at meta.com.,https://arxiv.org/pdf/2304.02643.pdf#page=28,2.8 metric tons of carbon dioxide,68 hours,256 A100 GPUs,,,,,,,302,image,image,689
389,model,SAM,Meta,"SAM (Segment Anything Model) is a foundation model for image segmentation. The model is designed and trained to be promptable, and supports flexible prompts (point, box, mask and free-form text) to compute masks in real-time to allow interactive use.",2023-04-05,https://arxiv.org/pdf/2304.02643.pdf,unknown,"""We extensively evaluate SAM. First, using a diverse new suite of 23 segmentation datasets, we find that SAM produces high-quality masks from a single foreground point, often only slightly below that of the manually annotated ground truth. Second, we find consistently strong quantitative and qualitative results on a variety of downstream tasks under a zero-shot transfer protocol using prompt engineering, including edge detection, object proposal generation, instance segmentation, and a preliminary exploration of text-to-mask prediction.""
",SA-1B,"""We perform a Responsible AI (RAI) analysis of our work by investigating potential fairness concerns and biases when using SA-1B and SAM. We focus on the geographic and income distribution of SA-1B and fairness of SAM across protected attributes of people.""
",open,Apache 2.0,"""SAM is intended to be used for any prompt-based segmentation task. We explored its use in segmenting objects from a point, edge detection, segmenting all objects, and segmenting detected objects. We explored how SAM can integrate with other vision models to segment objects from text.""
","For out-of-scope use cases see terms of use in [[LICENSE]](https://github.com/facebookresearch/segment-anything/blob/main/LICENSE). Authors also discuss the following limitations of the model: ""While SAM performs well in general, it is not perfect. It can miss fine structures, hallucinates small disconnected components at times, and does not produce boundaries as crisply as more computationally intensive methods that “zoom-in”, e.g. [18]. In general, we expect dedicated interactive segmentation methods to outperform SAM when many points are provided, e.g. [67]. Unlike these methods, SAM is designed for generality and breadth of use rather than high IoU interactive segmentation. Moreover, SAM can process prompts in real-time, but nevertheless SAM's overall performance is not real-time when using a heavy image encoder. Our foray into the text-to-mask task is exploratory and not entirely robust, although we believe it can be improved with more effort. While SAM can perform many tasks, it is unclear how to design simple prompts that implement semantic and panoptic segmentation. Finally, there are domain-specific tools, such as [7], that we expect to outperform SAM in their respective domains.""
",,Feedback can be given via the feedback form on their website [segment-anything.com](https://segment-anything.com/) or by emailing at segment-anything at meta.com.,https://arxiv.org/pdf/2304.02643.pdf#page=28,2.8 metric tons of carbon dioxide,68 hours,256 A100 GPUs,,,,,,,302,text,image,690
390,model,Voicebox,Meta,Voicebox is the first generative AI model for speech to generalize across tasks with state-of-the-art performance.,2023-06-16,https://research.facebook.com/publications/voicebox-text-guided-multilingual-universal-speech-generation-at-scale/,330M parameters (dense),"Evaluated on zero-shot text-to-speech benchmarks, with Voicebox outperforming the current state-of-the-art English model VALL-E.",,,closed,,,,,,,unknown,"750,000 iterations",32 GPUs of unspecified type,,,,,,,303,audio,text,691
391,model,PEER,Meta,"PEER is a collaborative language model that is trained to imitate the entire writing process itself. PEER can write drafts, add suggestions, propose edits and provide explanations for its actions.",2022-08-24,https://arxiv.org/pdf/2208.11663.pdf,3B parameters (dense),"PEER is evaluated on core research questions intended to gauge language understanding, proper use of citations, instruction following, and iterative use.",,"Heuristics and edit filtering was used on data set, which consisted mostly of Wikipedia pages.",open,,adapting LLMs to work with collaborative writing and updating.,,,,,,,64 GPUs,,,,,,,304,text,text,692
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Meta Music Initative Sound Collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,audio,audio,693
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Shutterstock music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,audio,audio,694
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Pond5 music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,audio,audio,695
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Meta Music Initative Sound Collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,audio,text,696
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Shutterstock music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,audio,text,697
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Pond5 music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,audio,text,698
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Meta Music Initative Sound Collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,text,audio,699
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Shutterstock music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,text,audio,700
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Pond5 music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,text,audio,701
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Meta Music Initative Sound Collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,text,text,702
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Shutterstock music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,text,text,703
392,model,MusicGen,Meta,MusicGen is a simple and controllable model for music generation that doesn't require self-supervised semantic representation,2023-08-02,https://huggingface.co/spaces/facebook/MusicGen/tree/main,3.3B parameters (dense),"MusicGen was evaluated on standard music benchmarks of Frechet Audio Distance, Kullback-Leibler Divergence, and its CLAP score.",Pond5 music collection,,open,MIT,The primary use of MusicGen is research on AI-based music generation,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate music pieces that create hostile or alienating environments for people. This includes generating music that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/spaces/facebook/MusicGen/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/MUSICGEN_MODEL_CARD.md,,,,,,,,,,305,text,text,704
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioSet,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,705
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,BBC sound effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,706
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioCaps,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,707
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Clotho v2,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,708
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,VGG-Sound,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,709
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,FSD50K,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,710
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Free To Use Sounds,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,711
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Sonniss Game Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,712
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,WeSoundEffects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,713
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Paramount Motion - Odeon Cinematic Sound Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,audio,714
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioSet,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,715
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,BBC sound effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,716
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioCaps,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,717
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Clotho v2,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,718
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,VGG-Sound,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,719
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,FSD50K,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,720
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Free To Use Sounds,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,721
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Sonniss Game Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,722
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,WeSoundEffects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,723
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Paramount Motion - Odeon Cinematic Sound Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,audio,text,724
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioSet,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,725
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,BBC sound effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,726
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioCaps,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,727
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Clotho v2,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,728
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,VGG-Sound,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,729
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,FSD50K,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,730
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Free To Use Sounds,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,731
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Sonniss Game Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,732
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,WeSoundEffects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,733
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Paramount Motion - Odeon Cinematic Sound Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,audio,734
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioSet,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,735
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,BBC sound effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,736
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,AudioCaps,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,737
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Clotho v2,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,738
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,VGG-Sound,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,739
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,FSD50K,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,740
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Free To Use Sounds,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,741
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Sonniss Game Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,742
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,WeSoundEffects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,743
393,model,AudioGen,Meta,AudioGen is an auto-regressive generative model that generates audio samples conditioned on text inputs,2023-08-02,https://felixkreuk.github.io/audiogen/paper.pdf,1.5B parameters (dense),Evaluated on Frechet Audio Distance and Kullback-Leibler Divergence as well as qualitative studies with human participants.,Paramount Motion - Odeon Cinematic Sound Effects,,open,MIT,The primary use of AudioGen is research on AI-based audio generation.,"The model should not be used on downstream applications without further risk evaluation and mitigation. The model should not be used to intentionally create or disseminate audio pieces that create hostile or alienating environments for people. This includes generating audio that people would foreseeably find disturbing, distressing, or offensive; or content that propagates historical or current stereotypes.",,https://huggingface.co/facebook/audiogen-medium/discussions,https://github.com/facebookresearch/audiocraft/blob/main/model_cards/AUDIOGEN_MODEL_CARD.md,,,,,,,,,,306,text,text,744
394,model,Emu,Meta,Emu is a pre-trained latent diffusion model on 1.1 billion image-text pairs and fine-tuned with only a few thousand carefully selected high-quality images.,2023-09-27,https://ai.meta.com/research/publications/emu-enhancing-image-generation-models-using-photogenic-needles-in-a-haystack/,1.5B parameters (dense),Emu significantly outperforms a publicly available state-of-the-art model SDXLv1.0 on visual appeal when compared on standard benchmarks.,CLIP,,closed,unknown,,,,,,,,,,,,,,,307,text,image,745
394,model,Emu,Meta,Emu is a pre-trained latent diffusion model on 1.1 billion image-text pairs and fine-tuned with only a few thousand carefully selected high-quality images.,2023-09-27,https://ai.meta.com/research/publications/emu-enhancing-image-generation-models-using-photogenic-needles-in-a-haystack/,1.5B parameters (dense),Emu significantly outperforms a publicly available state-of-the-art model SDXLv1.0 on visual appeal when compared on standard benchmarks.,T5,,closed,unknown,,,,,,,,,,,,,,,307,text,image,746
395,model,Code LLaMA,Meta,Code Llama is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 34 billion parameters.,2023-08-24,https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/,34B parameters (dense),Evaluated on several code benchmarks like HumanEval and MBPP.,Llama 2,,open,Llama 2,Code Llama and its variants is intended for commercial and research use in English and relevant programming languages.,Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Code Llama and its variants.,,https://huggingface.co/allenai/codetulu-2-13b/discussions,https://huggingface.co/codellama/CodeLlama-34b-hf,65.3 tCO2eq,400K GPU hours,A100-80GB GPUs,,,,,,,308,text,code,747
395,model,Code LLaMA,Meta,Code Llama is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 34 billion parameters.,2023-08-24,https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/,34B parameters (dense),Evaluated on several code benchmarks like HumanEval and MBPP.,Llama 2,,open,Llama 2,Code Llama and its variants is intended for commercial and research use in English and relevant programming languages.,Use in any manner that violates applicable laws or regulations (including trade compliance laws). Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Code Llama and its variants.,,https://huggingface.co/allenai/codetulu-2-13b/discussions,https://huggingface.co/codellama/CodeLlama-34b-hf,65.3 tCO2eq,400K GPU hours,A100-80GB GPUs,,,,,,,308,text,text,748
396,model,Emu Video,Meta,"Emu Video is a text-to-video generation model that factorizes the generation into two steps, first generating an image conditioned on the text, and then generating a video conditioned on the text and the generated image.",2023-11-16,https://emu-video.metademolab.com/,6B parameters (dense),Analyzed against nearest neighbor model baseline and by extending the video length.,Emu,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,309,text,video,749
396,model,Emu Video,Meta,"Emu Video is a text-to-video generation model that factorizes the generation into two steps, first generating an image conditioned on the text, and then generating a video conditioned on the text and the generated image.",2023-11-16,https://emu-video.metademolab.com/,6B parameters (dense),Analyzed against nearest neighbor model baseline and by extending the video length.,CLIP,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,309,text,video,750
396,model,Emu Video,Meta,"Emu Video is a text-to-video generation model that factorizes the generation into two steps, first generating an image conditioned on the text, and then generating a video conditioned on the text and the generated image.",2023-11-16,https://emu-video.metademolab.com/,6B parameters (dense),Analyzed against nearest neighbor model baseline and by extending the video length.,T5,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,309,text,video,751
397,model,Emu Edit,Meta,Emu Edit is a multi-task image editing model which sets state-of-the-art results in instruction-based image editing.,2023-11-16,https://emu-edit.metademolab.com/,unknown,Evaluated on test set of actions in comparison to SoTA image editing models.,Emu,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,310,text,image,752
397,model,Emu Edit,Meta,Emu Edit is a multi-task image editing model which sets state-of-the-art results in instruction-based image editing.,2023-11-16,https://emu-edit.metademolab.com/,unknown,Evaluated on test set of actions in comparison to SoTA image editing models.,CLIP,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,310,text,image,753
397,model,Emu Edit,Meta,Emu Edit is a multi-task image editing model which sets state-of-the-art results in instruction-based image editing.,2023-11-16,https://emu-edit.metademolab.com/,unknown,Evaluated on test set of actions in comparison to SoTA image editing models.,T5,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,310,text,image,754
398,model,MetaCLIP,Meta,MetaCLIP is a more transparent rendition of CLIP that aims to reveal CLIP's training data curation methods.,2023-10-02,https://arxiv.org/pdf/2103.00020.pdf,unknown,Evaluated in comparison to CLIP.,Common Crawl,,open,CC-BY-NC-4.0,,,,,https://huggingface.co/facebook/metaclip-b32-400m,unknown,unknown,unknown,,,,,,,311,text,text,755
399,model,Llama 3,Meta,Llama 3 is the third generation of Meta AI's open-source large language model. It comes with pretrained and instruction-fine-tuned language models with 8B and 70B parameters that can support a broad range of use cases.,2024-04-18,https://llama.meta.com/llama3/,70B parameters,"The models were evaluated based on their performance on standard benchmarks and real-world scenarios. These evaluations were performed using a high-quality human evaluation set containing 1,800 prompts covering multiple use cases. The models also went through red-teaming for safety, where human experts and automated methods were used to generate adversarial prompts to test for problematic responses.",,"Extensive internal and external testing for safety, and design of new trust and safety tools.",open,Llama 3,"Llama 3 is intended for a broad range of use cases, including AI assistance, content creation, learning, and analysis.",unknown,Extensive internal and external performance evaluation and red-teaming approach for safety testing.,"Feedback is encouraged from users to improve the model, but the feedback mechanism is not explicitly described.",https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md,unknown,unknown,2 custom-built Meta 24K GPU clusters,,,,,,,312,text,text,756
400,application,HyperWrite,OthersideAI,"HyperWrite is a writing assistant that generates text based on a user's request, as well as style and tone choices.
",,https://hyperwriteai.com/,,,OpenAI API,unknown,limited,custom,"HyperWrite is intended to be used as a writing assistant.
",unknown,unknown,unknown,,,,,unknown,Generation,https://hyperwriteai.com/terms,unknown,unknown,unknown,313,nan,nan,757
401,model,Midm,KT Corporation,Midm is a pre-trained Korean-English language model developed by KT. It takes text as input and creates text. The model is based on Transformer architecture for an auto-regressive language model.,2023-10-31,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1,7B parameters,unknown,AI-HUB dataset,"KT tried to remove unethical expressions such as profanity, slang, prejudice, and discrimination from training data.",open,CC-BY-NC 4.0,It is expected to be used for various research purposes.,It cannot be used for commercial purposes.,unknown,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1/discussions,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1,unknown,unknown,unknown,,,,,,,314,text,text,758
401,model,Midm,KT Corporation,Midm is a pre-trained Korean-English language model developed by KT. It takes text as input and creates text. The model is based on Transformer architecture for an auto-regressive language model.,2023-10-31,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1,7B parameters,unknown,National Institute of Korean Language dataset,"KT tried to remove unethical expressions such as profanity, slang, prejudice, and discrimination from training data.",open,CC-BY-NC 4.0,It is expected to be used for various research purposes.,It cannot be used for commercial purposes.,unknown,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1/discussions,https://huggingface.co/KT-AI/midm-bitext-S-7B-inst-v1,unknown,unknown,unknown,,,,,,,314,text,text,759
404,model,Anthropic RLHF models,Anthropic,"Anthropic RLHF models are models trained using reinforcement learning from human feedback (RLHF). For Anthropic RLHF models, authors started with a set of base models, and asked humans to rank model generated prompts based on a specific tasks. They then trained preference models (PM) on the prompt pairs, and use the PM scores as rewards for training the RLHF models.
",2022-04-12,https://arxiv.org/pdf/2204.05862.pdf,52B parameters (dense),"The authors analyzed the impact of the dataset mixture on the preference models (PM). In addition to human evaluation, RLHF model were evaluated on MMLU, Lambada, HellaSwag, OpenBookQA, ARC-Easy, ARC-Challenge, TriviaQA, code generation, summarization.
",Anthropic Harmlessness dataset,"unknown
",closed,,unknown,unknown,unknown,unknown,,unknown,unknown,unknown,,,,,,,315,code,text,760
404,model,Anthropic RLHF models,Anthropic,"Anthropic RLHF models are models trained using reinforcement learning from human feedback (RLHF). For Anthropic RLHF models, authors started with a set of base models, and asked humans to rank model generated prompts based on a specific tasks. They then trained preference models (PM) on the prompt pairs, and use the PM scores as rewards for training the RLHF models.
",2022-04-12,https://arxiv.org/pdf/2204.05862.pdf,52B parameters (dense),"The authors analyzed the impact of the dataset mixture on the preference models (PM). In addition to human evaluation, RLHF model were evaluated on MMLU, Lambada, HellaSwag, OpenBookQA, ARC-Easy, ARC-Challenge, TriviaQA, code generation, summarization.
",Anthropic Helpfulness dataset,"unknown
",closed,,unknown,unknown,unknown,unknown,,unknown,unknown,unknown,,,,,,,315,code,text,761
405,application,Anthropic Human Feedback Interface,Anthropic,"The feedback interface used to collect preference datasets to train Anthropic RLHF models [[Paper]](https://arxiv.org/pdf/2204.05862.pdf).
",2022-04-12,https://arxiv.org/pdf/2204.05862.pdf,,,Anthropic RLHF models,unknown,closed,unknown,"Intended to be used by crowdworkers who are tasked with ranking model answers.
",unknown,unknown,unknown,,,,,,"UI allowing users to indicate their preference for the model responses shown.
",unknown,unknown,crowdworkers,unknown,316,nan,nan,762
406,application,Anthropic API,Anthropic,"API is designed to be a backend that incorporates Claude into any application you’ve developed. Our application sends text to our API, then receives a response via server-sent events, a streaming protocol for the web.",2023-03-14,https://console.anthropic.com/docs/api,,,Claude,,limited,,,,,,,,,,,,,,,,317,nan,nan,763
406,application,Anthropic API,Anthropic,"API is designed to be a backend that incorporates Claude into any application you’ve developed. Our application sends text to our API, then receives a response via server-sent events, a streaming protocol for the web.",2023-03-14,https://console.anthropic.com/docs/api,,,Claude Instant,,limited,,,,,,,,,,,,,,,,317,nan,nan,764
407,model,Claude,Anthropic,,2023-03-14,https://www.anthropic.com/index/introducing-claude,unknown,,,,limited,unknown,,,,,,,,,,,,,,,318,text,text,765
408,model,Claude Instant,Anthropic,,2023-03-14,https://www.anthropic.com/index/introducing-claude,unknown,,,,limited,unknown,,,,,,,,,,,,,,,319,text,text,766
409,model,Claude 2,Anthropic,"Claude 2 is a more evolved and refined version of Claude, which is a general purpose large language model using a transformer architecture and trained via unsupervised learning.",2023-07-11,https://www.anthropic.com/index/claude-2,,"Evaluated with human feedback on helpfulness, harmfulness, and honesty and on the Bias Benchmark for QA.",Claude human feedback data,,limited,,"Claude 2 tends to perform well at general, open-ended conversation; search, writing, editing, outlining, and summarizing text; coding; and providing helpful advice about a broad range of subjects. Claude 2 is particularly well suited to support creative or literary use cases. They can take direction on tone and “personality,” and users have described them as feeling steerable and conversational.",Claude 2 should not be used on their own in high stakes situations where an incorrect answer would cause harm.,,,https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf,,,unknown,,,,,,,320,text,text,767
409,model,Claude 2,Anthropic,"Claude 2 is a more evolved and refined version of Claude, which is a general purpose large language model using a transformer architecture and trained via unsupervised learning.",2023-07-11,https://www.anthropic.com/index/claude-2,,"Evaluated with human feedback on helpfulness, harmfulness, and honesty and on the Bias Benchmark for QA.",Unknown licensed third party datasets,,limited,,"Claude 2 tends to perform well at general, open-ended conversation; search, writing, editing, outlining, and summarizing text; coding; and providing helpful advice about a broad range of subjects. Claude 2 is particularly well suited to support creative or literary use cases. They can take direction on tone and “personality,” and users have described them as feeling steerable and conversational.",Claude 2 should not be used on their own in high stakes situations where an incorrect answer would cause harm.,,,https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf,,,unknown,,,,,,,320,text,text,768
410,model,Claude 2.1,Anthropic,"Claude 2.1 is an updated version of Claude 2, with an increased context window, less hallucination and tool use.",2023-11-21,https://www.anthropic.com/index/claude-2-1,unknown,"Evaluated on open-ended conversation accuracy and long context question answering. In evaluations, Claude 2.1 demonstrated a 30% reduction in incorrect answers and a 3-4x lower rate of mistakenly concluding a document supports a particular claim.",,,limited,unknown,,,,,,unknown,unknown,unknown,,,,,,,321,text,text,769
411,application,Claude for Sheets,Anthropic,Claude for Sheets is a Google Sheets add-on that allows the usage of Claude directly in Google Sheets.,2023-12-21,https://workspace.google.com/marketplace/app/claude_for_sheets/909417792257,,,Anthropic API,,open,unknown,as an integrated AI assistant in Google Sheets,,unknown,Reviews on https://workspace.google.com/marketplace/app/claude_for_sheets/909417792257,,,,,,AI-generated text from prompt,https://claude.ai/legal,unknown,unknown,unknown,322,nan,nan,770
412,model,Claude 3,Anthropic,The Claude 3 model family is a collection of models which sets new industry benchmarks across a wide range of cognitive tasks.,2024-03-04,https://www.anthropic.com/news/claude-3-family,unknown,"Evaluated on reasoning, math, coding, reading comprehension, and question answering, outperforming GPT-4 on standard benchmarks.",,Pre-trained on diverse dataset and aligned with Constitutional AI technique.,limited,unknown,"Claude models excel at open-ended conversation and collaboration on ideas, and also perform exceptionally well in coding tasks and when working with text - whether searching, writing, editing, outlining, or summarizing.","Prohibited uses include, but are not limited to, political campaigning or lobbying, surveillance, social scoring, criminal justice decisions, law enforcement, and decisions related to financing, employment, and housing.",,,https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf,unknown,unknown,unknown,,,,,,,323,image,text,771
412,model,Claude 3,Anthropic,The Claude 3 model family is a collection of models which sets new industry benchmarks across a wide range of cognitive tasks.,2024-03-04,https://www.anthropic.com/news/claude-3-family,unknown,"Evaluated on reasoning, math, coding, reading comprehension, and question answering, outperforming GPT-4 on standard benchmarks.",,Pre-trained on diverse dataset and aligned with Constitutional AI technique.,limited,unknown,"Claude models excel at open-ended conversation and collaboration on ideas, and also perform exceptionally well in coding tasks and when working with text - whether searching, writing, editing, outlining, or summarizing.","Prohibited uses include, but are not limited to, political campaigning or lobbying, surveillance, social scoring, criminal justice decisions, law enforcement, and decisions related to financing, employment, and housing.",,,https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf,unknown,unknown,unknown,,,,,,,323,text,text,772
416,model,T0++,BigScience,T0++ is an multitask fine-tuned language model based on T5.,2021-10-15,https://arxiv.org/pdf/2110.08207.pdf,11B parameters (dense),,T5,https://arxiv.org/pdf/2110.08207.pdf,open,Apache 2.0,"You can use the models to perform inference on tasks by specifying your query in natural language, and the models will generate a prediction.",,,https://huggingface.co/bigscience/T0pp/discussions,https://huggingface.co/bigscience/T0pp,0.9 tCO2e,27 hours,Jean Zay (v3-512),,,,,,,324,text,text,773
416,model,T0++,BigScience,T0++ is an multitask fine-tuned language model based on T5.,2021-10-15,https://arxiv.org/pdf/2110.08207.pdf,11B parameters (dense),,P3,https://arxiv.org/pdf/2110.08207.pdf,open,Apache 2.0,"You can use the models to perform inference on tasks by specifying your query in natural language, and the models will generate a prediction.",,,https://huggingface.co/bigscience/T0pp/discussions,https://huggingface.co/bigscience/T0pp,0.9 tCO2e,27 hours,Jean Zay (v3-512),,,,,,,324,text,text,774
417,model,BLOOM,BigScience,BLOOM is an autoregressive multilingual language model.,2022-07-12,https://arxiv.org/abs/2211.05100,176B parameters (dense),,ROOTS,,open,BigScience RAIL v1.0,This model is being created in order to enable public research on large language models (LLMs). LLMs are intended to be used for language generation or as a pretrained base model that can be further fine-tuned for specific tasks. Use cases below are not exhaustive.,"Using the model in high-stakes settings is out of scope for this model (e.g. biomedical/political/legal/finance domains, evaluating or scoring individuals). The model is not designed for critical decisions nor uses with any material consequences on an individual's livelihood or wellbeing. The model outputs content that appears factual but may not be correct. Misuse. Intentionally using the model for harm, violating human rights, or other kinds of malicious activities, is a misuse of this model (e.g. spam generation, disinformation, disparagement, deception, surveillance).",,https://huggingface.co/bigscience/bloom/discussions,,25 tCO2e,7039 petaflop/s-days,Jean Zay (48 * 8xA100 80GB nodes),,,,,,,325,code,code,775
417,model,BLOOM,BigScience,BLOOM is an autoregressive multilingual language model.,2022-07-12,https://arxiv.org/abs/2211.05100,176B parameters (dense),,ROOTS,,open,BigScience RAIL v1.0,This model is being created in order to enable public research on large language models (LLMs). LLMs are intended to be used for language generation or as a pretrained base model that can be further fine-tuned for specific tasks. Use cases below are not exhaustive.,"Using the model in high-stakes settings is out of scope for this model (e.g. biomedical/political/legal/finance domains, evaluating or scoring individuals). The model is not designed for critical decisions nor uses with any material consequences on an individual's livelihood or wellbeing. The model outputs content that appears factual but may not be correct. Misuse. Intentionally using the model for harm, violating human rights, or other kinds of malicious activities, is a misuse of this model (e.g. spam generation, disinformation, disparagement, deception, surveillance).",,https://huggingface.co/bigscience/bloom/discussions,,25 tCO2e,7039 petaflop/s-days,Jean Zay (48 * 8xA100 80GB nodes),,,,,,,325,code,text,776
417,model,BLOOM,BigScience,BLOOM is an autoregressive multilingual language model.,2022-07-12,https://arxiv.org/abs/2211.05100,176B parameters (dense),,ROOTS,,open,BigScience RAIL v1.0,This model is being created in order to enable public research on large language models (LLMs). LLMs are intended to be used for language generation or as a pretrained base model that can be further fine-tuned for specific tasks. Use cases below are not exhaustive.,"Using the model in high-stakes settings is out of scope for this model (e.g. biomedical/political/legal/finance domains, evaluating or scoring individuals). The model is not designed for critical decisions nor uses with any material consequences on an individual's livelihood or wellbeing. The model outputs content that appears factual but may not be correct. Misuse. Intentionally using the model for harm, violating human rights, or other kinds of malicious activities, is a misuse of this model (e.g. spam generation, disinformation, disparagement, deception, surveillance).",,https://huggingface.co/bigscience/bloom/discussions,,25 tCO2e,7039 petaflop/s-days,Jean Zay (48 * 8xA100 80GB nodes),,,,,,,325,text,code,777
417,model,BLOOM,BigScience,BLOOM is an autoregressive multilingual language model.,2022-07-12,https://arxiv.org/abs/2211.05100,176B parameters (dense),,ROOTS,,open,BigScience RAIL v1.0,This model is being created in order to enable public research on large language models (LLMs). LLMs are intended to be used for language generation or as a pretrained base model that can be further fine-tuned for specific tasks. Use cases below are not exhaustive.,"Using the model in high-stakes settings is out of scope for this model (e.g. biomedical/political/legal/finance domains, evaluating or scoring individuals). The model is not designed for critical decisions nor uses with any material consequences on an individual's livelihood or wellbeing. The model outputs content that appears factual but may not be correct. Misuse. Intentionally using the model for harm, violating human rights, or other kinds of malicious activities, is a misuse of this model (e.g. spam generation, disinformation, disparagement, deception, surveillance).",,https://huggingface.co/bigscience/bloom/discussions,,25 tCO2e,7039 petaflop/s-days,Jean Zay (48 * 8xA100 80GB nodes),,,,,,,325,text,text,778
418,model,mT0,BigScience,mT0 is an multitask fine-tuned multilingual language model based on mT5.,2021-10-15,https://arxiv.org/pdf/2110.08207.pdf,13B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,mT5,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/T0pp,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,326,text,text,779
418,model,mT0,BigScience,mT0 is an multitask fine-tuned multilingual language model based on mT5.,2021-10-15,https://arxiv.org/pdf/2110.08207.pdf,13B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,xP3,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/T0pp,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,326,text,text,780
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,BLOOM,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,code,code,781
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,xP3,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,code,code,782
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,BLOOM,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,code,text,783
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,xP3,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,code,text,784
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,BLOOM,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,text,code,785
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,xP3,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,text,code,786
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,BLOOM,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,text,text,787
419,model,BLOOMZ,BigScience,BLOOMZ is an multitask fine-tuned autoregressive multilingual language model.,2022-11-03,https://arxiv.org/pdf/2211.01786.pdf,176B parameters (dense),https://huggingface.co/bigscience/bloomz#evaluation,xP3,https://arxiv.org/pdf/2211.01786.pdf,open,BigScience RAIL v1.0,We recommend using the model to perform tasks expressed in natural language.,,,https://huggingface.co/bigscience/bloomz/discussions,https://huggingface.co/bigscience/bloomz,unknown,unknown,"Jean Zay (288 A100 80GB GPUs with 8 GPUs per node (36 nodes) using NVLink 4 inter-gpu connects, 4 OmniPath links)",,,,,,,327,text,text,788
420,model,CausalLM,CausalLM,CausalLM is an LLM based on the model weights of Qwen and trained on a model architecture identical to LLaMA 2.,2023-10-21,https://huggingface.co/CausalLM/14B,14B parameters (dense),Evaluated on standard benchmarks across a range of tasks.,Qwen,,open,WTFPL,,,unknown,,https://huggingface.co/CausalLM/14B,unknown,unknown,unknown,,,,,,,328,text,text,789
420,model,CausalLM,CausalLM,CausalLM is an LLM based on the model weights of Qwen and trained on a model architecture identical to LLaMA 2.,2023-10-21,https://huggingface.co/CausalLM/14B,14B parameters (dense),Evaluated on standard benchmarks across a range of tasks.,OpenOrca,,open,WTFPL,,,unknown,,https://huggingface.co/CausalLM/14B,unknown,unknown,unknown,,,,,,,328,text,text,790
420,model,CausalLM,CausalLM,CausalLM is an LLM based on the model weights of Qwen and trained on a model architecture identical to LLaMA 2.,2023-10-21,https://huggingface.co/CausalLM/14B,14B parameters (dense),Evaluated on standard benchmarks across a range of tasks.,Open Platypus,,open,WTFPL,,,unknown,,https://huggingface.co/CausalLM/14B,unknown,unknown,unknown,,,,,,,328,text,text,791
421,application,Bain Chat,Bain,"With the alliance, Bain will combine its deep digital implementation capabilities and strategic expertise with OpenAI’s AI tools and platforms, including ChatGPT, to help its clients around the world identify and implement the value of AI to maximize business potential.",2023-02-21,https://www.bain.com/vector-digital/partnerships-alliance-ecosystem/openai-alliance/,,,ChatGPT API,,limited,unknown,,,,,,,,,,,,,,,329,nan,nan,792
422,model,SauerkrautLM,VAGO Solutions,SauerkrautLM is a German language model merged from two Mistral derivatives.,2023-11-28,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO,7B parameters (dense),Evaluated on standard benchmarks in comparison to other German language models.,OpenHermes 2.5 Mistral,,open,Apache 2.0,,,unknown,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO/discussions,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO,unknown,unknown,unknown,,,,,,,330,text,text,793
422,model,SauerkrautLM,VAGO Solutions,SauerkrautLM is a German language model merged from two Mistral derivatives.,2023-11-28,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO,7B parameters (dense),Evaluated on standard benchmarks in comparison to other German language models.,OpenOrca Mistral,,open,Apache 2.0,,,unknown,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO/discussions,https://huggingface.co/VAGOsolutions/SauerkrautLM-7b-HerO,unknown,unknown,unknown,,,,,,,330,text,text,794
423,application,Transformify Automate,Transformify,Transformify Automate is a platform for automated task integration using natural language prompts.,2023-05-30,https://www.transformify.ai/automate,,,GPT-4,,open,,,,,,,,,,,text and code,https://www.transformify.ai/legal-stuff,,,,331,nan,nan,795
424,model,Palmyra,Writer,Palmyra is a family of privacy-first LLMs for enterprises trained on business and marketing writing.,2023-01-01,https://gpt3demo.com/apps/palmyra,20B parameters (dense),Evaluated on the SuperGLUE benchmark,Writer dataset,,open,Apache 2.0,generating text from a prompt,,,https://huggingface.co/Writer/palmyra-base/discussions,https://huggingface.co/Writer/palmyra-base,unknown,unknown,,,,,,,,332,text,text,796
425,model,Camel,Writer,Camel is an instruction-following large language model tailored for advanced NLP and comprehension capabilities.,2023-04-01,https://chatcamel.vercel.app/,5B parameters (dense),,Palmyra,,open,Apache 2.0,,,,https://huggingface.co/Writer/camel-5b-hf/discussions,https://huggingface.co/Writer/camel-5b-hf,unknown,unknown,,,,,,,,333,text,text,797
425,model,Camel,Writer,Camel is an instruction-following large language model tailored for advanced NLP and comprehension capabilities.,2023-04-01,https://chatcamel.vercel.app/,5B parameters (dense),,Camel dataset,,open,Apache 2.0,,,,https://huggingface.co/Writer/camel-5b-hf/discussions,https://huggingface.co/Writer/camel-5b-hf,unknown,unknown,,,,,,,,333,text,text,798
426,model,Dolly,Databricks,"""Databricks’ Dolly, a large language model trained on the Databricks
 Machine Learning Platform, demonstrates that a two-years-old open source
 model (GPT-J) can, when subjected to just 30 minutes of fine tuning on a
 focused corpus of 50k records (Stanford Alpaca), exhibit surprisingly
 high quality instruction following behavior not characteristic of the
 foundation model on which it is based.""
 [[Dolly Repository]](https://github.com/databrickslabs/dolly).
",2023-03-24,https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html,6B parameters (dense),"""We evaluated Dolly on the instruction-following capabilities described in the InstructGPT paper that ChatGPT is based on and found that it exhibits many of the same qualitative capabilities, including text generation, brainstorming and open Q&A."" [[Databricks Blog Post]] (https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html).
",GPT-J,,open,Apache 2.0,"""Dolly is intended exclusively for research purposes and is not licensed for commercial use."" [[Limitations]](https://github.com/databrickslabs/dolly#limitations).
","Authors note the following limitations of the model: ""The Dolly model family is under active development, and so any list of shortcomings is unlikely to be exhaustive, but we include known limitations and misfires here as a means to document and share our preliminary findings with the community. In particular, dolly-6b struggles with syntactically complex prompts, mathematical operations, factual errors, dates and times, open-ended question answering, hallucination, enumerating lists of specific length, and stylistic mimicry."" [[Limitations]](https://github.com/databrickslabs/dolly#limitations).
",,https://github.com/databrickslabs/dolly/issues,,unknown,30 minutes,A single NDasrA100_v4 machine with 8x A100 40GB GPUs,,,,,,,334,text,text,799
426,model,Dolly,Databricks,"""Databricks’ Dolly, a large language model trained on the Databricks
 Machine Learning Platform, demonstrates that a two-years-old open source
 model (GPT-J) can, when subjected to just 30 minutes of fine tuning on a
 focused corpus of 50k records (Stanford Alpaca), exhibit surprisingly
 high quality instruction following behavior not characteristic of the
 foundation model on which it is based.""
 [[Dolly Repository]](https://github.com/databrickslabs/dolly).
",2023-03-24,https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html,6B parameters (dense),"""We evaluated Dolly on the instruction-following capabilities described in the InstructGPT paper that ChatGPT is based on and found that it exhibits many of the same qualitative capabilities, including text generation, brainstorming and open Q&A."" [[Databricks Blog Post]] (https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html).
",Alpaca dataset,,open,Apache 2.0,"""Dolly is intended exclusively for research purposes and is not licensed for commercial use."" [[Limitations]](https://github.com/databrickslabs/dolly#limitations).
","Authors note the following limitations of the model: ""The Dolly model family is under active development, and so any list of shortcomings is unlikely to be exhaustive, but we include known limitations and misfires here as a means to document and share our preliminary findings with the community. In particular, dolly-6b struggles with syntactically complex prompts, mathematical operations, factual errors, dates and times, open-ended question answering, hallucination, enumerating lists of specific length, and stylistic mimicry."" [[Limitations]](https://github.com/databrickslabs/dolly#limitations).
",,https://github.com/databrickslabs/dolly/issues,,unknown,30 minutes,A single NDasrA100_v4 machine with 8x A100 40GB GPUs,,,,,,,334,text,text,800
427,model,DBRX,Databricks,DBRX is a transformer-based decoder-only large language model (LLM) that was trained using next-token prediction by Databricks. It uses a fine-grained mixture-of-experts (MoE) architecture with 132B total parameters of which 36B parameters are active on any input. DBRX only accepts text-based inputs and produces text-based outputs.,2024-03-27,https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm,132B parameters (sparse),"DBRX outperforms established open-source and open-weight base models on the Databricks Model Gauntlet, the Hugging Face Open LLM Leaderboard, and HumanEval. Full evaluation details can be found in the corresponding technical blog post.",,Recommendations provided for retrieval augmented generation (RAG) in scenarios where accuracy and fidelity are important and additional testing around safety in the context of the specific application and domain is suggested.,open,Databricks Open Model License,"DBRX models are open, general-purpose LLMs intended and licensed for both commercial and research applications. They can be further fine-tuned for various domain-specific natural language and coding tasks.","DBRX models are not intended to be used out-of-the-box in non-English languages, and do not support native code execution, function calling or any use that violates applicable laws or regulations or is otherwise prohibited by the Databricks Open Model License and Databricks Open Model Acceptable Use Policy.",unknown,https://huggingface.co/databricks/dbrx-base/discussions,https://huggingface.co/databricks/dbrx-base,unknown,3 months,3072 NVIDIA H100s connected by 3.2Tbps Infiniband,,,,,,,335,text,text,801
428,model,Vicuna,LMSYS,An open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.,2023-03-30,https://lmsys.org/blog/2023-03-30-vicuna/,13B parameters (dense),Evaluated against similar LLMs using GPT-4 as a judge.,LLaMA,,open,Apache 2.0,research on LLMs and chatbots,,,https://huggingface.co/datasets/bigcode/the-stack/discussions,https://huggingface.co/lmsys/vicuna-13b-delta-v0,,1 day,8 A100 GPUs,,,,,,,336,text,text,802
428,model,Vicuna,LMSYS,An open-source chatbot trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.,2023-03-30,https://lmsys.org/blog/2023-03-30-vicuna/,13B parameters (dense),Evaluated against similar LLMs using GPT-4 as a judge.,ShareGPT conversations data,,open,Apache 2.0,research on LLMs and chatbots,,,https://huggingface.co/datasets/bigcode/the-stack/discussions,https://huggingface.co/lmsys/vicuna-13b-delta-v0,,1 day,8 A100 GPUs,,,,,,,336,text,text,803
429,model,EXAONE 2.0,LG AI Research,EXAONE 2.0 is a multimodal artificial intelligence that can be used to help develop new materials and medicines.,2023-07-19,https://www.lgresearch.ai/exaone,unknown,,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,337,image,image,804
429,model,EXAONE 2.0,LG AI Research,EXAONE 2.0 is a multimodal artificial intelligence that can be used to help develop new materials and medicines.,2023-07-19,https://www.lgresearch.ai/exaone,unknown,,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,337,image,text,805
429,model,EXAONE 2.0,LG AI Research,EXAONE 2.0 is a multimodal artificial intelligence that can be used to help develop new materials and medicines.,2023-07-19,https://www.lgresearch.ai/exaone,unknown,,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,337,text,image,806
429,model,EXAONE 2.0,LG AI Research,EXAONE 2.0 is a multimodal artificial intelligence that can be used to help develop new materials and medicines.,2023-07-19,https://www.lgresearch.ai/exaone,unknown,,,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,337,text,text,807
430,model,RakutenAI,Rakuten,RakutenAI-7B is a model developed with a focus on Japanese language understanding. It offers competitive performance on English tests as well.,2024-03-21,https://global.rakuten.com/corp/news/press/2024/0321_01.html,7B parameters,"RakutenAI achieves the highest average score in both Japanese and English LM-Harness metrics, outperforming other similarly-sized Japanese language models.",Mistral,unknown,open,Apache 2.0,The model can be used for text generation tasks in both Japanese and English.,unknown,unknown,https://huggingface.co/Rakuten/RakutenAI-7B/discussions,https://huggingface.co/Rakuten/RakutenAI-7B,unknown,unknown,unknown,,,,,,,338,text,text,808
431,model,OpenBA,Soochow University,OpenBA is an open-sourced 15B bilingual (English + Chinese) asymmetric seq2seq model.,2023-10-01,https://arxiv.org/pdf/2309.10706.pdf,15B parameters (dense),Evaluated across different text benchmarks in English and Chinese.,,,open,Apache 2.0,,,,https://huggingface.co/OpenBA/OpenBA-LM/discussions,https://huggingface.co/OpenBA/OpenBA-LM,6.5 tCO2eq,38k GPU hours,8 NVIDIA A100-80GB GPUs,,,,,,,339,text,text,809
432,application,AI DJ,Spotify,"The DJ is a personalized AI guide that knows you and your music taste so well that it can choose what to play for you. This feature, first rolling out in beta, will deliver a curated lineup of music alongside commentary around the tracks and artists we think you’ll like in a stunningly realistic voice.",2023-02-23,https://newsroom.spotify.com/2023-02-22/spotify-debuts-a-new-ai-dj-right-in-your-pocket/,,,ChatGPT API,,limited,custom,,,,,,,,,,,https://www.spotify.com/us/legal/end-user-agreement/,,,,340,nan,nan,810
432,application,AI DJ,Spotify,"The DJ is a personalized AI guide that knows you and your music taste so well that it can choose what to play for you. This feature, first rolling out in beta, will deliver a curated lineup of music alongside commentary around the tracks and artists we think you’ll like in a stunningly realistic voice.",2023-02-23,https://newsroom.spotify.com/2023-02-22/spotify-debuts-a-new-ai-dj-right-in-your-pocket/,,,Sonantic AI,,limited,custom,,,,,,,,,,,https://www.spotify.com/us/legal/end-user-agreement/,,,,340,nan,nan,811
433,model,Koala,Berkeley,A relatively small chatbot trained by fine-tuning Meta’s LLaMA on dialogue data gathered from the web.,2023-04-03,https://bair.berkeley.edu/blog/2023/04/03/koala/,13B parameters (dense),Evaluated in comparison with ChatGPT and Stanford Alpaca.,LLaMA,,open,Apache 2.0,academic research,,,https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g/discussions,https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g,,6 hours,8 A100 GPUs,,,,,,,341,text,text,812
433,model,Koala,Berkeley,A relatively small chatbot trained by fine-tuning Meta’s LLaMA on dialogue data gathered from the web.,2023-04-03,https://bair.berkeley.edu/blog/2023/04/03/koala/,13B parameters (dense),Evaluated in comparison with ChatGPT and Stanford Alpaca.,web-scraped dialogue data,,open,Apache 2.0,academic research,,,https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g/discussions,https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g,,6 hours,8 A100 GPUs,,,,,,,341,text,text,813
434,model,Gorilla,Berkeley,Gorilla is a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.,2023-05-24,https://arxiv.org/pdf/2305.15334v1.pdf,7B parameters (dense),Evaluated using AST sub-tree matching technique and compared to other models in terms of API functionality accuracy.,LLaMA,"No specific quality control is mentioned in model training, though details on data processing and collection are provided in the paper.",open,Apache 2.0,In conjunction with a LLM to improve its capability for using API calls.,,,,,,,,,,,,,,342,text,API,814
434,model,Gorilla,Berkeley,Gorilla is a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls.,2023-05-24,https://arxiv.org/pdf/2305.15334v1.pdf,7B parameters (dense),Evaluated using AST sub-tree matching technique and compared to other models in terms of API functionality accuracy.,Gorilla document retriever,"No specific quality control is mentioned in model training, though details on data processing and collection are provided in the paper.",open,Apache 2.0,In conjunction with a LLM to improve its capability for using API calls.,,,,,,,,,,,,,,342,text,API,815
435,model,OpenLLaMA,Berkeley,OpenLlama is an open source reproduction of Meta's LLaMA model.,2023-05-03,https://github.com/openlm-research/open_llama,17B parameters (dense),Evaluated on wide range of tasks using own evaluation benchmarks.,RedPajama,,open,Apache 2.0,,,,,,unknown,unknown,,,,,,,,343,text,text,816
436,model,SaiLY,Deepnight Research,SaiLy is a series/collection of AI Models by Deepnight Research which are highly experimental and uncensored.,2023-11-04,https://huggingface.co/deepnight-research/saily_100b,100B parameters (dense),,,,open,MIT,,,unknown,https://huggingface.co/deepnight-research/saily_100b/discussions,https://huggingface.co/deepnight-research/saily_100b,unknown,unknown,unknown,,,,,,,344,text,text,817
437,application,Poe,Quora,"Poe lets people ask questions, get instant answers, and have back-and-forth conversations with several AI-powered bots. It is initially available on iOS, but we will be adding support for all major platforms in the next few months, along with more bots.",2023-02-03,https://quorablog.quora.com/Poe-1,,,ChatGPT API,,limited,,,,,,,,,,,,https://poe.com/tos,,,,345,nan,nan,818
437,application,Poe,Quora,"Poe lets people ask questions, get instant answers, and have back-and-forth conversations with several AI-powered bots. It is initially available on iOS, but we will be adding support for all major platforms in the next few months, along with more bots.",2023-02-03,https://quorablog.quora.com/Poe-1,,,GPT-4 API,,limited,,,,,,,,,,,,https://poe.com/tos,,,,345,nan,nan,819
437,application,Poe,Quora,"Poe lets people ask questions, get instant answers, and have back-and-forth conversations with several AI-powered bots. It is initially available on iOS, but we will be adding support for all major platforms in the next few months, along with more bots.",2023-02-03,https://quorablog.quora.com/Poe-1,,,Claude API,,limited,,,,,,,,,,,,https://poe.com/tos,,,,345,nan,nan,820
437,application,Poe,Quora,"Poe lets people ask questions, get instant answers, and have back-and-forth conversations with several AI-powered bots. It is initially available on iOS, but we will be adding support for all major platforms in the next few months, along with more bots.",2023-02-03,https://quorablog.quora.com/Poe-1,,,Dragonfly API,,limited,,,,,,,,,,,,https://poe.com/tos,,,,345,nan,nan,821
437,application,Poe,Quora,"Poe lets people ask questions, get instant answers, and have back-and-forth conversations with several AI-powered bots. It is initially available on iOS, but we will be adding support for all major platforms in the next few months, along with more bots.",2023-02-03,https://quorablog.quora.com/Poe-1,,,Sage API,,limited,,,,,,,,,,,,https://poe.com/tos,,,,345,nan,nan,822
438,application,Notion AI,Notion,"Notion AI is a connected assistant that helps you think bigger, work faster, and augments your creativity, right inside the functional workspace you’re already familiar with.",2023-02-22,https://www.notion.so/help/guides/notion-ai-for-docs,,,Anthropic API,,limited,,,,,,,,,,,,,,,,346,nan,nan,823
439,model,Deepseek,Deepseek AI,Deepseek is a 67B parameter model with Grouped-Query Attention trained on 2 trillion tokens from scratch.,2023-11-28,https://github.com/deepseek-ai/DeepSeek-LLM,67B parameters (dense),"Deepseek and baseline models (for comparison) evaluated on a series of representative benchmarks, both in English and Chinese.",,Training dataset comprised of diverse data composition and pruned and deduplicated.,open,custom,,,unknown,https://huggingface.co/deepseek-ai/deepseek-llm-67b-base/discussions,https://huggingface.co/deepseek-ai/deepseek-llm-67b-base,unknown,unknown,unknown,,,,,,,347,text,text,824
440,model,Deepseek Chat,Deepseek AI,Deepseek Chat is a 67B parameter model initialized from Deepseek and fine-tuned on extra instruction data.,2023-11-29,https://github.com/deepseek-ai/DeepSeek-LLM,67B parameters (dense),"Deepseek and baseline models (for comparison) evaluated on a series of representative benchmarks, both in English and Chinese.",Deepseek,Training dataset comprised of diverse data composition and pruned and deduplicated.,open,custom,,,unknown,https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat/discussions,https://huggingface.co/deepseek-ai/deepseek-llm-67b-chat,unknown,unknown,unknown,,,,,,,348,text,text,825
441,model,Deepseek Coder,Deepseek AI,"Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",2023-11-03,https://github.com/deepseek-ai/DeepSeek-Coder,33B parameters (dense),"Evaluated on code generation, code completion, cross-file code completion, and program-based math reasoning across standard benchmarks.",,,open,custom,,,unknkown,https://huggingface.co/deepseek-ai/deepseek-coder-33b-base/discussions,https://huggingface.co/deepseek-ai/deepseek-coder-33b-base,unknown,unknown,8 NVIDIA A100 GPUs and 8 NVIDIA H800 GPUs,,,,,,,349,text,code,826
442,model,Starling,Ollama,Starling is a large language model trained by reinforcement learning from AI feedback focused on improving chatbot helpfulness.,2023-11-02,https://starling.cs.berkeley.edu/,7B parameters (dense),"Mainly evaluated on MT-Bench and AlpacaEval, which are GPT-4-based comparisons.",,,open,CC BY NC 4.0,Academic research and free commercial usage,,,https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha/discussions,https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha,unknown,unknown,unknown,,,,,,,350,text,text,827
443,model,Falcon-40B,UAE Technology Innovation Institute,"Falcon-40B is a 40B parameters causal decoder-only model built by TII and trained on 1,000B tokens of RefinedWeb enhanced with curated corpora.",2023-06-14,https://arxiv.org/pdf/2311.16867.pdf,40B parameters (dense),"Evaluated in 1-shot against the PaLM models, with the tasks of the paper ""Language models are few-shot learners"" (Brown et al., 2020); (2) on a small set of few-shot tasks reported by the GPT-4 paper; (3) against state-of-the-art models across common sense, question answering, and code tasks; (4) against models which also report results from the EAI Harness, for which we are able to compare with identical prompts and metrics.",RefinedWeb,,open,Apache 2.0,Research on large language models; as a foundation for further specialization for specific use cases.,irresponsible or harmful use or production use without adequate assessment of risks and mitigation.,,https://huggingface.co/tiiuae/falcon-40b/discussions,https://huggingface.co/tiiuae/falcon-40b,unknown,2 months,384 A100 40GB GPUs,,,,,,,351,text,text,828
445,model,Falcon-180B,UAE Technology Innovation Institute,"Falcon-180B is a 180B parameters causal decoder-only model built by TII and trained on 3,500B tokens of RefinedWeb enhanced with curated corpora.",2023-09-06,https://arxiv.org/pdf/2311.16867.pdf,180B parameters (dense),"Falcon-180B outperforms LLaMA-2, StableLM, RedPajama, MPT on the Open LLM Leaderboard at https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard.",RefinedWeb,,open,unknown,Research on large language models; as a foundation for further specialization for specific use cases.,Production use without adequate assessment of risks and mitigation; any use cases which may be considered irresponsible or harmful.,,https://huggingface.co/tiiuae/falcon-180b/discussions,https://huggingface.co/tiiuae/falcon-180B,,9 months,4096 A100 40GB GPUs,,,,,,,352,text,text,829
446,application,My AI for Snapchat,Snap,"My AI offers Snapchatters a friendly, customizable chatbot at their fingertips that offers recommendations, and can even write a haiku for friends in seconds. Snapchat, where communication and messaging is a daily behavior, has 750 million monthly Snapchatters.",2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,ChatGPT API,,open,custom,,,,,,,,,,,https://snap.com/terms,,,,353,nan,nan,830
447,application,Brex Chat,Brex,"Brex Inc., a highly valued startup that makes software for finance professionals, is turning to the same artificial intelligence tool behind ChatGPT for a service that can answer questions about corporate budgets, policy and spending.",2023-03-07,https://fortune.com/2023/03/07/cfo-chatbot-chatgpt-ai-brex-finance-software-startup-budgets-policies/,,,ChatGPT API,,limited,custom,,,,,,,,,,,https://www.brex.com/legal/user-terms,,,,354,nan,nan,831
451,model,OpenFlamingo,LAION,"An open-source reproduction of DeepMind's Flamingo model. At its core, OpenFlamingo is a framework that enables training and evaluation of large multimodal models (LMMs).",2023-03-28,https://laion.ai/blog/open-flamingo/,9B parameters (dense),Evaluated on COCO captioning and VQAv2 vision-language tasks.,LLaMA,,open,MIT,academic research purposes,commercial use,,,https://github.com/mlfoundations/open_flamingo/blob/main/MODEL_CARD.md,,,,,,,,,,355,image,text,832
451,model,OpenFlamingo,LAION,"An open-source reproduction of DeepMind's Flamingo model. At its core, OpenFlamingo is a framework that enables training and evaluation of large multimodal models (LMMs).",2023-03-28,https://laion.ai/blog/open-flamingo/,9B parameters (dense),Evaluated on COCO captioning and VQAv2 vision-language tasks.,CLIP,,open,MIT,academic research purposes,commercial use,,,https://github.com/mlfoundations/open_flamingo/blob/main/MODEL_CARD.md,,,,,,,,,,355,image,text,833
451,model,OpenFlamingo,LAION,"An open-source reproduction of DeepMind's Flamingo model. At its core, OpenFlamingo is a framework that enables training and evaluation of large multimodal models (LMMs).",2023-03-28,https://laion.ai/blog/open-flamingo/,9B parameters (dense),Evaluated on COCO captioning and VQAv2 vision-language tasks.,LLaMA,,open,MIT,academic research purposes,commercial use,,,https://github.com/mlfoundations/open_flamingo/blob/main/MODEL_CARD.md,,,,,,,,,,355,text,text,834
451,model,OpenFlamingo,LAION,"An open-source reproduction of DeepMind's Flamingo model. At its core, OpenFlamingo is a framework that enables training and evaluation of large multimodal models (LMMs).",2023-03-28,https://laion.ai/blog/open-flamingo/,9B parameters (dense),Evaluated on COCO captioning and VQAv2 vision-language tasks.,CLIP,,open,MIT,academic research purposes,commercial use,,,https://github.com/mlfoundations/open_flamingo/blob/main/MODEL_CARD.md,,,,,,,,,,355,text,text,835
452,model,SALMONN,"ByteDance, Tsinghua University","SALMONN is a large language model (LLM) enabling speech, audio event, and music inputs.",2023-10-20,https://github.com/bytedance/SALMONN,unknown,"Evaluated on benchmarks pertaining to speech, music, and other audio recognition.",Whisper,,open,Apache 2.0,,,,https://huggingface.co/MSIIP/SALMONN/discussions,https://huggingface.co/MSIIP/SALMONN,unknown,unknown,unknown,,,,,,,356,audio,text,836
452,model,SALMONN,"ByteDance, Tsinghua University","SALMONN is a large language model (LLM) enabling speech, audio event, and music inputs.",2023-10-20,https://github.com/bytedance/SALMONN,unknown,"Evaluated on benchmarks pertaining to speech, music, and other audio recognition.",BEATs,,open,Apache 2.0,,,,https://huggingface.co/MSIIP/SALMONN/discussions,https://huggingface.co/MSIIP/SALMONN,unknown,unknown,unknown,,,,,,,356,audio,text,837
452,model,SALMONN,"ByteDance, Tsinghua University","SALMONN is a large language model (LLM) enabling speech, audio event, and music inputs.",2023-10-20,https://github.com/bytedance/SALMONN,unknown,"Evaluated on benchmarks pertaining to speech, music, and other audio recognition.",Vicuna,,open,Apache 2.0,,,,https://huggingface.co/MSIIP/SALMONN/discussions,https://huggingface.co/MSIIP/SALMONN,unknown,unknown,unknown,,,,,,,356,audio,text,838
452,model,SALMONN,"ByteDance, Tsinghua University","SALMONN is a large language model (LLM) enabling speech, audio event, and music inputs.",2023-10-20,https://github.com/bytedance/SALMONN,unknown,"Evaluated on benchmarks pertaining to speech, music, and other audio recognition.",Whisper,,open,Apache 2.0,,,,https://huggingface.co/MSIIP/SALMONN/discussions,https://huggingface.co/MSIIP/SALMONN,unknown,unknown,unknown,,,,,,,356,text,text,839
452,model,SALMONN,"ByteDance, Tsinghua University","SALMONN is a large language model (LLM) enabling speech, audio event, and music inputs.",2023-10-20,https://github.com/bytedance/SALMONN,unknown,"Evaluated on benchmarks pertaining to speech, music, and other audio recognition.",BEATs,,open,Apache 2.0,,,,https://huggingface.co/MSIIP/SALMONN/discussions,https://huggingface.co/MSIIP/SALMONN,unknown,unknown,unknown,,,,,,,356,text,text,840
452,model,SALMONN,"ByteDance, Tsinghua University","SALMONN is a large language model (LLM) enabling speech, audio event, and music inputs.",2023-10-20,https://github.com/bytedance/SALMONN,unknown,"Evaluated on benchmarks pertaining to speech, music, and other audio recognition.",Vicuna,,open,Apache 2.0,,,,https://huggingface.co/MSIIP/SALMONN/discussions,https://huggingface.co/MSIIP/SALMONN,unknown,unknown,unknown,,,,,,,356,text,text,841
453,model,SDXL-Lightning,ByteDance,"SDXL-Lightning is a lightning-fast text-to-image generation model. It can generate high-quality 1024px images in a few steps. The models are distilled from stabilityai/stable-diffusion-xl-base-1.0. This repository contains checkpoints for 1-step, 2-step, 4-step, and 8-step distilled models.",2024-02-21,https://arxiv.org/pdf/2402.13929.pdf,unknown,Evaluated via qualitative comparison relative to other SoTA image generation models.,Stable Diffusion XL,unknown,open,OpenRail++,"The model can be used for fast, high-quality text-to-image generation. It supports 1-step, 2-step, 4-step, and 8-step distilled models which provide varying generation quality.",unknown,unknown,https://huggingface.co/ByteDance/SDXL-Lightning/discussions,https://huggingface.co/ByteDance/SDXL-Lightning,unknown,unknown,64 A100 80G GPUs,,,,,,,357,text,image,842
454,model,VLMo,Microsoft,VLMo is a model for text-to-image generation,2021-11-03,https://arxiv.org/abs/2111.02358,562M parameters (dense),,Conceptual Captions,,closed,,,,,,,,,,,,,,,,358,text,image,843
454,model,VLMo,Microsoft,VLMo is a model for text-to-image generation,2021-11-03,https://arxiv.org/abs/2111.02358,562M parameters (dense),,SBU Captions,,closed,,,,,,,,,,,,,,,,358,text,image,844
454,model,VLMo,Microsoft,VLMo is a model for text-to-image generation,2021-11-03,https://arxiv.org/abs/2111.02358,562M parameters (dense),,COCO,,closed,,,,,,,,,,,,,,,,358,text,image,845
454,model,VLMo,Microsoft,VLMo is a model for text-to-image generation,2021-11-03,https://arxiv.org/abs/2111.02358,562M parameters (dense),,Visual Genome,,closed,,,,,,,,,,,,,,,,358,text,image,846
454,model,VLMo,Microsoft,VLMo is a model for text-to-image generation,2021-11-03,https://arxiv.org/abs/2111.02358,562M parameters (dense),,Wikipedia,,closed,,,,,,,,,,,,,,,,358,text,image,847
454,model,VLMo,Microsoft,VLMo is a model for text-to-image generation,2021-11-03,https://arxiv.org/abs/2111.02358,562M parameters (dense),,BooksCorpus,,closed,,,,,,,,,,,,,,,,358,text,image,848
455,model,T-ULRv5,Microsoft,T-ULRv5 is a language model trained with two unique training objectives,2022-09-28,https://www.microsoft.com/en-us/research/blog/microsoft-turing-universal-language-representation-model-t-ulrv5-tops-xtreme-leaderboard-and-trains-100x-faster/,2.2B parameters (dense),,,,limited,unknown,,,,,,,Less than two weeks,256 A100,,,,,,,359,text,text,849
456,model,Turing NLR-v5,Microsoft,,2021-12-02,https://www.microsoft.com/en-us/research/blog/efficiently-and-effectively-scaling-up-language-model-pretraining-for-best-language-representation-model-on-glue-and-superglue/?OCID=msr_blog_TNLRV5_tw,5B parameters (dense),,,,limited,unknown,,,,,,,,,,,,,,,360,text,text,850
457,model,Megatron-Turing NLG,"Microsoft, NVIDIA","Megatron-Turing NLG is a 530B parameter autoregressive language model.
",2022-01-28,https://arxiv.org/abs/2201.11990,530B parameters (dense),,The Pile,,limited,unknown,,,,,,,,4480 A100s (560 x 8),,,,,,,361,text,text,851
458,model,VALL-E,Microsoft,Vall-E is a neural code model for text-to-speech synthesis,2023-01-05,https://valle-demo.github.io/,unknown,,,,closed,unknown,,,,,,,,16 V100 32GB GPUs,,,,,,,362,text,audio,852
459,application,GitHub CoPilot,Microsoft,"GitHub CoPilot is a coding pair programmer assisting programmers as they write code.
",2021-06-29,https://copilot.github.com/,,,Codex,"GitHub is working on a filter to detect and suppress code generations that are verbatim from the training set [[GitHub Research Recitation]] (https://docs.github.com/en/github/copilot/research-recitation). According to the FAQ, GitHub implemented a simple filter that blocks emails in standard formats to protect personally identifiable data that may be present in the training data [[GitHub CoPilot]](https://copilot.github.com/).
",limited,unknown,"GitHub CoPilot is intended to be used as a coding assistant.
","Access to GPT-3 is governed by GitHub Acceptable Use Policies and Terms of Service, both of which list a set of prohibited uses [[Use Policies]] (https://docs.github.com/en/site-policy/acceptable-use-policies/github-acceptable-use-policies) [[Terms of Service]] (https://docs.github.com/en/site-policy/github-terms/github-terms-of-service).
","value: unknown explanation: >
  There may be internal monitoring mechanisms unknown to the public.
","Feedback can be provided in the CoPilot feedback project [[CoPilot feedback]] (https://github.com/github/feedback/discussions/categories/copilot-feedback).
",,,,,unknown,Code completions,"https://docs.github.com/en/site-policy/github-terms/github-terms-of-service
","GitHub Copilot reportedly has over 1 million sign-ups [[Tweet Source]](https://twitter.com/sama/status/1539737789310259200?s=21&t=YPaYd0ZueJzrR6rLslUqzg).
",unknown,unknown,363,nan,nan,853
460,model,BioGPT,Microsoft,,2022-09-24,https://academic.oup.com/bib/article/23/6/bbac409/6713511?guestAccessKey=a66d9b5d-4f83-4017-bb52-405815c907b9&login=true,1.5B parameters (dense),,PubMed,,open,MIT,,,,,,,,,,,,,,,364,text,text,854
461,application,Bing Search,Microsoft,"AI-powered Bing search engine and Edge browser, available in preview now at Bing.com, to deliver better search, more complete answers, a new chat experience and the ability to generate content. We think of these tools as an AI copilot for the web.",2023-02-07,https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/,,,ChatGPT API,,limited,custom,Search engine,,,"Feedback can be submitted at [bing.com](bing.com).
",,,,,unknown,Search results,https://www.microsoft.com/legal/terms-of-use,,,,365,nan,nan,855
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,The Pile,,closed,MIT,,,,,,,,,,,,,,,366,image,image,856
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,CommonCrawl,,closed,MIT,,,,,,,,,,,,,,,366,image,image,857
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-2B-en,,closed,MIT,,,,,,,,,,,,,,,366,image,image,858
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-400M,,closed,MIT,,,,,,,,,,,,,,,366,image,image,859
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,COYO-700M,,closed,MIT,,,,,,,,,,,,,,,366,image,image,860
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,Conceptual Captions,,closed,MIT,,,,,,,,,,,,,,,366,image,image,861
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,The Pile,,closed,MIT,,,,,,,,,,,,,,,366,image,text,862
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,CommonCrawl,,closed,MIT,,,,,,,,,,,,,,,366,image,text,863
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-2B-en,,closed,MIT,,,,,,,,,,,,,,,366,image,text,864
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-400M,,closed,MIT,,,,,,,,,,,,,,,366,image,text,865
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,COYO-700M,,closed,MIT,,,,,,,,,,,,,,,366,image,text,866
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,Conceptual Captions,,closed,MIT,,,,,,,,,,,,,,,366,image,text,867
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,The Pile,,closed,MIT,,,,,,,,,,,,,,,366,text,image,868
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,CommonCrawl,,closed,MIT,,,,,,,,,,,,,,,366,text,image,869
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-2B-en,,closed,MIT,,,,,,,,,,,,,,,366,text,image,870
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-400M,,closed,MIT,,,,,,,,,,,,,,,366,text,image,871
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,COYO-700M,,closed,MIT,,,,,,,,,,,,,,,366,text,image,872
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,Conceptual Captions,,closed,MIT,,,,,,,,,,,,,,,366,text,image,873
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,The Pile,,closed,MIT,,,,,,,,,,,,,,,366,text,text,874
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,CommonCrawl,,closed,MIT,,,,,,,,,,,,,,,366,text,text,875
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-2B-en,,closed,MIT,,,,,,,,,,,,,,,366,text,text,876
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,LAION-400M,,closed,MIT,,,,,,,,,,,,,,,366,text,text,877
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,COYO-700M,,closed,MIT,,,,,,,,,,,,,,,366,text,text,878
462,model,KOSMOS-1,Microsoft,"KOSMOS-1 is a multimodal language model that is capable of perceiving multimodal input, following instructions, and performing in-context learning for not only language tasks but also multimodal tasks.",2023-03-01,https://arxiv.org/pdf/2302.14045.pdf,1.6B parameters (dense),,Conceptual Captions,,closed,MIT,,,,,,,,,,,,,,,366,text,text,879
463,model,Prometheus,Microsoft,"In the context of Bing, we have developed a proprietary way of working with the OpenAI model that allows us to best leverage its power. We call this collection of capabilities and techniques the Prometheus model. This combination gives you more relevant, timely and targeted results, with improved safety.",2023-02-07,https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/,unknown,,,,closed,unknown,,,,,,,,,,,,,,,367,unknown,unknown,880
464,model,Florence,Microsoft,,2022-11-23,https://arxiv.org/abs/2111.11432,900M parameters (dense),,FLD-900M,,closed,unknown,,,,,,,,,,,,,,,368,text,image,881
466,application,Azure Cognitive Services for Vision,Microsoft,"Cost-effective, production-ready computer vision services in Azure Cognitive Service for Vision. The improved Vision Services enables developers to create cutting-edge, market-ready, responsible computer vision applications across various industries.",2023-03-07,https://azure.microsoft.com/en-us/blog/announcing-a-renaissance-in-computer-vision-ai-with-microsofts-florence-foundation-model/?utm_content=buffer16fa0&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer,,,Florence,,limited,custom,,,,,,,,,,,https://azure.microsoft.com/en-us/support/legal/,,,,369,nan,nan,882
467,model,VisualChatGPT,Microsoft,,2023-03-08,https://arxiv.org/pdf/2303.04671.pdf,unknown,,OpenAI API,,closed,,,,,,,,,,,,,,,,370,text,image,883
467,model,VisualChatGPT,Microsoft,,2023-03-08,https://arxiv.org/pdf/2303.04671.pdf,unknown,,OpenAI API,,closed,,,,,,,,,,,,,,,,370,text,text,884
468,application,Microsoft 365 Copilot,Microsoft,It combines the power of language models with your data in the Microsoft Graph and the Microsoft 365 apps to turn your words into the most powerful productivity tool on the planet.,2023-03-16,https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/,,,GPT-4 API,,limited,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,371,nan,nan,885
469,application,Microsoft Business Chat,Microsoft,"Business Chat works across the langugae model, the Microsoft 365 apps, and your data — your calendar, emails, chats, documents, meetings and contacts — to do things you’ve never been able to do before. You can give it natural language prompts like “Tell my team how we updated the product strategy,” and it will generate a status update based on the morning’s meetings, emails and chat threads.",2023-03-16,https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/,,,Microsoft 365 Copilot,,limited,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,372,nan,nan,886
470,application,Microsoft Excel,Microsoft,"Microsoft Excel is the industry leading spreadsheet software program, a powerful data visualization and analysis tool.",,https://www.microsoft.com/en-us/microsoft-365/excel,,,Microsoft 365 Copilot,,open,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,373,nan,nan,887
471,application,Microsoft Outlook,Microsoft,"Microsoft Outlook is a personal information manager software system from Microsoft, available as a part of the Microsoft Office and Microsoft 365 software suites.",,https://www.microsoft.com/en-us/microsoft-365/outlook/email-and-calendar-software-microsoft-outlook,,,Microsoft 365 Copilot,,open,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,374,nan,nan,888
472,application,Microsoft Power Platform,Microsoft,"Microsoft Power Platform is a line of business intelligence, app development, and app connectivity software applications.",,https://powerplatform.microsoft.com/en-us/,,,Microsoft 365 Copilot,,limited,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,375,nan,nan,889
473,application,Microsoft PowerPoint,Microsoft,Microsoft PowerPoint empowers you to create clean slideshow presentations and intricate pitch decks and gives you a powerful presentation maker.,,https://www.microsoft.com/en-us/microsoft-365/powerpoint,,,Microsoft 365 Copilot,,open,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,376,nan,nan,890
474,application,Microsoft Teams,Microsoft,"Microsoft Teams is a proprietary business communication platform developed by Microsoft, as part of the Microsoft 365 family of products.",,https://www.microsoft.com/en-us/microsoft-teams/group-chat-software,,,Microsoft 365 Copilot,,open,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,377,nan,nan,891
474,application,Microsoft Teams,Microsoft,"Microsoft Teams is a proprietary business communication platform developed by Microsoft, as part of the Microsoft 365 family of products.",,https://www.microsoft.com/en-us/microsoft-teams/group-chat-software,,,Microsoft Business Chat,,open,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,377,nan,nan,892
475,application,Microsoft Word,Microsoft,Microsoft Word is a word processing software developed by Microsoft,,https://www.microsoft.com/en-us/microsoft-365/word,,,Microsoft 365 Copilot,,open,custom,,,,,,,,,,,https://www.microsoft.com/legal/terms-of-use,,,,378,nan,nan,893
476,application,Microsoft Inside Look,Microsoft,"Inside look is a Microsoft Office feature, composing document insights highlighting key points, expected time to read, and popularity among others.
",,https://support.microsoft.com/en-us/office/see-file-insights-before-you-open-a-file-87a23bbc-a516-42e2-a7b6-0ecb8259e026,,,,unknown,limited,custom,Providing document insights to users.,unknown,unknown,unknown,,,,,unknown,Document level insights for users.,https://www.microsoft.com/legal/terms-of-use,unknown,unknown,unknown,379,nan,nan,894
477,application,Microsoft Suggested Replies,Microsoft,"Suggested replies is a Microsoft Outlook feature that suggests responses to emails, available in: English, Spanish, Italian, French, German, Portuguese Chinese Simplified, Chinese Traditional, Swedish, Russian, Korean, Czech, Hungarian, Arabic, Hebrew, Thai, Turkish, Japanese, Dutch, Norwegian, Danish, and Polish.
",,https://support.microsoft.com/en-us/office/use-suggested-replies-in-outlook-19316194-0434-43ba-a742-6b5890157379,,,,unknown,limited,custom,Suggesting email replies.,unknown,unknown,unknown,,,,,unknown,Suggested emails.,https://www.microsoft.com/legal/terms-of-use,unknown,unknown,unknown,380,nan,nan,895
478,application,Microsoft Security Copilot,Microsoft,"Microsoft Security Copilot is an AI-powered security analysis tool that enables analysts to respond to threats quickly, process signals at machine speed, and assess risk exposure in minutes.
",2023-03-28,https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/,,,GPT-4,"Security Copilot employs a closed-loop learning system that learns from user interactions and feedback, enabling it to provide more coherent, relevant, and useful answers that continually improve over time. Security Copilot is committed to delivering safe, secure, and responsible AI solutions, ensuring that customers' data and AI models are protected with enterprise compliance and security controls. Customer data is owned and controlled by them, and not used to train AI models for anyone outside their organization.",limited,custom,"Security Copilot is designed to enhance the capabilities of cybersecurity professionals. It leverages machine speed and scale to accelerate response to security incidents, discover and process threat signals, and assess risk exposure within minutes.",unknown,,unknown,,,,,Security Copilot combines OpenAI's GPT-4 generative AI with a security-specific model from Microsoft. This security-specific model in turn incorporates a growing set of security-specific skills and is informed by Microsoft's unique global threat intelligence and more than 65 trillion daily signals.,"Actionable responses to security-related questions (text and image). Security event, incident or threat reports (PowerPoint slide).",https://www.microsoft.com/legal/terms-of-use,unknown,unknown,unknown,381,nan,nan,896
478,application,Microsoft Security Copilot,Microsoft,"Microsoft Security Copilot is an AI-powered security analysis tool that enables analysts to respond to threats quickly, process signals at machine speed, and assess risk exposure in minutes.
",2023-03-28,https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/,,,Microsoft security-specific model,"Security Copilot employs a closed-loop learning system that learns from user interactions and feedback, enabling it to provide more coherent, relevant, and useful answers that continually improve over time. Security Copilot is committed to delivering safe, secure, and responsible AI solutions, ensuring that customers' data and AI models are protected with enterprise compliance and security controls. Customer data is owned and controlled by them, and not used to train AI models for anyone outside their organization.",limited,custom,"Security Copilot is designed to enhance the capabilities of cybersecurity professionals. It leverages machine speed and scale to accelerate response to security incidents, discover and process threat signals, and assess risk exposure within minutes.",unknown,,unknown,,,,,Security Copilot combines OpenAI's GPT-4 generative AI with a security-specific model from Microsoft. This security-specific model in turn incorporates a growing set of security-specific skills and is informed by Microsoft's unique global threat intelligence and more than 65 trillion daily signals.,"Actionable responses to security-related questions (text and image). Security event, incident or threat reports (PowerPoint slide).",https://www.microsoft.com/legal/terms-of-use,unknown,unknown,unknown,381,nan,nan,897
479,model,UniLM,Microsoft,UniLM is a unified language model that can be fine-tuned for both natural language understanding and generation tasks.,2019-10-01,https://proceedings.neurips.cc/paper_files/paper/2019/file/c20bb2d9a50d5ac1f713f8b34d9aac5a-Paper.pdf,340M parameters (dense),"Evaluated on GLUE, SQuAD 2.0, and CoQA benchmarks.",,,open,MIT,,,,,,unknown,"10,000 steps in 7 hours",8 NVIDIA Tesla V100 32GB GPUs,,,,,,,382,text,text,898
480,model,Docugami,Microsoft,Docugami is a LLM focused on writing business documents and data using generative AI.,2021-04-12,https://www.docugami.com/generative-ai,20B parameters (dense),,,,limited,,"analyzing, writing, and connecting business documents and data",,,,,unknown,unknown,,,,,,,,383,text,text,899
481,model,BEiT-3,Microsoft,BEiT-3 is a general-purpose multimodal foundation model for vision and vision-language tasks.,2022-08-31,https://arxiv.org/pdf/2208.10442.pdf,1.9B parameters (dense),"Evaluated on a range of standardized vision benchmarks, and achieves state of the art performance on all experimentally.",Multiway Transformer network,,open,,,,,,,unknown,,,,,,,,,384,image,image,900
481,model,BEiT-3,Microsoft,BEiT-3 is a general-purpose multimodal foundation model for vision and vision-language tasks.,2022-08-31,https://arxiv.org/pdf/2208.10442.pdf,1.9B parameters (dense),"Evaluated on a range of standardized vision benchmarks, and achieves state of the art performance on all experimentally.",Multiway Transformer network,,open,,,,,,,unknown,,,,,,,,,384,image,text,901
481,model,BEiT-3,Microsoft,BEiT-3 is a general-purpose multimodal foundation model for vision and vision-language tasks.,2022-08-31,https://arxiv.org/pdf/2208.10442.pdf,1.9B parameters (dense),"Evaluated on a range of standardized vision benchmarks, and achieves state of the art performance on all experimentally.",Multiway Transformer network,,open,,,,,,,unknown,,,,,,,,,384,text,image,902
481,model,BEiT-3,Microsoft,BEiT-3 is a general-purpose multimodal foundation model for vision and vision-language tasks.,2022-08-31,https://arxiv.org/pdf/2208.10442.pdf,1.9B parameters (dense),"Evaluated on a range of standardized vision benchmarks, and achieves state of the art performance on all experimentally.",Multiway Transformer network,,open,,,,,,,unknown,,,,,,,,,384,text,text,903
482,model,WizardLM,Microsoft,"Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM.",2023-04-24,https://arxiv.org/pdf/2304.12244v1.pdf,7B parameters (dense),Reports results on standard LLM benchmarks in comparison to other LLMs and test sets.,LLaMA,,open,Apache 2.0,"Creating large amounts of instruction data, particularly with high complexity",,,https://huggingface.co/datasets/WizardLM/evol_instruct_70k/discussions,https://huggingface.co/WizardLM/WizardLM-13B-1.0,,70 hours on 3 epochs,8 V100 GPUs,,,,,,,385,text,text,904
482,model,WizardLM,Microsoft,"Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM.",2023-04-24,https://arxiv.org/pdf/2304.12244v1.pdf,7B parameters (dense),Reports results on standard LLM benchmarks in comparison to other LLMs and test sets.,Evol-Instruct,,open,Apache 2.0,"Creating large amounts of instruction data, particularly with high complexity",,,https://huggingface.co/datasets/WizardLM/evol_instruct_70k/discussions,https://huggingface.co/WizardLM/WizardLM-13B-1.0,,70 hours on 3 epochs,8 V100 GPUs,,,,,,,385,text,text,905
482,model,WizardLM,Microsoft,"Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM.",2023-04-24,https://arxiv.org/pdf/2304.12244v1.pdf,7B parameters (dense),Reports results on standard LLM benchmarks in comparison to other LLMs and test sets.,Alpaca dataset,,open,Apache 2.0,"Creating large amounts of instruction data, particularly with high complexity",,,https://huggingface.co/datasets/WizardLM/evol_instruct_70k/discussions,https://huggingface.co/WizardLM/WizardLM-13B-1.0,,70 hours on 3 epochs,8 V100 GPUs,,,,,,,385,text,text,906
483,model,WizardCoder,Microsoft,"WizardCoder empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",2023-08-26,https://arxiv.org/pdf/2306.08568.pdf,34B parameters (dense),"Evaluated on four prominent code generation benchmarks HumanEval, HumanEval+, MBPP, and DS100.",Evol-Instruct,,open,BigCode Open Rail-M,,,,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0/discussions,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0,,,,,,,,,,386,text,text,907
483,model,WizardCoder,Microsoft,"WizardCoder empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",2023-08-26,https://arxiv.org/pdf/2306.08568.pdf,34B parameters (dense),"Evaluated on four prominent code generation benchmarks HumanEval, HumanEval+, MBPP, and DS100.",Alpaca dataset,,open,BigCode Open Rail-M,,,,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0/discussions,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0,,,,,,,,,,386,text,text,908
483,model,WizardCoder,Microsoft,"WizardCoder empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",2023-08-26,https://arxiv.org/pdf/2306.08568.pdf,34B parameters (dense),"Evaluated on four prominent code generation benchmarks HumanEval, HumanEval+, MBPP, and DS100.",StarCoder,,open,BigCode Open Rail-M,,,,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0/discussions,https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0,,,,,,,,,,386,text,text,909
484,model,Florence-2,Microsoft,"WizardCoder empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",2023-11-10,https://arxiv.org/pdf/2311.06242.pdf,771M parameters (dense),Evaluated on standard image processing benchmarks,FLD-5B,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,387,image,text,910
484,model,Florence-2,Microsoft,"WizardCoder empowers Code LLMs with complex instruction fine-tuning, by adapting the Evol-Instruct method to the domain of code.",2023-11-10,https://arxiv.org/pdf/2311.06242.pdf,771M parameters (dense),Evaluated on standard image processing benchmarks,FLD-5B,,closed,unknown,,,,,,unknown,unknown,unknown,,,,,,,387,text,text,911
487,model,LlongOrca,Microsoft,LlongOrca is an attempt to make OpenOrca able to function in a Llong context.,2023-08-01,https://huggingface.co/Open-Orca/LlongOrca-7B-16k,7B parameters (dense),LlongOrca evaluated on BigBench-Hard and AGIEval results.,OpenOrca,,open,LLaMA 2,training and evaluation in the field of natural language processing.,,,https://huggingface.co/Open-Orca/LlongOrca-7B-16k/discussions,https://huggingface.co/Open-Orca/LlongOrca-7B-16k,unknown,37 hours,8x A6000-48GB (first-gen) GPUs,,,,,,,388,text,text,912
487,model,LlongOrca,Microsoft,LlongOrca is an attempt to make OpenOrca able to function in a Llong context.,2023-08-01,https://huggingface.co/Open-Orca/LlongOrca-7B-16k,7B parameters (dense),LlongOrca evaluated on BigBench-Hard and AGIEval results.,LLongMA-2,,open,LLaMA 2,training and evaluation in the field of natural language processing.,,,https://huggingface.co/Open-Orca/LlongOrca-7B-16k/discussions,https://huggingface.co/Open-Orca/LlongOrca-7B-16k,unknown,37 hours,8x A6000-48GB (first-gen) GPUs,,,,,,,388,text,text,913
488,model,Phi-1.5,Microsoft,Phi-1.5 is a large language transformer model.,2023-09-11,https://arxiv.org/pdf/2309.05463.pdf,1.3B parameters (dense),"Evaluated on common sense reasoning, language understanding, and multi-step reasoning compared to other SOTA language models.",phi-1,generic web-crawl data is removed from dataset.,open,MIT,"Phi-1.5 is best suited for answering prompts using the QA format, the chat format, and the code format.",,,https://huggingface.co/microsoft/phi-1_5/discussions,https://huggingface.co/microsoft/phi-1_5,unknown,8 days,32 A100-40G GPUs,,,,,,,389,text,text,914
489,model,Orca 2,Microsoft,Orca 2 is a finetuned version of LLAMA-2 for research purposes.,2023-11-21,https://arxiv.org/pdf/2311.11045.pdf,13B parameters (dense),Orca 2 has been evaluated on a large number of tasks ranging from reasoning to grounding and safety.,LLaMA 2,,open,custom,Orca 2 is built for research purposes only. The main purpose is to allow the research community to assess its abilities and to provide a foundation for building better frontier models.,Any purposes other than research.,unknown,https://huggingface.co/microsoft/Orca-2-13b/discussions,https://huggingface.co/microsoft/Orca-2-13b,unknown,80 hours,32 NVIDIA A100 80GB GPUs,,,,,,,390,text,text,915
490,model,Phi-3 Mini,Microsoft,"Phi-3 Mini is a 3.8 billion-parameter, lightweight, state-of-the-art open model trained using the Phi-3 datasets.",2024-04-23,https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/,3.8B parameters,"The model has been evaluated against benchmarks that test common sense, language understanding, mathematics, coding, long-term context, and logical reasoning. The Phi-3 Mini-128K-Instruct demonstrated robust and state-of-the-art performance among models with fewer than 13 billion parameters.",,The model underwent post-training processes viz. supervised fine-tuning and direct preference optimization to increase its capability in following instructions and aligning to safety measures.,open,MIT,The model's primary use cases are for commercial and research purposes that require capable reasoning in memory or compute constrained environments and latency-bound scenarios. It can also serve as a building block for generative AI-powered features.,"The model should not be used for high-risk scenarios without adequate evaluation and mitigation techniques for accuracy, safety, and fairness.","Issues like allocation, high-risk scenarios, misinformation, generation of harmful content and misuse should be monitored and addressed.",https://huggingface.co/microsoft/Phi-3-mini-128k-instruct/discussions,https://huggingface.co/microsoft/Phi-3-mini-128k-instruct,unknown,7 days,512 H100-80G GPUs,,,,,,,391,text,text,916
491,model,TigerBot,TigerResearch,TigerBot is an open source multilingual multitask LLM.,2023-10-19,https://arxiv.org/pdf/2312.08688.pdf,180B parameters (dense),Evaluated across a range of domain tasks across standard benchmarks in comparison to predecessor Llama 2.,Llama 2,Safety filtering performed to mitigate risk and remove toxic content.,open,Apache 2.0,,,unknown,https://huggingface.co/TigerResearch/tigerbot-180b-base-v2/discussions,https://huggingface.co/TigerResearch/tigerbot-180b-base-v2,unknown,unknown,32 A100-40G GPUs,,,,,,,392,text,text,917
491,model,TigerBot,TigerResearch,TigerBot is an open source multilingual multitask LLM.,2023-10-19,https://arxiv.org/pdf/2312.08688.pdf,180B parameters (dense),Evaluated across a range of domain tasks across standard benchmarks in comparison to predecessor Llama 2.,BLOOM,Safety filtering performed to mitigate risk and remove toxic content.,open,Apache 2.0,,,unknown,https://huggingface.co/TigerResearch/tigerbot-180b-base-v2/discussions,https://huggingface.co/TigerResearch/tigerbot-180b-base-v2,unknown,unknown,32 A100-40G GPUs,,,,,,,392,text,text,918
493,model,Cohere Base,Cohere,"The Generations model is a language model trained by Cohere for generation tasks.
",2021-11-15,,unknown,"The model's performance was analyzed on Hellaswag and COPA, as well as several safety benchmarks [[Model Card]](https://docs.cohere.ai/generation-card).",coheretext,unknown,limited,unknown,"On the model card, the intended uses are stated as ""interactive autocomplete, augmenting human writing processes, summarization, text rephrasing, and other text-to-text tasks in non-sensitive domains"" [[Model Card]](https://docs.cohere.ai/generation-card).
","The usage of the model is bound by the Cohere usage guidelines [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines). A non-comprehensive list of specific application violating these guidelines are: astroturfing, generation of misinformation and other harmful content, and ""generation of text about people, places, or events without a human-in-the-loop"" [[Model Card]](https://docs.cohere.ai/generation-card).
","The usage of the model is monitored by Cohere [[Model Card]](https://docs.cohere.ai/generation-card).
",unknown,https://docs.cohere.ai/generation-card,unknown,unknown,unknown,,,,,,,393,text,text,919
494,model,Cohere Command,Cohere,"This model is a generative model optimized to follow commands in the prompt.
",2023-01-01,https://docs.cohere.com/docs/command-beta,unknown,"The model's performance was analyzed on Hellaswag and COPA, as well as several safety benchmarks [[Model Card]](https://docs.cohere.ai/generation-card).",Cohere Base,unknown,limited,unknown,"On the model card, the intended uses are stated as ""interactive autocomplete, augmenting human writing processes, summarization, text rephrasing, and other text-to-text tasks in non-sensitive domains"" [[Model Card]](https://docs.cohere.ai/generation-card).
","The usage of the model is bound by the Cohere usage guidelines [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines). A non-comprehensive list of specific application violating these guidelines are: astroturfing, generation of misinformation and other harmful content, and ""generation of text about people, places, or events without a human-in-the-loop"" [[Model Card]](https://docs.cohere.ai/generation-card).
","The usage of the model is monitored by Cohere [[Model Card]](https://docs.cohere.ai/generation-card).
",unknown,https://docs.cohere.ai/generation-card,unknown,unknown,unknown,,,,,,,394,text,text,920
495,model,Cohere Embed (English),Cohere,"The Embedding Large (English) model is a language model trained by Cohere for tasks requiring embeddings.
",2021-11-15,,unknown,"The model's performance was analyzed on several safety benchmarks [[Model Card]](https://docs.cohere.ai/representation-card).
",,unknown,limited,unknown,"The intended uses are stated as ""estimating semantic similarity between two sentences, choosing a sentence which is most likely to follow another sentence, sentiment analysis, topic extraction, or categorizing user feedback"" on the Cohere model card [[Model Card]](https://docs.cohere.ai/representation-card).
","The usage of the model is bound by the Cohere usage guidelines [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines). A non-comprehensive list of specific application violating these guidelines are: extraction of identity and demographic information, building purposefully opaque text classification systems, and ""building downstream classifiers that serve as automated decision-making systems that have real-world consequences on people, where those decisions are made without a human-in-the-loop"" [[Model Card]](https://docs.cohere.ai/representation-card).
","The usage of the model is monitored by Cohere [[Model Card]](https://docs.cohere.ai/representation-card).
",unknown,https://docs.cohere.ai/representation-card,unknown,unknown,unknown,,,,,,,395,text,text,921
496,model,Cohere Embed (Multilingual),Cohere,"This model maps text from 100+ languages to a semantic vector space, positioning text with a similar meaning (regardless of language) in close proximity.
",2022-12-12,https://txt.cohere.ai/multilingual/,unknown,"The model's performance was analyzed on several safety benchmarks [[Model Card]](https://docs.cohere.ai/representation-card).
",,unknown,limited,unknown,"The intended uses are stated as ""estimating semantic similarity between two sentences, choosing a sentence which is most likely to follow another sentence, sentiment analysis, topic extraction, or categorizing user feedback"" on the Cohere model card [[Model Card]](https://docs.cohere.ai/representation-card).
","The usage of the model is bound by the Cohere usage guidelines [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines). A non-comprehensive list of specific application violating these guidelines are: extraction of identity and demographic information, building purposefully opaque text classification systems, and ""building downstream classifiers that serve as automated decision-making systems that have real-world consequences on people, where those decisions are made without a human-in-the-loop"" [[Model Card]](https://docs.cohere.ai/representation-card).
","The usage of the model is monitored by Cohere [[Model Card]](https://docs.cohere.ai/representation-card).
",unknown,https://docs.cohere.ai/representation-card,unknown,unknown,unknown,,,,,,,396,text,text,922
497,application,Cohere API,Cohere,"Cohere API allows users to access the cohere language models and utilize them in their applications.
",2021-11-15,https://cohere.ai/,,,Cohere Generate Endpoint,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,custom,"Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation and embeddings,https://cohere.ai/terms-of-use,unknown,unknown,unknown,397,nan,nan,923
497,application,Cohere API,Cohere,"Cohere API allows users to access the cohere language models and utilize them in their applications.
",2021-11-15,https://cohere.ai/,,,Cohere Embed Endpoint,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,custom,"Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation and embeddings,https://cohere.ai/terms-of-use,unknown,unknown,unknown,397,nan,nan,924
497,application,Cohere API,Cohere,"Cohere API allows users to access the cohere language models and utilize them in their applications.
",2021-11-15,https://cohere.ai/,,,Cohere Classify Endpoint,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,custom,"Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation and embeddings,https://cohere.ai/terms-of-use,unknown,unknown,unknown,397,nan,nan,925
497,application,Cohere API,Cohere,"Cohere API allows users to access the cohere language models and utilize them in their applications.
",2021-11-15,https://cohere.ai/,,,Cohere Summarize Endpoint,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,custom,"Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation and embeddings,https://cohere.ai/terms-of-use,unknown,unknown,unknown,397,nan,nan,926
498,application,Cohere Generate Endpoint,Cohere,"This endpoint generates realistic text conditioned on a given input.
",2021-11-15,https://docs.cohere.ai/reference/generate,,,Cohere Base,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation,https://cohere.ai/terms-of-use,unknown,unknown,unknown,398,nan,nan,927
498,application,Cohere Generate Endpoint,Cohere,"This endpoint generates realistic text conditioned on a given input.
",2021-11-15,https://docs.cohere.ai/reference/generate,,,Cohere Command,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation,https://cohere.ai/terms-of-use,unknown,unknown,unknown,398,nan,nan,928
499,application,Cohere Embed Endpoint,Cohere,"This endpoint returns text embeddings. An embedding is a list of floating point numbers that captures semantic information about the text that it represents.
",2021-11-15,https://docs.cohere.ai/reference/embed,,,Cohere Embed (Multilingual),"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,embedding,https://cohere.ai/terms-of-use,unknown,unknown,unknown,399,nan,nan,929
499,application,Cohere Embed Endpoint,Cohere,"This endpoint returns text embeddings. An embedding is a list of floating point numbers that captures semantic information about the text that it represents.
",2021-11-15,https://docs.cohere.ai/reference/embed,,,Cohere Embed (English),"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,embedding,https://cohere.ai/terms-of-use,unknown,unknown,unknown,399,nan,nan,930
500,application,Cohere Classify Endpoint,Cohere,"This endpoint makes a prediction about which label best fits a specified text input. To make a prediction, Classify uses the provided examples of text + label pairs as a reference.
",2022-05-05,https://docs.cohere.ai/reference/classify,,,Cohere Embed (Multilingual),"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,embedding,https://cohere.ai/terms-of-use,unknown,unknown,unknown,400,nan,nan,931
500,application,Cohere Classify Endpoint,Cohere,"This endpoint makes a prediction about which label best fits a specified text input. To make a prediction, Classify uses the provided examples of text + label pairs as a reference.
",2022-05-05,https://docs.cohere.ai/reference/classify,,,Cohere Embed (English),"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,embedding,https://cohere.ai/terms-of-use,unknown,unknown,unknown,400,nan,nan,932
501,application,Cohere Summarize Endpoint,Cohere,"This endpoint generates a succinct version of the original text that relays the most important information.
",2023-02-22,https://docs.cohere.ai/reference/summarize,,,,"The new users of the API get a limited access restricting the sizes of the models as well as the number of tokens that can be used. Users are required to go through an internal application to upgrade to full access [[Limited Access]](https://docs.cohere.ai/limited-access).
",limited,"Limited use license to Cohere platform users [[Terms of Use]](https://cohere.ai/terms-of-use).
","Intended to be used by developers who would like to incorporate NLP into their applications [[Cohere Website]](https://cohere.ai/).
","The usage of the API is bound by the Cohere usage guidelines. Disallowed use cases include violence and threats, antisocial and antidemocratic uses, deceit, attacks on security or privacy, unsafe unsupervised uses, decision-making, high-Risk generations among others [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
","All applications developed using the Cohere API is subject to review by Cohere.
","General feedback as well as the violations of the usage guidelines can be reported to Cohere at responsibility at cohere.ai [[Usage Guidelines]](https://docs.cohere.ai/usage-guidelines).
",,,,,unknown,generation,https://cohere.ai/terms-of-use,unknown,unknown,unknown,401,nan,nan,933
502,model,Cohere Embedv3 (English),Cohere,"As of release, Cohere Embedv3 is Cohere's latest and most advanced embeddings model.",2023-11-02,https://txt.cohere.com/introducing-embed-v3/,unknown,Achieves SOTA performances on trusted MTEB and BEIR benchmarks.,,,limited,unknown,,,,https://huggingface.co/Cohere/Cohere-embed-english-v3.0/discussions,https://huggingface.co/Cohere/Cohere-embed-english-v3.0,unknown,unknown,unknown,,,,,,,402,text,text,934
503,model,Aya,"Cohere for AI, Cohere, Brown University, Carnegie Mellon University, MIT",Aya is a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced.,2024-02-12,https://arxiv.org/pdf/2402.07827.pdf,13B parameters (dense),Evaluated on standard LLM and multilingual benchmarks in comparison to SotA models.,mT5,,open,Apache 2.0,,,unknown,https://huggingface.co/CohereForAI/aya-101/discussions,https://huggingface.co/CohereForAI/aya-101,unknown,unknown,unknown,,,,,,,403,text,text,935
503,model,Aya,"Cohere for AI, Cohere, Brown University, Carnegie Mellon University, MIT",Aya is a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced.,2024-02-12,https://arxiv.org/pdf/2402.07827.pdf,13B parameters (dense),Evaluated on standard LLM and multilingual benchmarks in comparison to SotA models.,Aya Dataset,,open,Apache 2.0,,,unknown,https://huggingface.co/CohereForAI/aya-101/discussions,https://huggingface.co/CohereForAI/aya-101,unknown,unknown,unknown,,,,,,,403,text,text,936
504,model,Command-R,Cohere,Command-R is a scalable generative model targeting RAG and Tool Use to enable production-scale AI for enterprise.,2024-03-11,https://txt.cohere.com/command-r/,35B parameters (dense),,,,open,CC BY NC 4.0,,,,https://huggingface.co/CohereForAI/c4ai-command-r-v01/discussions,https://huggingface.co/CohereForAI/c4ai-command-r-v01,unknown,unknown,unknown,,,,,,,404,text,text,937
506,model,Rerank 3,Cohere,Rerank 3 is a new foundation model for efficient enterprise search and retrieval with 4k context length.,2024-04-11,https://cohere.com/blog/rerank-3,unknown,"Evaluated on code retrieval and data retrieval capabilities, with improvements compared to the standard in both.",,,limited,unknown,Efficient enterprise search and retrieval.,,unknown,,,unknown,unknown,unknown,,,,,,,405,text,text,938
507,model,Grok-1,xAI,"Grok is an AI modeled after the Hitchhiker’s Guide to the Galaxy,",2023-11-04,https://grok.x.ai/,314B parameters (dense),Grok-1 was evaluated on a range of reasoning benchmark tasks and on curated foreign mathematic examination questions.,,,open,Apache 2.0,"Grok-1 is intended to be used as the engine behind Grok for natural language processing tasks including question answering, information retrieval, creative writing and coding assistance.",,unknown,,https://x.ai/model-card/,unknown,unknown,unknown,,,,,,,406,text,text,939
508,model,Grok-1.5V,xAI,"Grok-1.5V is a first-generation multimodal model which can process a wide variety of visual information, including documents, diagrams, charts, screenshots, and photographs.",2024-04-12,https://x.ai/blog/grok-1.5v,unknown,"The model is evaluated in a zero-shot setting without chain-of-thought prompting. The evaluation domains include multi-disciplinary reasoning, understanding documents, science diagrams, charts, screenshots, photographs and real-world spatial understanding. The model shows competitive performance with existing frontier multimodal models.",,,limited,unknown,"Grok-1.5V can be used for understanding documents, science diagrams, charts, screenshots, photographs. It can also translate diagrams into Python code.",unknown,unknown,,,unknown,unknown,unknown,,,,,,,407,image,text,940
508,model,Grok-1.5V,xAI,"Grok-1.5V is a first-generation multimodal model which can process a wide variety of visual information, including documents, diagrams, charts, screenshots, and photographs.",2024-04-12,https://x.ai/blog/grok-1.5v,unknown,"The model is evaluated in a zero-shot setting without chain-of-thought prompting. The evaluation domains include multi-disciplinary reasoning, understanding documents, science diagrams, charts, screenshots, photographs and real-world spatial understanding. The model shows competitive performance with existing frontier multimodal models.",,,limited,unknown,"Grok-1.5V can be used for understanding documents, science diagrams, charts, screenshots, photographs. It can also translate diagrams into Python code.",unknown,unknown,,,unknown,unknown,unknown,,,,,,,407,text,text,941
509,application,Speak,Speak,Speak is an AI-powered language learning app focused on building the best path to spoken fluency and is the the fastest-growing English app in South Korea.,2023-03-01,https://openai.com/blog/introducing-chatgpt-and-whisper-apis,,,Whisper API,,open,,,,,,,,,,,,,,,,408,nan,nan,942
510,model,OceanGPT,Zhejiang University,OceanGPT is the first-ever LLM in the ocean domain and displays expertise in various ocean science tasks.,2024-02-06,https://www.zjukg.org/project/OceanGPT/,7B parameters (dense),Evaluated on standard and ocean science benchmarks in comparison to other similar-sized models.,,,open,MIT,,,unknown,https://huggingface.co/zjunlp/OceanGPT-7b/discussions,https://huggingface.co/zjunlp/OceanGPT-7b,unknown,7 days,6 A800 NVIDIA GPUs,,,,,,,409,text,text,943
511,model,BioMedLM,Stanford,,2022-12-15,https://crfm.stanford.edu/2022/12/15/pubmedgpt.html,2.7B parameters (dense),,The Pile,,open,bigscience-bloom-rail-1.0,,,,,,,,,,,,,,,410,text,text,944
512,model,RoentGen,Stanford,RoentGen is a generative medical imaging model that can create visually convincing X-ray images.,2022-11-23,https://arxiv.org/pdf/2211.12737.pdf,330M parameters (dense),Evaluated on own framework that tests domain-specific tasks in medical field.,Stable Diffusion,,open,,,,,,,unknown,60k training steps per day,64 A100 GPUs,,,,,,,411,text,image,945
512,model,RoentGen,Stanford,RoentGen is a generative medical imaging model that can create visually convincing X-ray images.,2022-11-23,https://arxiv.org/pdf/2211.12737.pdf,330M parameters (dense),Evaluated on own framework that tests domain-specific tasks in medical field.,RoentGen radiology dataset,,open,,,,,,,unknown,60k training steps per day,64 A100 GPUs,,,,,,,411,text,image,946
513,model,CORGI,Stanford,Model trained to generate language corrections for physical control tasks.,2023-06-12,https://arxiv.org/pdf/2306.07012.pdf,124M parameters (dense),"Evaluated on three physical control tasks, drawing, steering, and human body movement on various dynamics",GPT-2,,open,MIT,,,,,,,unknown,one NVIDIA A40 GPU,,,,,,,412,human trajectories,text,947
513,model,CORGI,Stanford,Model trained to generate language corrections for physical control tasks.,2023-06-12,https://arxiv.org/pdf/2306.07012.pdf,124M parameters (dense),"Evaluated on three physical control tasks, drawing, steering, and human body movement on various dynamics",BABEL,,open,MIT,,,,,,,unknown,one NVIDIA A40 GPU,,,,,,,412,human trajectories,text,948
513,model,CORGI,Stanford,Model trained to generate language corrections for physical control tasks.,2023-06-12,https://arxiv.org/pdf/2306.07012.pdf,124M parameters (dense),"Evaluated on three physical control tasks, drawing, steering, and human body movement on various dynamics",text-davinci-003,,open,MIT,,,,,,,unknown,one NVIDIA A40 GPU,,,,,,,412,human trajectories,text,949
515,model,Alpaca,Stanford,"Alpaca-7B is an instruction-following model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations.
",2023-03-13,https://crfm.stanford.edu/2023/03/13/alpaca.html,7B parameters (dense model),,LLaMa,,open,CC BY NC 4.0 (model weights),Alpaca is intended and licensed for research use only.,,,Feedback can be provided on [[GitHub Issues]](https://github.com/tatsu-lab/stanford_alpaca/issues).,,unknown,,,,,,,,,413,text (English),text (English),950
515,model,Alpaca,Stanford,"Alpaca-7B is an instruction-following model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations.
",2023-03-13,https://crfm.stanford.edu/2023/03/13/alpaca.html,7B parameters (dense model),,Alpaca dataset,,open,CC BY NC 4.0 (model weights),Alpaca is intended and licensed for research use only.,,,Feedback can be provided on [[GitHub Issues]](https://github.com/tatsu-lab/stanford_alpaca/issues).,,unknown,,,,,,,,,413,text (English),text (English),951
517,model,Nous Hermes 2,Nous Research,Nous Hermes 2 Mixtral 8x7B DPO is the new flagship Nous Research model trained over the Mixtral 8x7B MoE LLM.,2024-01-10,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO,7B parameters (dense),"Evaluated across standard benchmarks and generally performs better than Mixtral, which it was fine-tuned on.",Mixtral,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO/discussions,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO,unknown,unknown,unknown,,,,,,,414,text,code,952
517,model,Nous Hermes 2,Nous Research,Nous Hermes 2 Mixtral 8x7B DPO is the new flagship Nous Research model trained over the Mixtral 8x7B MoE LLM.,2024-01-10,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO,7B parameters (dense),"Evaluated across standard benchmarks and generally performs better than Mixtral, which it was fine-tuned on.",Mixtral,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO/discussions,https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO,unknown,unknown,unknown,,,,,,,414,text,text,953
518,model,YaRN LLaMA 2,"Nous Research, EleutherAI, University of Geneva",YaRN LLaMA 2 is an adapted version of LLaMA 2 using the YaRN extension method.,2023-11-01,https://arxiv.org/pdf/2309.00071.pdf,70B parameters (dense),Evaluated across a variety of standard benchmarks in comparison to LLaMA 2.,LLaMA 2,,open,LLaMA 2,,,unknown,https://huggingface.co/NousResearch/Yarn-Llama-2-70b-32k/discussions,https://huggingface.co/NousResearch/Yarn-Llama-2-70b-32k,unknown,unknown,unknown,,,,,,,415,text,text,954
519,model,Nous Capybara,Nous Research,The Capybara series is a series of LLMs and the first Nous collection of models made by fine-tuning mostly on data created by Nous in-house.,2023-11-13,https://huggingface.co/NousResearch/Nous-Capybara-34B,34B parameters (dense),,Yi,,open,MIT,,,unknown,https://huggingface.co/NousResearch/Nous-Capybara-34B/discussions,https://huggingface.co/NousResearch/Nous-Capybara-34B,unknown,unknown,unknown,,,,,,,416,text,text,955
520,model,YaRN Mistral,"Nous Research, EleutherAI, University of Geneva",YaRN Mistral is an adapted version of Mistral using the YaRN extension method.,2023-11-01,https://arxiv.org/pdf/2309.00071.pdf,7B parameters (dense),Evaluated across a variety of standard benchmarks in comparison to Mistral.,Mistral,,open,MIT,,,unknown,https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k/discussions,https://huggingface.co/NousResearch/Yarn-Mistral-7b-128k,unknown,unknown,unknown,,,,,,,417,text,text,956
521,model,OpenHermes 2.5 Mistral,Nous Research,"OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, trained on additional code datasets.",2023-11-03,https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B,7B parameters (dense),Evaluated on common LLM benchmarks in comparison to other Mistral derivatives.,Mistral,,open,Apache 2.0,,,unknown,https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B/discussions,https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B,unknown,unknown,unknown,,,,,,,418,text,text,957
522,model,Hermes 2 Pro-Mistral,Nous,"Hermes 2 Pro on Mistral 7B is an upgraded, retrained version of Nous Hermes 2. This improved version excels at function calling, JSON Structured Outputs, and several other areas, scoring positively on various benchmarks.",2024-03-10,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,7B parameters (dense),"The model was examined across a range of benchmarks including GPT4All, AGIEval, BigBench, TruthfulQA and in-house evaluations of function calling and JSON mode.",Mistral,"The model was evaluated across multiple tasks, displaying notable scores in GPT4All, AGIEval, BigBench, and TruthfulQA. It also has a high score on function calling and JSON mode, indicating the robustness of its capabilities.",open,Apache 2.0,"The model is intended for general task and conversation capabilities, function calling, and JSON structured outputs.",unknown,unknown,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B/discussions,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,unknown,unknown,unknown,,,,,,,419,text,text,958
522,model,Hermes 2 Pro-Mistral,Nous,"Hermes 2 Pro on Mistral 7B is an upgraded, retrained version of Nous Hermes 2. This improved version excels at function calling, JSON Structured Outputs, and several other areas, scoring positively on various benchmarks.",2024-03-10,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,7B parameters (dense),"The model was examined across a range of benchmarks including GPT4All, AGIEval, BigBench, TruthfulQA and in-house evaluations of function calling and JSON mode.",OpenHermes 2.5 Dataset,"The model was evaluated across multiple tasks, displaying notable scores in GPT4All, AGIEval, BigBench, and TruthfulQA. It also has a high score on function calling and JSON mode, indicating the robustness of its capabilities.",open,Apache 2.0,"The model is intended for general task and conversation capabilities, function calling, and JSON structured outputs.",unknown,unknown,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B/discussions,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,unknown,unknown,unknown,,,,,,,419,text,text,959
522,model,Hermes 2 Pro-Mistral,Nous,"Hermes 2 Pro on Mistral 7B is an upgraded, retrained version of Nous Hermes 2. This improved version excels at function calling, JSON Structured Outputs, and several other areas, scoring positively on various benchmarks.",2024-03-10,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,7B parameters (dense),"The model was examined across a range of benchmarks including GPT4All, AGIEval, BigBench, TruthfulQA and in-house evaluations of function calling and JSON mode.",Nous Hermes 2,"The model was evaluated across multiple tasks, displaying notable scores in GPT4All, AGIEval, BigBench, and TruthfulQA. It also has a high score on function calling and JSON mode, indicating the robustness of its capabilities.",open,Apache 2.0,"The model is intended for general task and conversation capabilities, function calling, and JSON structured outputs.",unknown,unknown,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B/discussions,https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B,unknown,unknown,unknown,,,,,,,419,text,text,960
523,model,Genstruct,Nous,"Genstruct is an instruction-generation model, designed to create valid instructions given a raw text corpus. This enables the creation of new, partially synthetic instruction finetuning datasets from any raw-text corpus. This work was inspired by Ada-Instruct and the model is also trained to generate questions involving complex scenarios that require detailed reasoning.",2024-03-07,https://huggingface.co/NousResearch/Genstruct-7B,7B parameters (dense),unknown,,unknown,open,Apache 2.0,"The model is intended for instruction-generation, creating questions involving complex scenarios and generating reasoning steps for those questions.",unknown,unknown,https://huggingface.co/NousResearch/Genstruct-7B/discussions,https://huggingface.co/NousResearch/Genstruct-7B,unknown,unknown,unknown,,,,,,,420,text,text,961
524,model,Megatron-LM,NVIDIA,Megatron-LM is an autoregressive language model,2021-04-09,https://arxiv.org/abs/2104.04473,1T parameters (dense),,,unknown,closed,unknown,,,,,,unknown,84 days,3072 A100 GPUs,,,,,,,421,text,text,962
527,model,VIMA,"NVIDIA, Stanford",,2022-10-06,https://vimalabs.github.io/,200M parameters (dense),,,,open,MIT,,,,,,,,,,,,,,,422,image,robotics trajectories,963
527,model,VIMA,"NVIDIA, Stanford",,2022-10-06,https://vimalabs.github.io/,200M parameters (dense),,,,open,MIT,,,,,,,,,,,,,,,422,text,robotics trajectories,964
528,model,Nemotron 4,Nvidia,Nemotron 4 is a 15-billion-parameter large multilingual language model trained on 8 trillion text tokens.,2024-02-27,https://arxiv.org/pdf/2402.16819.pdf,15B parameters (dense),"Evaluated on standard LLM benchmarks across a range of fields like reasoning, code generation, and mathematical skills.",,Deduplication and quality filtering techniques are applied to the training dataset.,open,unknown,,,unknown,,,unknown,13 days,3072 H100 80GB SXM5 GPUs across 384 DGX H100 nodes,,,,,,,423,text,code,965
528,model,Nemotron 4,Nvidia,Nemotron 4 is a 15-billion-parameter large multilingual language model trained on 8 trillion text tokens.,2024-02-27,https://arxiv.org/pdf/2402.16819.pdf,15B parameters (dense),"Evaluated on standard LLM benchmarks across a range of fields like reasoning, code generation, and mathematical skills.",,Deduplication and quality filtering techniques are applied to the training dataset.,open,unknown,,,unknown,,,unknown,13 days,3072 H100 80GB SXM5 GPUs across 384 DGX H100 nodes,,,,,,,423,text,text,966
529,model,BigTrans,Institute of Automation Chinese Academy of Sciences,BigTrans is a model which adapts LLaMA that covers only 20 languages and enhances it with multilingual translation capability on more than 100 languages,2023-05-29,https://arxiv.org/pdf/2305.18098v1.pdf,13B parameters (dense),Reports results on standard translation benchmarks across 102 languages in comparison with Google Translate and ChatGPT,LLaMA,,open,Apache 2.0,Advancing future research in multilingual LLMs,,,https://huggingface.co/James-WYang/BigTrans/discussions,https://huggingface.co/James-WYang/BigTrans,unknown,unknown,16 A100 GPUs with 80 GB of RAM,,,,,,,424,text,text,967
529,model,BigTrans,Institute of Automation Chinese Academy of Sciences,BigTrans is a model which adapts LLaMA that covers only 20 languages and enhances it with multilingual translation capability on more than 100 languages,2023-05-29,https://arxiv.org/pdf/2305.18098v1.pdf,13B parameters (dense),Reports results on standard translation benchmarks across 102 languages in comparison with Google Translate and ChatGPT,CLUE,,open,Apache 2.0,Advancing future research in multilingual LLMs,,,https://huggingface.co/James-WYang/BigTrans/discussions,https://huggingface.co/James-WYang/BigTrans,unknown,unknown,16 A100 GPUs with 80 GB of RAM,,,,,,,424,text,text,968
529,model,BigTrans,Institute of Automation Chinese Academy of Sciences,BigTrans is a model which adapts LLaMA that covers only 20 languages and enhances it with multilingual translation capability on more than 100 languages,2023-05-29,https://arxiv.org/pdf/2305.18098v1.pdf,13B parameters (dense),Reports results on standard translation benchmarks across 102 languages in comparison with Google Translate and ChatGPT,BigTrans parallel dataset,,open,Apache 2.0,Advancing future research in multilingual LLMs,,,https://huggingface.co/James-WYang/BigTrans/discussions,https://huggingface.co/James-WYang/BigTrans,unknown,unknown,16 A100 GPUs with 80 GB of RAM,,,,,,,424,text,text,969
530,model,YAYI 2,Institute of Automation Chinese Academy of Sciences,YAYI 2 is an open source large language model trained in both English and Chinese.,2023-12-22,https://arxiv.org/pdf/2312.14862.pdf,30B parameters (dense),"Evaluated on standard benchmarks for knowledge and language understanding, mathematical reasoning, and programming ability in comparison to similarly sized open-source models.",,"data is deduplicated, normalized, cleaned, and filtered for toxicity",open,custom,,,,https://huggingface.co/wenge-research/yayi2-30b/discussions,https://huggingface.co/wenge-research/yayi2-30b,unknown,unknown,over 1000 A800 GPUs,,,,,,,425,text,text,970
531,model,YaLM,Yandex,YaLM is a 100B parameter autoregressive model trained on 25% English and 75% Russian text.,2022-06-22,https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6,100B parameters (dense),,The Pile,,open,Apache 2.0,,,,,,,,Yandex 800 A100 Cluster,,,,,,,426,text,text,971
531,model,YaLM,Yandex,YaLM is a 100B parameter autoregressive model trained on 25% English and 75% Russian text.,2022-06-22,https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6,100B parameters (dense),,Yandex Russian Pretraining Dataset,,open,Apache 2.0,,,,,,,,Yandex 800 A100 Cluster,,,,,,,426,text,text,972
532,application,Yandex Search,Yandex,Yandex is a search engine and web portal. Yandex offers internet search and other services,2022-06-23,https://medium.com/yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6,,,YaLM,,open,custom,,,,,,,,,,,https://yandex.com/legal/browser_agreement/,,,,427,nan,nan,973
533,application,Continue,"Continue Dev, Inc.",Continue is the open-source autopilot for software development. It is an IDE extension that brings the power of ChatGPT to VS Code and JetBrains. It’s built to be deeply customizable and continuously learn from development data.,2023-07-26,https://continue.dev,,,GPT-4 API,,open,Apache 2.0,,,,,,,,,,,https://github.com/continuedev/continue/blob/main/LICENSE,,,,428,nan,nan,974
533,application,Continue,"Continue Dev, Inc.",Continue is the open-source autopilot for software development. It is an IDE extension that brings the power of ChatGPT to VS Code and JetBrains. It’s built to be deeply customizable and continuously learn from development data.,2023-07-26,https://continue.dev,,,Code Llama,,open,Apache 2.0,,,,,,,,,,,https://github.com/continuedev/continue/blob/main/LICENSE,,,,428,nan,nan,975
533,application,Continue,"Continue Dev, Inc.",Continue is the open-source autopilot for software development. It is an IDE extension that brings the power of ChatGPT to VS Code and JetBrains. It’s built to be deeply customizable and continuously learn from development data.,2023-07-26,https://continue.dev,,,Claude API,,open,Apache 2.0,,,,,,,,,,,https://github.com/continuedev/continue/blob/main/LICENSE,,,,428,nan,nan,976
533,application,Continue,"Continue Dev, Inc.",Continue is the open-source autopilot for software development. It is an IDE extension that brings the power of ChatGPT to VS Code and JetBrains. It’s built to be deeply customizable and continuously learn from development data.,2023-07-26,https://continue.dev,,,WizardCoder,,open,Apache 2.0,,,,,,,,,,,https://github.com/continuedev/continue/blob/main/LICENSE,,,,428,nan,nan,977
533,application,Continue,"Continue Dev, Inc.",Continue is the open-source autopilot for software development. It is an IDE extension that brings the power of ChatGPT to VS Code and JetBrains. It’s built to be deeply customizable and continuously learn from development data.,2023-07-26,https://continue.dev,,,PaLM API,,open,Apache 2.0,,,,,,,,,,,https://github.com/continuedev/continue/blob/main/LICENSE,,,,428,nan,nan,978
534,model,GOAT,National University of Singapore,GOAT is a fine-tuned LLaMA model which uses the tokenization of numbers to significantly outperform benchmark standards on a range of arithmetic tasks.,2023-05-23,https://arxiv.org/pdf/2305.14201.pdf,7B parameters (dense),"Performance assessed on BIG-bench arithmetic sub-task, and various elementary arithmetic tasks.",LLaMA,Number data is randomly generated from log space to reduce likelihood of redundancy and range of magnitudes.,open,Apache 2.0,Integration into other instruction-tuned LLMs to further enhance arithmetic reasoning abilities in solving math word problems.,,,,,unknown,unknown,24 GB VRAM GPU,,,,,,,429,text,text,979
534,model,GOAT,National University of Singapore,GOAT is a fine-tuned LLaMA model which uses the tokenization of numbers to significantly outperform benchmark standards on a range of arithmetic tasks.,2023-05-23,https://arxiv.org/pdf/2305.14201.pdf,7B parameters (dense),"Performance assessed on BIG-bench arithmetic sub-task, and various elementary arithmetic tasks.",GOAT dataset,Number data is randomly generated from log space to reduce likelihood of redundancy and range of magnitudes.,open,Apache 2.0,Integration into other instruction-tuned LLMs to further enhance arithmetic reasoning abilities in solving math word problems.,,,,,unknown,unknown,24 GB VRAM GPU,,,,,,,429,text,text,980
535,model,OpenMoE,"National University of Singapore, University of Edinburgh, ETH Zurich",OpenMoE is a series of fully open-sourced and reproducible decoder-only MoE LLMs.,2024-01-12,https://github.com/XueFuzhao/OpenMoE,34B parameters (dense),Evaluated on relatively simple established benchmarks.,RedPajama,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/OrionZheng/openmoe-base/discussions,https://huggingface.co/OrionZheng/openmoe-base,unknown,unknown,unknown,,,,,,,430,text,text,981
535,model,OpenMoE,"National University of Singapore, University of Edinburgh, ETH Zurich",OpenMoE is a series of fully open-sourced and reproducible decoder-only MoE LLMs.,2024-01-12,https://github.com/XueFuzhao/OpenMoE,34B parameters (dense),Evaluated on relatively simple established benchmarks.,The Stack,unknown,open,Apache 2.0,,,unknown,https://huggingface.co/OrionZheng/openmoe-base/discussions,https://huggingface.co/OrionZheng/openmoe-base,unknown,unknown,unknown,,,,,,,430,text,text,982
536,model,Baichuan 2,Baichuan Inc.,"Baichuan 2 is a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens.",2023-09-20,https://arxiv.org/pdf/2309.10305.pdf,13B parameters (dense),"Evaluated on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval.",,,open,Apache 2.0,,,,https://huggingface.co/Xwin-LM/Xwin-LM-70B-V0.1/discussions,,unknown,unknown,1024 NVIDIA A800 GPUs,,,,,,,431,text,text,983
538,model,Wu Dao 2.0,Beijing Academy of Artificial Intelligence,,2021-01-12,https://www.tsinghua.edu.cn/en/info/1420/10473.htm,1.75T parameters (dense),,Wu Dao dataset,,closed,unknown,,,,,,,,,,,,,,,432,image,image,984
538,model,Wu Dao 2.0,Beijing Academy of Artificial Intelligence,,2021-01-12,https://www.tsinghua.edu.cn/en/info/1420/10473.htm,1.75T parameters (dense),,Wu Dao dataset,,closed,unknown,,,,,,,,,,,,,,,432,image,text,985
538,model,Wu Dao 2.0,Beijing Academy of Artificial Intelligence,,2021-01-12,https://www.tsinghua.edu.cn/en/info/1420/10473.htm,1.75T parameters (dense),,Wu Dao dataset,,closed,unknown,,,,,,,,,,,,,,,432,text,image,986
538,model,Wu Dao 2.0,Beijing Academy of Artificial Intelligence,,2021-01-12,https://www.tsinghua.edu.cn/en/info/1420/10473.htm,1.75T parameters (dense),,Wu Dao dataset,,closed,unknown,,,,,,,,,,,,,,,432,text,text,987
539,model,JudgeLM,Beijing Academy of Artificial Intelligence,JudgeLM is a fine-tuned to be a scalable judge to evaluate LLMs efficiently and effectively in open-ended benchmarks.,2023-10-26,https://arxiv.org/pdf/2310.17631.pdf,13B parameters (dense),Evaluated on objective and reliability metrics.,Vicuna,,open,Apache 2.0,Research on evaluating the performance of large language models and chatbots.,,,https://huggingface.co/BAAI/JudgeLM-13B-v1.0/discussions,https://huggingface.co/BAAI/JudgeLM-13B-v1.0,unknown,unknown,8 A100 40GB NVIDIA GPUs,,,,,,,433,text,text,988
539,model,JudgeLM,Beijing Academy of Artificial Intelligence,JudgeLM is a fine-tuned to be a scalable judge to evaluate LLMs efficiently and effectively in open-ended benchmarks.,2023-10-26,https://arxiv.org/pdf/2310.17631.pdf,13B parameters (dense),Evaluated on objective and reliability metrics.,JudgeLM Dataset,,open,Apache 2.0,Research on evaluating the performance of large language models and chatbots.,,,https://huggingface.co/BAAI/JudgeLM-13B-v1.0/discussions,https://huggingface.co/BAAI/JudgeLM-13B-v1.0,unknown,unknown,8 A100 40GB NVIDIA GPUs,,,,,,,433,text,text,989
541,model,SegMamba,"Hong Kong University of Science and Technology (Guangzhou + original), Beijing Academy of Artificial Intelligence","SegMamba is a novel 3D medical image Segmentation Mamba model, designed to effectively capture long-range dependencies within whole volume features at every scale.",2024-01-25,https://arxiv.org/pdf/2401.13560v2.pdf,unknown,Compared to other segmentation models across different modalities on BraTS2023 dataset.,,unknown,open,Apache 2.0,,,unknown,,,unknown,1000 epochs,4 NVIDIA A100 GPUs,,,,,,,434,image,text,990
542,model,BGE M3 Embedding,"Beijing Academy of Artificial Intelligence, University of Science and Technology of China","BGE M3 Embedding is a new embedding model that can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks.",2024-02-05,https://arxiv.org/pdf/2402.03216.pdf,unknown,"Evaluated on standard datasets in multilingual, cross-lingual, long document retrieval, and Q&A domains.",,unknown,open,MIT,,,unknown,https://huggingface.co/BAAI/bge-m3/discussions,https://huggingface.co/BAAI/bge-m3,unknown,"20,000 steps",32 A100 40GB GPUs,,,,,,,435,text,text,991
543,model,EVA-CLIP,"Beijing Academy of Artificial Intelligence, Tsinghua University","As of release, EVA-CLIP is the largest and most powerful open-source CLIP model to date, with 18 billion parameters.",2024-02-06,https://arxiv.org/pdf/2402.04252.pdf,18B parameters (dense),Evaluated on zero-shot classification performance across multiple image classification benchmarks.,CLIP,,open,MIT,,,unknown,https://huggingface.co/BAAI/EVA-CLIP-8B-448/discussions,https://huggingface.co/BAAI/EVA-CLIP-8B-448,unknown,unknown,384 A100 40GB GPUs,,,,,,,436,image,text,992
543,model,EVA-CLIP,"Beijing Academy of Artificial Intelligence, Tsinghua University","As of release, EVA-CLIP is the largest and most powerful open-source CLIP model to date, with 18 billion parameters.",2024-02-06,https://arxiv.org/pdf/2402.04252.pdf,18B parameters (dense),Evaluated on zero-shot classification performance across multiple image classification benchmarks.,CLIP,,open,MIT,,,unknown,https://huggingface.co/BAAI/EVA-CLIP-8B-448/discussions,https://huggingface.co/BAAI/EVA-CLIP-8B-448,unknown,unknown,384 A100 40GB GPUs,,,,,,,436,text,text,993
545,model,Luminous,Aleph Alpha,Luminous is a family of multilingual language models,2022-04-14,https://twitter.com/Aleph__Alpha/status/1514576711492542477,200B parameters (dense),,Luminous dataset,,limited,,,,,,,unknown,unknown,unknown,,,,,,,437,text,text,994
546,application,Aleph Alpha API,Aleph Alpha,The Aleph Alpha API serves a family of text-only language models (Luminous) and multimodal text-and-image models (Magma).,2021-09-30,https://www.aleph-alpha.com/,,,Luminous,,limited,,unknown,unknown,unknown,unknown,,,,,,The text models provide text outputs given text inputs. The multimodal models provide text completions given text and image inputs.,https://www.aleph-alpha.com/terms-conditions,unknown,unknown,unknown,438,nan,nan,995
547,model,MAGMA,Aleph Alpha,An autoregressive VL model that is able to generate text from an arbitrary combination of visual and textual input,2022-10-24,https://arxiv.org/pdf/2112.05253.pdf,6B parameters (dense),Evaluated on the OKVQA benchmark as a fully open-ended generative task.,GPT-J,,open,MIT,,,,,,,,32 A100 GPUs,,,,,,,439,image,text,996
547,model,MAGMA,Aleph Alpha,An autoregressive VL model that is able to generate text from an arbitrary combination of visual and textual input,2022-10-24,https://arxiv.org/pdf/2112.05253.pdf,6B parameters (dense),Evaluated on the OKVQA benchmark as a fully open-ended generative task.,CLIP,,open,MIT,,,,,,,,32 A100 GPUs,,,,,,,439,image,text,997
547,model,MAGMA,Aleph Alpha,An autoregressive VL model that is able to generate text from an arbitrary combination of visual and textual input,2022-10-24,https://arxiv.org/pdf/2112.05253.pdf,6B parameters (dense),Evaluated on the OKVQA benchmark as a fully open-ended generative task.,GPT-J,,open,MIT,,,,,,,,32 A100 GPUs,,,,,,,439,text,text,998
547,model,MAGMA,Aleph Alpha,An autoregressive VL model that is able to generate text from an arbitrary combination of visual and textual input,2022-10-24,https://arxiv.org/pdf/2112.05253.pdf,6B parameters (dense),Evaluated on the OKVQA benchmark as a fully open-ended generative task.,CLIP,,open,MIT,,,,,,,,32 A100 GPUs,,,,,,,439,text,text,999
548,application,Robin AI,Robin AI,"Robin AI uses Claude and Anthropic's models to understand language - including in technical domains like legal language. It's also very confident at drafting, summarising, translations, and explaining complex concepts in simple terms",,https://www.robinai.co.uk/,,,Anthropic API,,limited,,,,,,,,,,,,https://www.robinai.co.uk/terms,,,,440,nan,nan,1000
549,application,Juni Tutor Bot,Juni Learning,An online tutoring solution to help students achieve academic success.,,https://junilearning.com/,,,Anthropic API,,limited,unknown,,,,,,,,,,,,,,,441,nan,nan,1001
551,model,Composer,Alibaba,,2023-02-20,https://arxiv.org/pdf/2302.09778.pdf,4.4B parameters (dense),,ImageNet,,closed,unknown,,,,,,,,,,,,,,,442,image,image,1002
551,model,Composer,Alibaba,,2023-02-20,https://arxiv.org/pdf/2302.09778.pdf,4.4B parameters (dense),,WebVision,,closed,unknown,,,,,,,,,,,,,,,442,image,image,1003
551,model,Composer,Alibaba,,2023-02-20,https://arxiv.org/pdf/2302.09778.pdf,4.4B parameters (dense),,LAION-1B,,closed,unknown,,,,,,,,,,,,,,,442,image,image,1004
551,model,Composer,Alibaba,,2023-02-20,https://arxiv.org/pdf/2302.09778.pdf,4.4B parameters (dense),,ImageNet,,closed,unknown,,,,,,,,,,,,,,,442,text,image,1005
551,model,Composer,Alibaba,,2023-02-20,https://arxiv.org/pdf/2302.09778.pdf,4.4B parameters (dense),,WebVision,,closed,unknown,,,,,,,,,,,,,,,442,text,image,1006
551,model,Composer,Alibaba,,2023-02-20,https://arxiv.org/pdf/2302.09778.pdf,4.4B parameters (dense),,LAION-1B,,closed,unknown,,,,,,,,,,,,,,,442,text,image,1007
552,model,Qwen,Alibaba,"QWEN is a comprehensive language model series that encompasses distinct models with varying parameter counts. Qwen series, now including Qwen, the base language models, namely Qwen-7B and Qwen-14B, as well as Qwen-Chat, the chat models, namely Qwen-7B-Chat and Qwen-14B-Chat. ",2023-08-03,https://arxiv.org/abs/2309.16609,14B parameters (dense),"Evaluated on MMLU, C-Eval, GSM8K, MATH, HumanEval, etc.",,"They filter out low-quality data, they employ a combination of rule-based and machine-learning-based methods. Specifically, they use multiple models to score the content, including language models, text-quality scoring models, and models for identifying potentially offensive or inappropriate content. They also manually sample texts from various sources and review them to ensure their quality. To further enhance the quality of our data, they selectively up-sample data from certain sources, to ensure that our models are trained on a diverse range of high-quality content.",open,custom,,,"Governed by the laws of China, without regard to conflict of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement. And The People's Courts in Hangzhou City shall have exclusive jurisdiction over any dispute arising out of this Agreement.",,https://huggingface.co/Qwen,unknown,,,,,,,,,443,image,text,1008
552,model,Qwen,Alibaba,"QWEN is a comprehensive language model series that encompasses distinct models with varying parameter counts. Qwen series, now including Qwen, the base language models, namely Qwen-7B and Qwen-14B, as well as Qwen-Chat, the chat models, namely Qwen-7B-Chat and Qwen-14B-Chat. ",2023-08-03,https://arxiv.org/abs/2309.16609,14B parameters (dense),"Evaluated on MMLU, C-Eval, GSM8K, MATH, HumanEval, etc.",,"They filter out low-quality data, they employ a combination of rule-based and machine-learning-based methods. Specifically, they use multiple models to score the content, including language models, text-quality scoring models, and models for identifying potentially offensive or inappropriate content. They also manually sample texts from various sources and review them to ensure their quality. To further enhance the quality of our data, they selectively up-sample data from certain sources, to ensure that our models are trained on a diverse range of high-quality content.",open,custom,,,"Governed by the laws of China, without regard to conflict of law principles, and the UN Convention on Contracts for the International Sale of Goods does not apply to this Agreement. And The People's Courts in Hangzhou City shall have exclusive jurisdiction over any dispute arising out of this Agreement.",,https://huggingface.co/Qwen,unknown,,,,,,,,,443,text,text,1009
553,model,Qwen 1.5,Alibaba,"Qwen 1.5 is the next iteration in their Qwen series, consisting of Transformer-based large language models pretrained on a large volume of data, including web texts, books, codes, etc.",2024-02-04,https://qwenlm.github.io/blog/qwen1.5/,72B parameters (dense),"Base models are evaluated on MMLU, C-Eval, GSM8K, MATH, HumanEval, MBPP, BBH, CMMLU, all standard English and Chinese benchmarks, and chat models are evaluated on Chatbot Arena, AlpacaEval, MT-Bench, etc.",,unknown,open,custom,,,unknown,https://huggingface.co/Qwen/Qwen1.5-72B/discussions,https://huggingface.co/Qwen/Qwen1.5-72B,unknown,unknown,unknown,,,,,,,444,text,text,1010
554,model,Qwen 1.5 MoE,Qwen Team,"Qwen 1.5 is the next iteration in their Qwen series, consisting of Transformer-based large language models pretrained on a large volume of data, including web texts, books, codes, etc. Qwen 1.5 MoE is the MoE model of the Qwen 1.5 series.",2024-03-28,https://qwenlm.github.io/blog/qwen-moe/,14B parameters with 2.7B parameters for activation (MoE),"Base models are evaluated on MMLU, C-Eval, GSM8K, MATH, HumanEval, MBPP, BBH, CMMLU, all standard English and Chinese benchmarks, and chat models are evaluated on Chatbot Arena, AlpacaEval, MT-Bench, etc.",,unknown,open,custom,,,unknown,https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B/discussions,https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B,unknown,unknown,unknown,,,,,,,445,text,text,1011
555,model,SeaLLM v2.5,"DAMO Academy, Alibaba",SeaLLM v2.5 is a multilingual large language model for Southeast Asian (SEA) languages.,2024-04-12,https://github.com/DAMO-NLP-SG/SeaLLMs,7B parameters,"The model was evaluated on 3 benchmarks (MMLU for English, M3Exam (M3e) for English, Chinese, Vietnamese, Indonesian, and Thai, and VMLU for Vietnamese) and it outperformed GPT-3 and Vistral-7B-chat models across these benchmarks in the given languages.",Gemma,"Despite efforts in red teaming and safety fine-tuning and enforcement, the creators suggest, developers and stakeholders should perform their own red teaming and provide related security measures before deployment, and they must abide by and comply with local governance and regulations.",open,custom,"The model is intended for multilingual tasks such as knowledge retrieval, math reasoning, and instruction following. Also, it could be used to provide multilingual assistance.","The model should not be used in a way that could lead to inaccurate, misleading or potentially harmful generation. Users should comply with local laws and regulations when deploying the model.",unknown,https://huggingface.co/SeaLLMs/SeaLLM-7B-v2.5/discussions,https://huggingface.co/SeaLLMs/SeaLLM-7B-v2.5,unknown,unknown,unknown,,,,,,,446,text,text,1012
557,model,Orion,OrionStarAI,Orion series models are open-source multilingual large language models trained from scratch by OrionStarAI.,2024-01-20,https://github.com/OrionStarAI/Orion,14B parameters (dense),Evaluated on multilingual and NLP benchmarks in comparison with SoTA models of comparable size.,,unknown,open,custom,,,unknown,https://huggingface.co/OrionStarAI/Orion-14B-Base/discussions,https://huggingface.co/OrionStarAI/Orion-14B-Base,unknown,unknown,unknown,,,,,,,447,text,text,1013
558,model,SambaLingo,Samba Nova Systems,SambaLingo is a suite of models that adapt Llama 2 to a diverse set of 9 languages.,2024-02-26,https://sambanova.ai/blog/sambalingo-open-source-language-experts,unknown,Evaluated on open source multilingual model benchmarks.,Llama 2,,open,LLaMA 2,,"SambaLingo should not be used for mission-critical applications, applications involving the safety of others, and highly critical decisions.",,https://huggingface.co/sambanovasystems/SambaLingo-Arabic-Base/discussions,https://huggingface.co/sambanovasystems/SambaLingo-Arabic-Base,unknown,unknown,unknown,,,,,,,448,text,text,1014
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,Llama 2,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1015
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,Mistral,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1016
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,Falcon-180B,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1017
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,Deepseek,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1018
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,BLOOM,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1019
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,LLaVA,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1020
559,model,Samba 1,Samba Nova Systems,Samba 1 is a trillion parameter generative AI model using a Composition of Experts architecture.,2024-02-28,https://sambanova.ai/blog/samba-1-composition-of-experts-mode,1T parameters (dense),unknown,CLIP,,limited,unknown,,,unknown,,,unknown,unknown,unknown,,,,,,,449,text,text,1021
561,model,SciPhi Mistral,SciPhi,SciPhi Mistral is a Large Language Model (LLM) fine-tuned from Mistral.,2023-11-07,https://huggingface.co/SciPhi/SciPhi-Mistral-7B-32k,7B parameters (dense),,Mistral,,open,MIT,,,unknown,https://huggingface.co/SciPhi/SciPhi-Mistral-7B-32k/discussions,https://huggingface.co/SciPhi/SciPhi-Mistral-7B-32k,unknown,unknown,unknown,,,,,,,450,text,text,1022
562,model,Notus,Argilla,"Notus is an open source LLM, fine-tuned using Direct Preference Optimization (DPO) and AIF (AI Feedback) techniques.",2023-12-01,https://argilla.io/blog/notus7b/,7B parameters (dense),Evaluated on MT-Bench and AlphaEval benchmarks.,UltraFeedback,,open,MIT,Academic research and free commercial usage,,,https://huggingface.co/argilla/notus-7b-v1/discussions,https://huggingface.co/argilla/notus-7b-v1,unknown,unknown,8 x A100 40GB GPUs,,,,,,,451,text,text,1023
562,model,Notus,Argilla,"Notus is an open source LLM, fine-tuned using Direct Preference Optimization (DPO) and AIF (AI Feedback) techniques.",2023-12-01,https://argilla.io/blog/notus7b/,7B parameters (dense),Evaluated on MT-Bench and AlphaEval benchmarks.,Zephyr,,open,MIT,Academic research and free commercial usage,,,https://huggingface.co/argilla/notus-7b-v1/discussions,https://huggingface.co/argilla/notus-7b-v1,unknown,unknown,8 x A100 40GB GPUs,,,,,,,451,text,text,1024
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,Arxiv,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1025
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,Books,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1026
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,C4,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1027
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,RefinedWeb,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1028
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,StarCoder,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1029
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,StackExchange,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1030
563,model,Amber,LLM360,"Amber is the first model in the LLM360 family, an initiative for comprehensive and fully open-sourced LLMs, where all training details, model checkpoints, intermediate results, and additional analyses are made available to the community.",2023-12-12,https://www.llm360.ai/,7B parameters (dense),Evaluated on several benchmark LLM tasks,Wikipedia,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/Amber/discussions,https://huggingface.co/LLM360/Amber,unknown,unknown,"56 DGX A100 nodes, each equipped with 4 80GB A100 GPUs",,,,,,,452,text,text,1031
564,model,CrystalCoder,LLM360,CrystalCoder is a language model with a balance of code and text data that follows the initiative under LLM360 of its training process being fully transparent.,2023-12-12,https://www.llm360.ai/,7B parameters (dense),"Evaluated on English and coding tasks and benchmarks, and outperforms LLaMA 2 in some.",SlimPajama,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/CrystalCoder/discussions,https://huggingface.co/LLM360/CrystalCoder,unknown,unknown,"Trained on the Cerebras Condor Galaxy 1 (CG-1), a 4 exaFLOPS, 54 million core, 64-node cloud AI supercomputer.",,,,,,,453,text,code,1032
564,model,CrystalCoder,LLM360,CrystalCoder is a language model with a balance of code and text data that follows the initiative under LLM360 of its training process being fully transparent.,2023-12-12,https://www.llm360.ai/,7B parameters (dense),"Evaluated on English and coding tasks and benchmarks, and outperforms LLaMA 2 in some.",StarCoder,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/CrystalCoder/discussions,https://huggingface.co/LLM360/CrystalCoder,unknown,unknown,"Trained on the Cerebras Condor Galaxy 1 (CG-1), a 4 exaFLOPS, 54 million core, 64-node cloud AI supercomputer.",,,,,,,453,text,code,1033
564,model,CrystalCoder,LLM360,CrystalCoder is a language model with a balance of code and text data that follows the initiative under LLM360 of its training process being fully transparent.,2023-12-12,https://www.llm360.ai/,7B parameters (dense),"Evaluated on English and coding tasks and benchmarks, and outperforms LLaMA 2 in some.",SlimPajama,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/CrystalCoder/discussions,https://huggingface.co/LLM360/CrystalCoder,unknown,unknown,"Trained on the Cerebras Condor Galaxy 1 (CG-1), a 4 exaFLOPS, 54 million core, 64-node cloud AI supercomputer.",,,,,,,453,text,text,1034
564,model,CrystalCoder,LLM360,CrystalCoder is a language model with a balance of code and text data that follows the initiative under LLM360 of its training process being fully transparent.,2023-12-12,https://www.llm360.ai/,7B parameters (dense),"Evaluated on English and coding tasks and benchmarks, and outperforms LLaMA 2 in some.",StarCoder,,open,Apache 2.0,to support open and collaborative AI research by making the full LLM training process transparent.,,unknown,https://huggingface.co/LLM360/CrystalCoder/discussions,https://huggingface.co/LLM360/CrystalCoder,unknown,unknown,"Trained on the Cerebras Condor Galaxy 1 (CG-1), a 4 exaFLOPS, 54 million core, 64-node cloud AI supercomputer.",,,,,,,453,text,text,1035
565,application,Duolingo Explain My Answer,Duolingo,"Explain My Answer offers learners the chance to learn more about their response in a lesson (whether their answer was correct or incorrect!) By tapping a button after certain exercise types, learners can enter a chat with Duo to get a simple explanation on why their answer was right or wrong, and ask for examples or further clarification.",2023-03-14,https://blog.duolingo.com/duolingo-max/,,,GPT-4 API,,limited,custom,,,,,,,,,,,https://www.duolingo.com/terms,,,,454,nan,nan,1036
566,application,Duolingo Max,Duolingo,Duolingo Max is a new subscription tier above Super Duolingo that gives learners access to two brand-new features and exercises - Explain My Answer and Roleplay.,2023-03-14,https://blog.duolingo.com/duolingo-max/,,,Duolingo Role Play,,limited,custom,,,,,,,,,,,,,,,455,nan,nan,1037
566,application,Duolingo Max,Duolingo,Duolingo Max is a new subscription tier above Super Duolingo that gives learners access to two brand-new features and exercises - Explain My Answer and Roleplay.,2023-03-14,https://blog.duolingo.com/duolingo-max/,,,Duolingo Explain My Answer,,limited,custom,,,,,,,,,,,,,,,455,nan,nan,1038
567,application,Duolingo Role Play,Duolingo,"Roleplay allows learners to practice real-world conversation skills with world characters in the app. These challenges, which earn XP, will live alongside the path as one of the “Side Quests” learners can access by tapping on the character. What will you talk about? We’ll guide you through different scenarios! Learners might discuss future vacation plans with Lin, order coffee at a café in Paris, go furniture shopping with Eddy, or ask a friend to go for a hike.",2023-03-14,https://blog.duolingo.com/duolingo-max/,,,GPT-4 API,,limited,custom,,,,,,,,,,,https://www.duolingo.com/terms,,,,456,nan,nan,1039
