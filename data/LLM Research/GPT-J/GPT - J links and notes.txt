>> Credibility <<

> (TrackRecord)
* lots of other projects done by this organisation. people also seem to like them 
(mainly b/c non-profit)
  https://www.reddit.com/r/MachineLearning/comments/11g4a9p/n_eleutherai_has_formed_a_nonprofit/

> (Endorsement)
https://en.wikipedia.org/wiki/GPT-J
https://aws.amazon.com/blogs/machine-learning/fine-tune-gpt-j-using-an-amazon-sagemaker-hugging-face-estimator-and-the-model-parallel-library/

> (Recognition)
https://en.wikipedia.org/wiki/GPT-J
--------------------------------------------------------------------------------------
>> Harmfulness <<

>(Incident)

* sometimes give unecessary or inaccurate info

>(Safeguards)


* Bias Detection Algorithms: Frameworks like GPTBIAS have been developed to evaluate and address 
 biases in large language models, including GPT-J. These frameworks use specific attack 
 instructions to identify and measure the extent of bias in model outputs​ (ar5iv)​.
* Moderation Tools: OpenAI has introduced a moderation API to warn or block unsafe content 
 generated by models like GPT-J. This API is trained by data labelers who categorize and filter 
 content to reduce toxicity and bias​ (OpenAI)​​ (Artificial intelligence)​.
* Human Feedback: Reinforcement Learning from Human Feedback (RLHF) is used to fine-tune the 
 model's responses, aiming to align outputs with human values and reduce controversial or biased 
 content. This involves labelers ranking and refining the model's responses during training​ 
 (OpenAI)​​ (Artificial intelligence)​.
 --> essentially all the normal stuff other models hav done too


-------------------------------------------------------------------
>> Accuracy <<

>> good code generation
>> fewer parameters and training data than gpt 2 and 3 -- so less accuarate than those ~ 25%


---------------------------------------------------------------------
>> Benchmark <<

>> Hugging Face Open LLM leaderboard
> The values from the above can be smaller than other benchmark scores so looking at Llama 3 data
 ( for which I had scores from both hugging face and other sources) I did a (ratio calculation) to
 get a better idea of a score

> https://www.width.ai/post/gpt-j-vs-gpt-3

-------------------------------------------------------------------------

>> Capabilities <<

* code generation tasks, create chatbox , story writing, translation of texts and information searches
* user input - limited characters - more concise prompts
* fine-tuning = better responses (like all other models)
---------------------------------------------------------------------------------
>> Success Stories<<

https://news.ycombinator.com/item?id=35000339 -- positive review

---------------------------------------------------------------------------
>> Popularity<<

* popular b/c of open-source nature and eluther ai being a non-profit
* not sure if popularity is affected by the model itself

> (active users) & (growth rate)
* because of open source nature probably more than normal

> (variety)
* good for code generation and has chatbot -- but limited training data limits its potential
* users also report unnecessary information produced as a result
